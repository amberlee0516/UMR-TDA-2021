{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions cluster_fun, mapper_pca_func written by Wako Bungula<br>\n",
    "Time list code and stratum dictionaries written by Wako Bungula<br>\n",
    "Function mapper - modified from mapper_pca_func, written by Killian Davis<br>\n",
    "Coloring nodes code was written by Killian Davis<br>\n",
    "JSON and pickle creation written by Forrest Miller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "from kmapper.plotlyviz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#from sklearn import ensemble\n",
    "# DBSCAN from sklearn for clustering algorithms\n",
    "from sklearn.cluster import DBSCAN\n",
    "# PCA from sklearn for projection/lens creation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "# from sklearn.manifold import MDS\n",
    "\n",
    "# scipy for interpolation\n",
    "# import scipy \n",
    "# from scipy.interpolate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly and Dash\n",
    "import plotly.graph_objs as go\n",
    "from kmapper.plotlyviz import plotlyviz\n",
    "from kmapper.plotlyviz import *\n",
    "from ipywidgets import (HBox, VBox)\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash\n",
    "from ipywidgets import interactive, HBox, VBox, widgets, interact\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predicted_df = pd.read_csv(r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Data\\water_full.csv\")\n",
    "predicted_df = predicted_df[predicted_df['FLDNUM']=='Havana, IL']\n",
    "predicted_df[\"MONTH\"] = pd.DatetimeIndex(predicted_df[\"DATE\"]).month\n",
    "predicted_df[\"SEASON\"] = predicted_df[\"MONTH\"]\n",
    "seasons = {3 : 'SPRING',\n",
    "           4 : 'SPRING',\n",
    "           5 : 'SPRING',\n",
    "           6 : 'SUMMER',\n",
    "           7 : 'SUMMER',\n",
    "           8 : 'SUMMER',\n",
    "           9 : 'FALL',\n",
    "           10 : 'FALL',\n",
    "           11: 'FALL',\n",
    "           12: 'WINTER',\n",
    "           1: 'WINTER',\n",
    "           2: 'WINTER'}\n",
    "predicted_df = predicted_df.replace({\"SEASON\" : seasons})\n",
    "\n",
    "stratum = {'Main channel' : 1, 'Side channel' : 2, 'Backwater area contiguous to the main channel' : 3}\n",
    "predicted_df = predicted_df.replace({\"STRATUM\" : stratum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dummy_list = ['STRATUM', 'FLDNUM', 'YEAR']\n",
    "\n",
    "for var in to_dummy_list:\n",
    "    temp = pd.get_dummies(predicted_df[var])\n",
    "    predicted_df = pd.concat([predicted_df, temp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "### Creating three main time spans and two overlapping time spans,\n",
    "### a total of five time spans\n",
    "\n",
    "# defining different time periods\n",
    "# first decade\n",
    "time_dec1 = [1993, 1994, 1995, 1997, 1998, 1999, 2000]\n",
    "# second decade\n",
    "time_dec2 = [2001, 2002,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]\n",
    "# third decade\n",
    "time_dec3 = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# overlap time periods for continuity\n",
    "time_overlap1 = [1998, 1999, 2000, 2001, 2002,2003, 2004]\n",
    "time_overlap2 = [2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "time_list = [time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "\n",
    "time_list_names = ['93-00', '98-04', '01-13', '10-16', '14-20']\n",
    "time_list =[time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "stratum_list = [1, 2, 3, 4, 5, 6, 7, 9]\n",
    "Season_names = [\"SPRING\", \"SUMMER\", \"FALL\", \"WINTER\"]\n",
    "\n",
    "nonempty_stratum = []\n",
    "for i in stratum_list:\n",
    "    if predicted_df[predicted_df['STRATUM'] == i].shape[0]!=0:\n",
    "        nonempty_stratum.append(i)\n",
    "print(nonempty_stratum) \n",
    "\n",
    "\n",
    "df_stratum_season_time_dict_list = []\n",
    "df_stratum_season_time_dict = {}\n",
    "s=\"\"\n",
    "for i in range(len(time_list)):\n",
    "    for j in nonempty_stratum:\n",
    "        for k in Season_names:\n",
    "            s=str(\"Stratum \") + str(j)+ \" \" + k + \" \" + time_list_names[i] + str(\": \")\n",
    "            df_stratum_season_time_dict[s] = predicted_df[(predicted_df['YEAR'].isin(time_list[i])) &\n",
    "                                                             (predicted_df['STRATUM'].isin([j])) & \n",
    "                                                             (predicted_df['SEASON'].isin([k]))]\n",
    "            df_stratum_season_time_dict_list.append(df_stratum_season_time_dict)\n",
    "            df_stratum_season_time_dict = {}\n",
    "            s=\"\"\n",
    "print(len(df_stratum_season_time_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_fun(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [7,7], PERC_OVERLAP = [.5,.5]):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    keys = list(dict_df.keys())\n",
    "    print(keys)\n",
    "    X = dict_df.get(keys[0])\n",
    "    X = X[[\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \n",
    "           \"TURB\", \"VEL\", \"TP\", \n",
    "           \"TN\", \"SS\", \"CHLcal\"]]\n",
    "    if X.shape[0]<DBSCAN_MIN_SAMPLES:\n",
    "        #print(X)\n",
    "        print(\"Not enough data to cluster in \", keys, \"_size = \", X.shape[0])\n",
    "        print(\"DBSCAN_MIN_SAMPLES\", DBSCAN_MIN_SAMPLES)\n",
    "        return([DBSCAN_MIN_SAMPLES, X.shape[0]])\n",
    "    \n",
    "    \n",
    "    db = DBSCAN(eps=20, min_samples=2).fit(X)\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    \n",
    "    return(db)\n",
    "\n",
    "    \n",
    "    \n",
    "def mapper_pca_func(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [7,7], PERC_OVERLAP = [.5,.5]):\n",
    "    \"\"\"\n",
    "    str(df_stratum_season_time_dict_list[1].keys())\n",
    "    \"\"\"\n",
    "\n",
    "    if len(dict_df) == 0:\n",
    "        print(\"Not Enough Data\")\n",
    "        return\n",
    "    \n",
    "    # \n",
    "    keys = list(dict_df.keys())\n",
    "    print(keys)\n",
    "    \n",
    "    X = dict_df.get(keys[0])\n",
    "    X = X[[\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \n",
    "           \"TURB\", \"VEL\", \"TP\", \n",
    "           \"TN\", \"SS\", \"CHLcal\"]]\n",
    "    \n",
    "    continuous_variables = [\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \n",
    "           \"TURB\", \"VEL\", \"TP\", \n",
    "           \"TN\", \"SS\", \"CHLcal\"]\n",
    "    var_to_index = {continuous_variables[i] : i for i in range(len(continuous_variables))}\n",
    "    \n",
    "    projected_vars = continuous_variables\n",
    "    #projected_vars = ['PredictedTP, PredictedTN']\n",
    "    projected_var_indices = [var_to_index[var] for var in projected_vars]\n",
    "    \n",
    "    if X.shape[0]<10:\n",
    "        #print(X)\n",
    "        print(\"Not enough data in \", keys, \"_size = \", X.shape[0])\n",
    "        return(X.shape[0], -1)\n",
    "    \n",
    "    X.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # defining clustering and kmapper parameters\n",
    "    DBSCAN_EPSILON = DBSCAN_EPSILON\n",
    "    DBSCAN_MIN_SAMPLES = DBSCAN_MIN_SAMPLES\n",
    "    N_CUBES = N_CUBES\n",
    "    PERC_OVERLAP = PERC_OVERLAP\n",
    "    \n",
    "    # create instance of clustering alg\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps=DBSCAN_EPSILON, min_samples=DBSCAN_MIN_SAMPLES, metric='euclidean')\n",
    "\n",
    "    # Instantiate kepler mapper object\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "    # defining filter function as projection on to the first 2 component axis\n",
    "    pca = PCA(n_components=1)\n",
    "    lens = pca.fit_transform(X)\n",
    "    #pca.fit_transform(X)\n",
    "    principle_component = max(abs(pca.components_[0].min()), abs(pca.components_[0].max()))\n",
    "    max_index = 0\n",
    "    for i in range(len(pca.components_[0])):\n",
    "        if abs(pca.components_[0][i]) == principle_component:\n",
    "            max_index = i\n",
    "    print(\"Primary variable: \", continuous_variables[max_index])\n",
    "    print(\"Corresponding component: \", pca.components_[0][max_index])\n",
    "    print('Explained Variance: ', pca.explained_variance_ratio_)\n",
    "    #lens = np.array(X[continuous_variables[max_index]])\n",
    "    #lens = np.array(X[['PredictedTN', 'PredictedSS']])\n",
    "    # Generate the simplicial complex\n",
    "    scomplex = mapper.map(lens, X, cover=km.Cover(n_cubes=N_CUBES, perc_overlap=PERC_OVERLAP), clusterer=cluster_alg,\n",
    "                         remove_duplicate_nodes=True)  \n",
    "    summary_variable = mapper.project(np.array(X), projection=projected_var_indices, scaler=None)\n",
    "\n",
    "    pl_brewer = [[0.0, '#006837'],\n",
    "             [0.1, '#1a9850'],\n",
    "             [0.2, '#66bd63'],\n",
    "             [0.3, '#a6d96a'],\n",
    "             [0.4, '#d9ef8b'],\n",
    "             [0.5, '#ffffbf'],\n",
    "             [0.6, '#fee08b'],\n",
    "             [0.7, '#fdae61'],\n",
    "             [0.8, '#f46d43'],\n",
    "             [0.9, '#d73027'],\n",
    "             [1.0, '#a50026']]\n",
    "\n",
    "    color_values = lens[:,0] - lens[:,0].min()\n",
    "    #color_function_name = [continuous_variables[max_index]]\n",
    "    color_function_name = ['Principle Component: ' + continuous_variables[max_index]]\n",
    "    my_colorscale = pl_brewer\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                     color_values=color_values,  \n",
    "                                                                     color_function_name=color_function_name, \n",
    "                                                                     colorscale=my_colorscale)\n",
    "\n",
    "    bgcolor = 'rgba(10,10,10, 0.9)'\n",
    "    # y_gridcolor = 'rgb(150,150,150)'# on a black background the gridlines are set on  grey\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout='fr', colorscale=my_colorscale, \n",
    "                                     factor_size=2.5, edge_linewidth=0.5)\n",
    "    plot_title = str(keys[0]) + str(DBSCAN_EPSILON) + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    # plot_title = 'Pool 13, Summer 1993-1999; Epsilon ' + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    layout = plot_layout(title=plot_title,  \n",
    "                         width=620, height=570,\n",
    "                         annotation_text=get_kmgraph_meta(mapper_summary),  \n",
    "                         bgcolor=bgcolor)\n",
    "\n",
    "    # FigureWidget is responsible for event listeners\n",
    "\n",
    "    fw_graph = go.FigureWidget(data=plotly_graph_data, layout=layout)\n",
    "    fw_hist = node_hist_fig(colorf_distribution, bgcolor=bgcolor)\n",
    "    fw_summary = summary_fig(mapper_summary, height=300)\n",
    "\n",
    "    dashboard = hovering_widgets(kmgraph, \n",
    "                                 fw_graph, \n",
    "                                 bgcolor=bgcolor, \n",
    "                                 member_textbox_width=600)\n",
    "\n",
    "    # DESIRED FILE PATH, CHANGE TO FIT YOUR LOCAL MACHINE\n",
    "    directory_path = \"Users\\\\killiad\\\\Documents\\\\Senior\\\\REU\\\\Mapper\\\\Backwater\\\\\"\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    fw_graph.data[1].marker.colorbar.title = 'dist to<br>x-min'\n",
    "    #html_output_path = directory_path + str(keys[0]) + 'PCA_2' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES[0]) + 'PEROvLp_' + str(PERC_OVERLAP[0]) + '.html'\n",
    "    html_output_path = directory_path + str(keys[0]) + 'PCA_1' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES) + 'PEROvLp_' + str(PERC_OVERLAP) + '.html'\n",
    "    html_output_path = html_output_path.replace(\" \", \"-\")\n",
    "    html_output_path = html_output_path.replace(\":\", \"_\")\n",
    "    html_output_path = \"C:\\\\\" + html_output_path\n",
    "    mapper.visualize(scomplex, color_values=color_values, color_function_name=color_function_name, path_html=html_output_path,\n",
    "                    lens = summary_variable, lens_names = projected_vars)\n",
    "    return scomplex, X\n",
    "\n",
    "\n",
    "\n",
    "def mapper(df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [7,7], PERC_OVERLAP = [.5,.5]):\n",
    "    \"\"\"\n",
    "    str(df_stratum_season_time_dict_list[1].keys())\n",
    "    \"\"\"\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"Not Enough Data\")\n",
    "        return\n",
    "    \n",
    "    df = df[[\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \n",
    "           \"TURB\", \"VEL\", \"TP\", \n",
    "           \"TN\", \"SS\", \"CHLcal\"]]\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    X = RobustScaler().fit_transform(df)\n",
    "    \n",
    "    continuous_variables = [\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \n",
    "           \"TURB\", \"VEL\", \"TP\", \n",
    "           \"TN\", \"SS\", \"CHLcal\"]\n",
    "    var_to_index = {continuous_variables[i] : i for i in range(len(continuous_variables))}\n",
    "    \n",
    "    projected_vars = continuous_variables\n",
    "    #projected_vars = ['PredictedTP, PredictedTN']\n",
    "    projected_var_indices = [var_to_index[var] for var in projected_vars]\n",
    "    \n",
    "    if X.shape[0]<10:\n",
    "        #print(X)\n",
    "        print(\"Not enough data in \", keys, \"_size = \", X.shape[0])\n",
    "        return(X.shape[0], -1)\n",
    "\n",
    "    # defining clustering and kmapper parameters\n",
    "    DBSCAN_EPSILON = DBSCAN_EPSILON\n",
    "    DBSCAN_MIN_SAMPLES = DBSCAN_MIN_SAMPLES\n",
    "    N_CUBES = N_CUBES\n",
    "    PERC_OVERLAP = PERC_OVERLAP\n",
    "    \n",
    "    # create instance of clustering alg\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps=DBSCAN_EPSILON, min_samples=DBSCAN_MIN_SAMPLES, metric='euclidean')\n",
    "\n",
    "    # Instantiate kepler mapper object\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "    # defining filter function as projection on to the first 2 component axis\n",
    "    pca = PCA(n_components=2)\n",
    "    lens = pca.fit_transform(X)\n",
    "    #pca.fit_transform(X)\n",
    "    principle_component = max(abs(pca.components_[0].min()), abs(pca.components_[0].max()))\n",
    "    max_index = 0\n",
    "    for i in range(len(pca.components_[0])):\n",
    "        if abs(pca.components_[0][i]) == principle_component:\n",
    "            max_index = i\n",
    "    print(\"Primary variable: \", continuous_variables[max_index])\n",
    "    print(\"Corresponding component: \", pca.components_[0][max_index])\n",
    "    print('Explained Variance: ', pca.explained_variance_ratio_)\n",
    "    #lens = np.array(X[continuous_variables[max_index]])\n",
    "    #lens = np.array(X[['PredictedTN', 'PredictedSS']])\n",
    "    # Generate the simplicial complex\n",
    "    scomplex = mapper.map(lens, X, cover=km.Cover(n_cubes=N_CUBES, perc_overlap=PERC_OVERLAP), clusterer=cluster_alg,\n",
    "                         remove_duplicate_nodes=True)  \n",
    "    summary_variable = mapper.project(np.array(X), projection=projected_var_indices, scaler=None)\n",
    "\n",
    "    pl_brewer = [[0.0, '#006837'],\n",
    "             [0.1, '#1a9850'],\n",
    "             [0.2, '#66bd63'],\n",
    "             [0.3, '#a6d96a'],\n",
    "             [0.4, '#d9ef8b'],\n",
    "             [0.5, '#ffffbf'],\n",
    "             [0.6, '#fee08b'],\n",
    "             [0.7, '#fdae61'],\n",
    "             [0.8, '#f46d43'],\n",
    "             [0.9, '#d73027'],\n",
    "             [1.0, '#a50026']]\n",
    "\n",
    "    color_vals = water_df[continuous_variables]\n",
    "    color_function_names = continuous_variables\n",
    "    my_colorscale = pl_brewer\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                     color_values=color_values,  \n",
    "                                                                     color_function_name=color_function_name, \n",
    "                                                                     colorscale=my_colorscale)\n",
    "\n",
    "    bgcolor = 'rgba(10,10,10, 0.9)'\n",
    "    # y_gridcolor = 'rgb(150,150,150)'# on a black background the gridlines are set on  grey\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout='fr', colorscale=my_colorscale, \n",
    "                                     factor_size=2.5, edge_linewidth=0.5)\n",
    "    plot_title = \"LaGrange\" + str(DBSCAN_EPSILON) + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    # plot_title = 'Pool 13, Summer 1993-1999; Epsilon ' + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    layout = plot_layout(title=plot_title,  \n",
    "                         width=620, height=570,\n",
    "                         annotation_text=get_kmgraph_meta(mapper_summary),  \n",
    "                         bgcolor=bgcolor)\n",
    "\n",
    "    # FigureWidget is responsible for event listeners\n",
    "\n",
    "    fw_graph = go.FigureWidget(data=plotly_graph_data, layout=layout)\n",
    "    fw_hist = node_hist_fig(colorf_distribution, bgcolor=bgcolor)\n",
    "    fw_summary = summary_fig(mapper_summary, height=300)\n",
    "\n",
    "    dashboard = hovering_widgets(kmgraph, \n",
    "                                 fw_graph, \n",
    "                                 bgcolor=bgcolor, \n",
    "                                 member_textbox_width=600)\n",
    "\n",
    "    # DESIRED FILE PATH, CHANGE TO FIT YOUR LOCAL MACHINE\n",
    "    directory_path = \"Users\\\\killiad\\\\Documents\\\\Senior\\\\REU\\\\Mapper\\\\LaGrange\\\\\"\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    fw_graph.data[1].marker.colorbar.title = 'dist to<br>x-min'\n",
    "    #html_output_path = directory_path + str(keys[0]) + 'PCA_2' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES[0]) + 'PEROvLp_' + str(PERC_OVERLAP[0]) + '.html'\n",
    "    html_output_path = directory_path + \"LaGrange_Scaled_\" + 'PCA_1' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES) + 'PEROvLp_' + str(PERC_OVERLAP) + '.html'\n",
    "    html_output_path = html_output_path.replace(\" \", \"-\")\n",
    "    html_output_path = html_output_path.replace(\":\", \"_\")\n",
    "    html_output_path = \"C:\\\\\" + html_output_path\n",
    "    mapper.visualize(scomplex, color_values=color_values, color_function_name=color_function_name, path_html=html_output_path,\n",
    "                    lens = summary_variable, lens_names = projected_vars)\n",
    "    return scomplex, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbclus_dict = {}\n",
    "for i in df_stratum_season_time_dict_list:\n",
    "    dbclus_dict[str(list(i.keys()))]=cluster_fun(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_pca_output_dict = {}\n",
    "#for i in df_stratum_season_time_dict_list:\n",
    "#    mapper_pca_output_dict[str(list(i.keys()))] = mapper_pca_func(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_cubes = [10]\n",
    "perc_overlap = [.35]\n",
    "mapper_pca_output_dict = {}\n",
    "mapper_pca_output_df = {}\n",
    "for cubes in n_cubes:\n",
    "    for perc in perc_overlap:\n",
    "        for i in df_stratum_season_time_dict_list:\n",
    "            scomplex, X = mapper_pca_func(i, N_CUBES = cubes, PERC_OVERLAP = perc)\n",
    "            if type(X) != int:\n",
    "                mapper_pca_output_dict[str(list(i.keys()))] = scomplex\n",
    "                mapper_pca_output_df[str(list(i.keys()))] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary variable:  SS\n",
      "Corresponding component:  0.6402743093586369\n",
      "Explained Variance:  [0.44654951 0.18992681]\n"
     ]
    }
   ],
   "source": [
    "mapper_pca_output_dict = {}\n",
    "mapper_pca_output_df = {}\n",
    "scomplex, X = mapper(predicted_df, N_CUBES = [50,50], PERC_OVERLAP = [.35,.35], DBSCAN_MIN_SAMPLES = 10, DBSCAN_EPSILON = 1)\n",
    "if type(X) != int:\n",
    "    mapper_pca_output_dict['LaGrange'] = scomplex\n",
    "    mapper_pca_output_df['LaGrange'] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "json = json.dumps(mapper_pca_output_dict)\n",
    "f = open(r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Mapper\\LaGrange\\LaGrange_Scaled.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>...</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64787</th>\n",
       "      <td>46000030</td>\n",
       "      <td>07/12/1993</td>\n",
       "      <td>40.553983</td>\n",
       "      <td>-89.673876</td>\n",
       "      <td>Havana, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>9362003</td>\n",
       "      <td>6.311</td>\n",
       "      <td>0.239</td>\n",
       "      <td>26.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64788</th>\n",
       "      <td>46000031</td>\n",
       "      <td>07/12/1993</td>\n",
       "      <td>40.567896</td>\n",
       "      <td>-89.656652</td>\n",
       "      <td>Havana, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>9362002</td>\n",
       "      <td>4.895</td>\n",
       "      <td>0.258</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64789</th>\n",
       "      <td>46000032</td>\n",
       "      <td>07/12/1993</td>\n",
       "      <td>40.578620</td>\n",
       "      <td>-89.653755</td>\n",
       "      <td>Havana, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>9362001</td>\n",
       "      <td>5.947</td>\n",
       "      <td>0.246</td>\n",
       "      <td>26.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64790</th>\n",
       "      <td>46000038</td>\n",
       "      <td>07/12/1993</td>\n",
       "      <td>40.526434</td>\n",
       "      <td>-89.847580</td>\n",
       "      <td>Havana, IL</td>\n",
       "      <td>2</td>\n",
       "      <td>9362020</td>\n",
       "      <td>6.204</td>\n",
       "      <td>0.249</td>\n",
       "      <td>26.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64791</th>\n",
       "      <td>46000040</td>\n",
       "      <td>07/12/1993</td>\n",
       "      <td>40.551597</td>\n",
       "      <td>-89.780275</td>\n",
       "      <td>Havana, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>9362004</td>\n",
       "      <td>2.833</td>\n",
       "      <td>0.258</td>\n",
       "      <td>26.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SHEETBAR        DATE   LATITUDE  LONGITUDE      FLDNUM  STRATUM  \\\n",
       "64787  46000030  07/12/1993  40.553983 -89.673876  Havana, IL        1   \n",
       "64788  46000031  07/12/1993  40.567896 -89.656652  Havana, IL        1   \n",
       "64789  46000032  07/12/1993  40.578620 -89.653755  Havana, IL        1   \n",
       "64790  46000038  07/12/1993  40.526434 -89.847580  Havana, IL        2   \n",
       "64791  46000040  07/12/1993  40.551597 -89.780275  Havana, IL        1   \n",
       "\n",
       "       LOCATCD     TN     TP  TEMP  ...  2011  2012  2013  2014  2015  2016  \\\n",
       "64787  9362003  6.311  0.239  26.2  ...     0     0     0     0     0     0   \n",
       "64788  9362002  4.895  0.258  27.0  ...     0     0     0     0     0     0   \n",
       "64789  9362001  5.947  0.246  26.3  ...     0     0     0     0     0     0   \n",
       "64790  9362020  6.204  0.249  26.9  ...     0     0     0     0     0     0   \n",
       "64791  9362004  2.833  0.258  26.8  ...     0     0     0     0     0     0   \n",
       "\n",
       "       2017  2018  2019 2020  \n",
       "64787     0     0     0    0  \n",
       "64788     0     0     0    0  \n",
       "64789     0     0     0    0  \n",
       "64790     0     0     0    0  \n",
       "64791     0     0     0    0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapper_pca_output_dict[\"['Stratum 1 WINTER 93-00: ']\"]['nodes']['cube2_cluster0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pickle = pk.dump(mapper_pca_output_df, open(r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Mapper\\LaGrange\\LaGrange_Scaled.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
