{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8917a773-86a7-4a3b-8663-2a006d34eac4",
   "metadata": {},
   "source": [
    "# Forrest TDA mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88b7094-878b-4e95-b2a2-d732a252abb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports\n"
     ]
    }
   ],
   "source": [
    "import kmapper as km\n",
    "from kmapper.plotlyviz import *\n",
    "import sklearn\n",
    "#from sklearn import ensemble\n",
    "# DBSCAN from sklearn for clustering algorithms\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PCA from sklearn for projection/lens creation\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import MDS\n",
    "# scipy for interpolation\n",
    "# import scipy \n",
    "# from scipy.interpolate import *\n",
    "# Plotly and Dash\n",
    "import plotly.graph_objs as go\n",
    "from kmapper.plotlyviz import plotlyviz\n",
    "from kmapper.plotlyviz import *\n",
    "from ipywidgets import (HBox, VBox)\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash\n",
    "from ipywidgets import interactive, HBox, VBox, widgets, interact\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "print(\"Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb1e1a-9266-4d7d-a523-4e269ca59716",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "Time periods creation & obtaining the datasets for each time period and strata and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3764fa8-b9ad-4c5c-bc48-880213a503bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non empty strata are:  ['Main channel', 'Side channel', 'Backwater area contiguous to the main channel', 'Lake Pepin or Swan Lake', 'Impounded']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "predicted_df = pd.read_csv(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\github\\UMR-TDA-2021\\LTRM data\\RF interpolation\\water_full.csv\")\n",
    "predicted_df = predicted_df[predicted_df['FLDNUM'] == 'Brighton, IL'] # filter for pool Bellevue, IA is pool 13\n",
    "### Creating three main time spans and two overlapping time spans,\n",
    "### a total of five time spans\n",
    "\n",
    "# defining different time periods\n",
    "# first decade\n",
    "time_dec1 = [1993, 1994, 1995, 1997, 1998, 1999, 2000]\n",
    "# second decade\n",
    "time_dec2 = [2001, 2002,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]\n",
    "# third decade\n",
    "time_dec3 = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# overlap time periods for continuity\n",
    "time_overlap1 = [1998, 1999, 2000, 2001, 2002,2003, 2004]\n",
    "time_overlap2 = [2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "time_list = [time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "\n",
    "time_list_names = ['93-00', '98-04', '01-13', '10-16', '14-20']        \n",
    "time_list =[time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "stratum_list = [\n",
    "    \"Main channel\",\"Side channel\",\"Backwater area contiguous to the main channel\",\"Lake Pepin or Swan Lake\",\n",
    "\"Impounded\",\n",
    "\"Isolated\"]\n",
    "Season_names = [2] # can add other seasons later\n",
    "\n",
    "nonempty_stratum = []\n",
    "for i in stratum_list:\n",
    "    if predicted_df[predicted_df['STRATUM'] == i].shape[0]!=0:\n",
    "        nonempty_stratum.append(i)\n",
    "print(\"Non empty strata are: \",nonempty_stratum) \n",
    "\n",
    "\n",
    "df_stratum_season_time_dict_list = []\n",
    "df_stratum_season_time_dict = {}\n",
    "s=\"\"\n",
    "\n",
    "for i in range(len(time_list)): # for every time period\n",
    "    for j in nonempty_stratum: # for every strata\n",
    "        for k in Season_names: # for every season # get rid of this line\n",
    "            s=\"Stratum \" + j + \" \" + str(k) + \" \" + time_list_names[i] + str(\": \")\n",
    "            df_stratum_season_time_dict[s] = predicted_df[(predicted_df['YEAR'].isin(time_list[i])) &\n",
    "                                                             (predicted_df['STRATUM'].isin([j])) & \n",
    "                                                             (predicted_df['SEASON'].isin([k]))]\n",
    "            df_stratum_season_time_dict_list.append(df_stratum_season_time_dict)\n",
    "            df_stratum_season_time_dict = {}\n",
    "            # obtain the subdata frame for the year set, strata, and season. Places that in a list\n",
    "            s=\"\"\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "print(len(df_stratum_season_time_dict_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47fcbfc5-d045-4ea8-83c4-cdfe5bd4cc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10879, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77186cb1-21a4-405d-bed1-f66fe0b66405",
   "metadata": {},
   "source": [
    "# TDA mapper function and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1107ac8-fcb6-4248-a0a9-4f8656dd993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "def cluster_fun(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = 10, PERC_OVERLAP = .3):\n",
    "    \"\"\"\n",
    "    How to cluster the data\n",
    "    \"\"\"\n",
    "    keys = list(dict_df.keys())\n",
    "    print(keys)\n",
    "    X = dict_df.get(keys[0])\n",
    "    X = X[[\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\", \"PREDICTED_VEL\", \"PREDICTED_TP\", #\"PREDICTED_COND\",\n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]]\n",
    "    \n",
    "    \n",
    "    if X.shape[0]<DBSCAN_MIN_SAMPLES:\n",
    "        #print(X)\n",
    "        print(\"Not enough data to cluster in \", keys, \"_size = \", X.shape[0])\n",
    "        print(\"DBSCAN_MIN_SAMPLES\", DBSCAN_MIN_SAMPLES)\n",
    "        return([DBSCAN_MIN_SAMPLES, X.shape[0]])\n",
    "    \n",
    "    \n",
    "    db = DBSCAN(eps=20, min_samples=2).fit(X)\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    \n",
    "    return(db)\n",
    "\n",
    "    \n",
    "    \n",
    "def mapper_func(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = 10, PERC_OVERLAP =.35, remove_duplicate_nodes = True):\n",
    "    \n",
    "    \n",
    "    #Initialize the dataframe to use \n",
    "    keys = list(dict_df.keys())\n",
    "    print(keys)\n",
    "    X = dict_df.get(keys[0])\n",
    "    variables = [\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\", \"PREDICTED_VEL\", \"PREDICTED_TP\", #\"PREDICTED_COND\",\n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]\n",
    "    \n",
    "    variables = [\"TN\", \"TP\",\"TEMP\", \"DO\",\"TURB\", \"VEL\", \"SS\", \"WDP\", \"CHLcal\",\"SECCHI\"] # \"COND\"\n",
    "    \n",
    "    var_to_index = {variables[i]:i for i in range(len(variables))}\n",
    "    \n",
    "    projected_vars = variables\n",
    "    projected_vars_indices = [var_to_index[var] for var in projected_vars]\n",
    "    \n",
    "    X = X[variables]\n",
    "    \n",
    "    if X.shape[0]<10:\n",
    "        #print(X)\n",
    "        print(\"Not enough data in \", keys, \"_size = \", X.shape[0])\n",
    "        return(X.shape[0])\n",
    "    # makes indices in kepler mapper 1 to 1 for statistical analysis on nodes in scomplexAnalysis\n",
    "    \n",
    "    X.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # create instance of clustering alg\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps=DBSCAN_EPSILON, min_samples=DBSCAN_MIN_SAMPLES, metric='euclidean')\n",
    "    # Instantiate kepler mapper object\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "        \n",
    "    # defining filter function as projection on to the first component axis\n",
    "    pca = PCA(n_components=1) # set to 1 for now \n",
    "    lens = pca.fit_transform(X)\n",
    "    print(\"pca explained variance: \", pca.explained_variance_ratio_)\n",
    "    \n",
    "    principle_component = max(abs(pca.components_[0].min()), abs(pca.components_[0].max()))\n",
    "    max_index = 0\n",
    "    for i in range(len(pca.components_[0])):\n",
    "        if abs(pca.components_[0][i]) == principle_component:\n",
    "            max_index = i\n",
    "    print(\"Max principal component: \", variables[max_index])\n",
    "    \n",
    "    # summary variables\n",
    "    summary_variables = mapper.project(np.array(X), projection = projected_vars_indices, scaler = None)\n",
    "    \n",
    "    \n",
    "    # Generate the simplicial complex\n",
    "    \n",
    "    \n",
    "    scomplex = mapper.map(lens, X, cover=km.Cover(n_cubes=N_CUBES, perc_overlap=PERC_OVERLAP), \n",
    "                          clusterer=cluster_alg, remove_duplicate_nodes = True)  \n",
    "    \n",
    "    \n",
    "    pl_brewer = [[0.0, '#006837'],\n",
    "             [0.1, '#1a9850'],\n",
    "             [0.2, '#66bd63'],\n",
    "             [0.3, '#a6d96a'],\n",
    "             [0.4, '#d9ef8b'],\n",
    "             [0.5, '#ffffbf'],\n",
    "             [0.6, '#fee08b'],\n",
    "             [0.7, '#fdae61'],\n",
    "             [0.8, '#f46d43'],\n",
    "             [0.9, '#d73027'],\n",
    "             [1.0, '#a50026']]\n",
    "\n",
    "    color_values = lens [:,0] - lens[:,0].min()\n",
    "    color_function_name = ['Distance to x-min']\n",
    "    my_colorscale = pl_brewer\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                     color_values = color_values,  \n",
    "                                                                     color_function_name=color_function_name, \n",
    "                                                                     colorscale=my_colorscale)\n",
    "\n",
    "    bgcolor = 'rgba(10,10,10, 0.9)'\n",
    "    # y_gridcolor = 'rgb(150,150,150)'# on a black background the gridlines are set on  grey\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout='fr', colorscale=my_colorscale, \n",
    "                                     factor_size=2.5, edge_linewidth=0.5)\n",
    "    plot_title = str(keys[0]) + str(DBSCAN_EPSILON) + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    # plot_title = 'Pool 13, Summer 1993-1999; Epsilon ' + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    layout = plot_layout(title=plot_title,  \n",
    "                         width=620, height=570,\n",
    "                         annotation_text=get_kmgraph_meta(mapper_summary),  \n",
    "                         bgcolor=bgcolor)\n",
    "\n",
    "    # FigureWidget is responsible for event listeners\n",
    "\n",
    "    fw_graph = go.FigureWidget(data=plotly_graph_data, layout=layout)\n",
    "    fw_hist = node_hist_fig(colorf_distribution, bgcolor=bgcolor)\n",
    "    fw_summary = summary_fig(mapper_summary, height=300)\n",
    "\n",
    "    dashboard = hovering_widgets(kmgraph, \n",
    "                                 fw_graph, \n",
    "                                 bgcolor=bgcolor, \n",
    "                                 member_textbox_width=600)\n",
    "\n",
    "    # DESIRED FILE PATH, CHANGE TO FIT YOUR LOCAL MACHINE\n",
    "    \n",
    "    directory_path = \"Users\\\\forre\\\\Desktop\\\\REU\\\\TDA\\\\Data\\\\TDAOutputs\"\n",
    "    html_output_path = directory_path + \"\\\\\" + str(keys[0]) + 'PCA_1' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES) + 'PEROvLp_' + str(PERC_OVERLAP) + '.html'\n",
    "    html_output_path = html_output_path.replace(\" \",\"-\")\n",
    "    html_output_path = html_output_path.replace(\":\",\"_\")\n",
    "    html_output_path = \"C:\\\\\"+html_output_path\n",
    "    #print(html_output_path)\n",
    "    mapper.visualize(scomplex, path_html=html_output_path, color_values = color_values,\n",
    "                    color_function_name = color_function_name,\n",
    "                    lens = summary_variables, lens_names = projected_vars)\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    fw_graph.data[1].marker.colorbar.title = 'dist to<br>x-min'\n",
    "    return scomplex, X\n",
    "    \n",
    "def mapper_test_func(dict_df, DBSCAN_EPSILON = 10, DBSCAN_MIN_SAMPLES = 5, N_CUBES = [100,100], PERC_OVERLAP = [.20,.20], remove_duplicate_nodes = True):\n",
    "    \n",
    "    \n",
    "    #Initialize the dataframe to use \n",
    "#     keys = list(dict_df.keys())\n",
    "#     print(keys)\n",
    "#     X = dict_df.get(keys[0])\n",
    "    X = dict_df\n",
    "    variables = [\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\", \"PREDICTED_VEL\", \"PREDICTED_TP\", #\"PREDICTED_COND\",\n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]\n",
    "    \n",
    "    variables = [\"TN\", \"TP\",\"TEMP\", \"DO\",\"TURB\", \"VEL\", \"SS\", \"WDP\", \"CHLcal\",\"SECCHI\"] # \"COND\"\n",
    "    \n",
    "    var_to_index = {variables[i]:i for i in range(len(variables))}\n",
    "    \n",
    "    projected_vars = variables\n",
    "    projected_vars_indices = [var_to_index[var] for var in projected_vars]\n",
    "    \n",
    "    X = X[variables]\n",
    "    \n",
    "    \n",
    "    Y = X.copy()\n",
    "    Y = pd.DataFrame(StandardScaler().fit_transform(Y))\n",
    "    \n",
    "    if Y.shape[0]<10:\n",
    "        #print(X)\n",
    "        print(\"Not enough data in \", keys, \"_size = \", X.shape[0])\n",
    "        return(Y.shape[0])\n",
    "    # makes indices in kepler mapper 1 to 1 for statistical analysis on nodes in scomplexAnalysis\n",
    "    X.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    Y.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # create instance of clustering alg\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps=DBSCAN_EPSILON, min_samples=DBSCAN_MIN_SAMPLES, metric='euclidean')\n",
    "    # Instantiate kepler mapper object\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "        \n",
    "    # defining filter function as projection on to the first component axis\n",
    "    pca = PCA(n_components=2) # set to 1 for now \n",
    "    lens = pca.fit_transform(X)\n",
    "    print(\"pca explained variance: \", pca.explained_variance_ratio_)\n",
    "    \n",
    "    principle_component = max(abs(pca.components_[0].min()), abs(pca.components_[0].max()))\n",
    "    max_index = 0\n",
    "    for i in range(len(pca.components_[0])):\n",
    "        if abs(pca.components_[0][i]) == principle_component:\n",
    "            max_index = i\n",
    "    print(\"Max principal component: \", variables[max_index])\n",
    "    \n",
    "    # summary variables\n",
    "    summary_variables = mapper.project(np.array(X), projection = projected_vars_indices, scaler = None)\n",
    "    \n",
    "    \n",
    "    # Generate the simplicial complex\n",
    "    # ******** # This is the Robust Scaler Change\n",
    "    \n",
    "    scomplex = mapper.map(lens, Y, cover=km.Cover(n_cubes=N_CUBES, perc_overlap=PERC_OVERLAP), \n",
    "                          clusterer=cluster_alg, remove_duplicate_nodes = True)  \n",
    "    \n",
    "    \n",
    "    pl_brewer = [[0.0, '#006837'],\n",
    "             [0.1, '#1a9850'],\n",
    "             [0.2, '#66bd63'],\n",
    "             [0.3, '#a6d96a'],\n",
    "             [0.4, '#d9ef8b'],\n",
    "             [0.5, '#ffffbf'],\n",
    "             [0.6, '#fee08b'],\n",
    "             [0.7, '#fdae61'],\n",
    "             [0.8, '#f46d43'],\n",
    "             [0.9, '#d73027'],\n",
    "             [1.0, '#a50026']]\n",
    "\n",
    "    color_values = lens [:,0] - lens[:,0].min()\n",
    "    color_function_name = ['Distance to x-min']\n",
    "    my_colorscale = pl_brewer\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                     color_values = color_values,  \n",
    "                                                                     color_function_name=color_function_name, \n",
    "                                                                     colorscale=my_colorscale)\n",
    "\n",
    "    bgcolor = 'rgba(10,10,10, 0.9)'\n",
    "    # y_gridcolor = 'rgb(150,150,150)'# on a black background the gridlines are set on  grey\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout='fr', colorscale=my_colorscale, \n",
    "                                     factor_size=2.5, edge_linewidth=0.5)\n",
    "    plot_title = str(DBSCAN_EPSILON) + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    # plot_title = 'Pool 13, Summer 1993-1999; Epsilon ' + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    layout = plot_layout(title=plot_title,  \n",
    "                         width=620, height=570,\n",
    "                         annotation_text=get_kmgraph_meta(mapper_summary),  \n",
    "                         bgcolor=bgcolor)\n",
    "\n",
    "    # FigureWidget is responsible for event listeners\n",
    "\n",
    "    fw_graph = go.FigureWidget(data=plotly_graph_data, layout=layout)\n",
    "    fw_hist = node_hist_fig(colorf_distribution, bgcolor=bgcolor)\n",
    "    fw_summary = summary_fig(mapper_summary, height=300)\n",
    "\n",
    "    dashboard = hovering_widgets(kmgraph, \n",
    "                                 fw_graph, \n",
    "                                 bgcolor=bgcolor, \n",
    "                                 member_textbox_width=600)\n",
    "\n",
    "    # DESIRED FILE PATH, CHANGE TO FIT YOUR LOCAL MACHINE\n",
    "    \n",
    "    directory_path = \"Users\\\\forre\\\\Desktop\\\\REU\\\\TDA\\\\Data\\\\TDAOutputs\\\\LetsGoAgain\"\n",
    "    html_output_path = directory_path + \"\\\\\"+ 'PCA_2' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES) + 'PEROvLp_' + str(PERC_OVERLAP) + '.html'\n",
    "    html_output_path = html_output_path.replace(\" \",\"\")\n",
    "    html_output_path = html_output_path.replace(\":\",\"_\")\n",
    "    html_output_path = \"C:\\\\\"+html_output_path\n",
    "    #print(html_output_path)\n",
    "    mapper.visualize(scomplex, path_html=html_output_path, color_values = color_values,\n",
    "                    color_function_name = color_function_name,\n",
    "                    lens = summary_variables, lens_names = projected_vars)\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    fw_graph.data[1].marker.colorbar.title = 'dist to<br>x-min'\n",
    "    return scomplex, X, Y\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff35246e-453b-448f-9ece-2039a45aec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca explained variance:  [0.7692028  0.15181453]\n",
      "Max principal component:  SS\n"
     ]
    }
   ],
   "source": [
    "scomplex, X, Y = mapper_test_func(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8df0f2-6bf3-49d4-abfe-360e1b63c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca explained variance:  [0.7692028  0.15181453]\n",
      "Max principal component:  SS\n"
     ]
    }
   ],
   "source": [
    "scomplex, X, Y = mapper_test_func(predicted_df)\n",
    "import json as js\n",
    "json = js.dumps(scomplex)\n",
    "f = open(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\LetsGoAgain\\pool26_complex.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()\n",
    "import pickle as pk\n",
    "pickle = pk.dump(X, open(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\LetsGoAgain\\pool26_df.p\",\"wb\"))\n",
    "pickle2 = pk.dump(Y, open(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\LetsGoAgain\\pool26_df_StandardScaled.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1be21d-c22a-4686-8fec-e28127311d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_output_dict = {}\n",
    "mapper_output_df = {}\n",
    "for i in df_stratum_season_time_dict_list:\n",
    "            scomplex, X = mapper_func(i)\n",
    "            mapper_output_dict[str(list(i.keys()))] = scomplex\n",
    "            mapper_output_df[str(list(i.keys()))] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55807769-45a0-43f3-adf9-5917b5ee0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "json = js.dumps(mapper_output_dict)\n",
    "f = open(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\PCA1_10Cubes_30Perc_complices.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6dd49-6fa6-4fde-9688-bd1b802289ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca95c630-771e-4596-943f-941f12e1a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d3b7c-705f-4863-8794-3f6e239596a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pickle = pk.dump(mapper_output_df,\n",
    "                 open(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\PCA1_10Cubes_30Perc_complices_dfs.p\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
