{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab6dbdc",
   "metadata": {},
   "source": [
    "Functions generate_scomplex, visualize_by_state are written by Killian Davis with code modified from mapper_pca_func, which is written by Wako Bungula.<br>\n",
    "Functions k_nearest_neighbors, calculate_density, generate_graph, generate_nodes, generate_edges, get_local_maxima, draw_graph,\n",
    "graph_distance, append_states are written by Killian Davis. Alaina Stockdill contributed the algorithm behind append_states, which is used to visualize the states in visualize_by_state<br>\n",
    "Functions getSubdf, adjacent, bfs, condenseShape, getShapes, clean_getShapes written by Forrest Miller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "from kmapper.plotlyviz import *\n",
    "import sklearn\n",
    "#from sklearn import ensemble\n",
    "# DBSCAN from sklearn for clustering algorithms\n",
    "from sklearn.cluster import DBSCAN\n",
    "# PCA from sklearn for projection/lens creation\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import MDS\n",
    "\n",
    "# scipy for interpolation\n",
    "# import scipy \n",
    "# from scipy.interpolate import *\n",
    "# Plotly and Dash\n",
    "import plotly.graph_objs as go\n",
    "from kmapper.plotlyviz import plotlyviz\n",
    "from kmapper.plotlyviz import *\n",
    "from ipywidgets import (HBox, VBox)\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash\n",
    "from ipywidgets import interactive, HBox, VBox, widgets, interact\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import json\n",
    "import queue\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scomplex(df, epsilon = 1, min_samples = 10, n_cubes = [125,125], perc_overlap = [.4,.4]):\n",
    "    '''\n",
    "    Create the simplicial complex using Mapper and DBSCAN\n",
    "    '''\n",
    "    X = RobustScaler().fit_transform(df)\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps = epsilon, min_samples = min_samples, metric = 'euclidean')\n",
    "    pca = PCA(n_components = 2)\n",
    "    lens = pca.fit_transform(X)\n",
    "    print(\"Explained Variance: \", pca.explained_variance_ratio_)\n",
    "\n",
    "    mapper = km.KeplerMapper(verbose = 0)\n",
    "    scomplex = mapper.map(lens, X, cover = km.Cover(n_cubes = n_cubes, perc_overlap = perc_overlap), \n",
    "                                                clusterer = cluster_alg, remove_duplicate_nodes = True)  \n",
    "    return scomplex\n",
    "\n",
    "\n",
    "def visualize_by_state(scomplex, df, filepath):\n",
    "    '''\n",
    "    Color the html file by state\n",
    "    '''\n",
    "    mapper = km.KeplerMapper(verbose = 0)\n",
    "    continuous_variables =  [\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \"TURB\", \"VEL\", \"TP\", \"TN\", \"SS\", \"CHLcal\"]\n",
    "    var_to_index = {continuous_variables[i] : i for i in range(len(continuous_variables))}\n",
    "    projected_var_indices = [var_to_index[var] for var in continuous_variables]\n",
    "    summary_variable = mapper.project(np.array(df), projection = projected_var_indices, scaler = None)\n",
    "    \n",
    "    # Make HTML with color values as the states\n",
    "    color_vals = df[scomplex['maxima']]\n",
    "    color_names = scomplex['maxima']\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                        color_values = color_vals,\n",
    "                                                                        color_function_name = color_names)\n",
    "\n",
    "    #for node in kmgraph['nodes']:\n",
    "    #    node['custom_tooltips'] = np.array(water_df[variable])[scomplex['nodes'][node['name']]]\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout = 'fr', factor_size = 2.5, edge_linewidth = 0.5)\n",
    "\n",
    "    layout = plot_layout(title = 'LTRM DATA',  \n",
    "                        width = 620, height = 570,\n",
    "                        annotation_text = get_kmgraph_meta(mapper_summary))\n",
    "\n",
    "#     # FigureWidget is responsible for event listeners\n",
    "#     fw_graph = go.FigureWidget(data = plotly_graph_data, layout = layout)\n",
    "#     fw_hist = node_hist_fig(colorf_distribution)\n",
    "#     fw_summary = summary_fig(mapper_summary, height = 300)\n",
    "#     dashboard = hovering_widgets(kmgraph, \n",
    "#                                 fw_graph, \n",
    "#                                 ctooltips = True,\n",
    "#                                 member_textbox_width = 600)\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    #fw_graph.data[1].marker.colorbar.title = 'hi'\n",
    "\n",
    "    html_output_path = filepath\n",
    "\n",
    "    mapper.visualize(scomplex, color_values = color_vals, color_function_name = color_names, \n",
    "                    path_html = html_output_path, lens = summary_variable, lens_names = continuous_variables)\n",
    "\n",
    "\n",
    "def k_nearest_neighbors(df, neigh, point, k):\n",
    "    '''\n",
    "    Uses sklearn to get the k nearnest neighbors for a point\n",
    "    '''\n",
    "    return neigh.kneighbors([list(df.loc[point])], k)[0].flatten()\n",
    "    \n",
    "def calculate_density(scomplex, node, df, k):\n",
    "    '''\n",
    "    Calculates the density of each node and makes dictionary scomplex['density']\n",
    "    '''\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(df)\n",
    "    knn = 0\n",
    "    n = len(scomplex['nodes'][node])\n",
    "    for point in scomplex['nodes'][node]:\n",
    "        distances = k_nearest_neighbors(df, neigh, point, k)\n",
    "        knn += (sum(distances) / k)\n",
    "    density = knn / (n*n)\n",
    "    return (1.0 / density)\n",
    "\n",
    "def generate_graph(scomplex, shape):\n",
    "    '''\n",
    "    Creates directed graph uses density generated from before\n",
    "    '''\n",
    "    dg = generate_nodes(scomplex, shape)\n",
    "    dg = generate_edges(scomplex, shape, dg)\n",
    "    return dg\n",
    "\n",
    "def generate_nodes(scomplex, shape):\n",
    "    '''\n",
    "    Makes nodes to make the graph\n",
    "    '''\n",
    "    dg = nx.DiGraph()\n",
    "    dg.add_nodes_from(shape)\n",
    "    return dg\n",
    "\n",
    "def generate_edges(scomplex, shape, dg):\n",
    "    '''\n",
    "    Makes edges to make the graph\n",
    "    '''\n",
    "    for node in shape:\n",
    "        if node in scomplex['links']:\n",
    "            for adjacent_node in scomplex['links'][node]:\n",
    "                if scomplex['density'][node] < scomplex['density'][adjacent_node]:\n",
    "                    dg.add_edge(node, adjacent_node)\n",
    "                else:\n",
    "                    dg.add_edge(adjacent_node, node)\n",
    "    return dg\n",
    "\n",
    "def get_local_maxima(dg):\n",
    "    maxima = []\n",
    "    for node in list(dg.nodes):\n",
    "        succ = dict(nx.bfs_successors(dg, source=node))\n",
    "        if not succ[node]:\n",
    "            maxima.append(node)\n",
    "    return maxima\n",
    "\n",
    "def draw_graph(scomplex, filepath, with_labels=False):\n",
    "    '''\n",
    "    Draws the graph and colors according to state\n",
    "    '''\n",
    "    #colors = ['#ff0000', '#3366ff', '#0BB30B', '#A312A3', '#669999']\n",
    "    colors = ['#ff0000', '#3366ff', '#0BB30B', '#A312A3', '#669999', '#4B8F8C', '#484DD6', '#2C365E', '#C5979D']\n",
    "    #colors.reverse()\n",
    "    colors_dict = {scomplex['maxima'][i] : colors[i] for i in range(len(scomplex['maxima']))}\n",
    "    transition_color = '#D8D135'\n",
    "    color_map = []\n",
    "    scomplex['states'] = {scomplex['maxima'][i] : [] for i in range(len(scomplex['maxima']))}\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = plt.subplot(111)\n",
    "    #ax.set_title('Mississippi River Ecological States', fontsize=40)\n",
    "    \n",
    "    transition_exists = False\n",
    "    for node in scomplex['graph']:\n",
    "        distDict = {scomplex['maxima'][i] : graph_distance(scomplex['graph'], node, scomplex['maxima'][i])\n",
    "                    for i in range(len(scomplex['maxima']))}\n",
    "        minDist = min(distDict.values())\n",
    "        states = [maxima if distDict[maxima] == minDist else None for maxima in scomplex['maxima']]\n",
    "        states = list(filter(None, states))\n",
    "        \n",
    "        for state in states:\n",
    "            scomplex['states'][state].append(node)\n",
    "        \n",
    "        if len(states) > 1:\n",
    "            color_map.append(transition_color)\n",
    "            transition_exists = True\n",
    "        else:\n",
    "            color_map.append(colors_dict[states[0]])\n",
    "    \n",
    "    #making the legend\n",
    "    for node in scomplex['maxima']:\n",
    "        plt.scatter([],[], c=[colors_dict[node]], label = \"Whole RIver State \" + str(scomplex['maxima'].index(node) + 1))\n",
    "    if transition_exists:\n",
    "        plt.scatter([],[], c=[transition_color], label = \"Transition State\")\n",
    "    plt.legend(markerscale = 4, prop={\"size\":19})\n",
    "        \n",
    "    #scomplex['graph'] = nx.relabel_nodes(scomplex['graph'], relabeling, copy=False)\n",
    "    nx.draw_kamada_kawai(scomplex['graph'], with_labels=with_labels, node_color=color_map, node_size = 200)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filepath, format=\"PNG\")\n",
    "    plt.show()\n",
    "\n",
    "def graph_distance(dg, source, target):\n",
    "    '''\n",
    "    Calculates distance from source to target. Retuns infinity if there is no path\n",
    "    '''\n",
    "    if nx.has_path(dg, source, target):\n",
    "        return len(nx.shortest_path(dg, source, target))\n",
    "    return float('inf')\n",
    "\n",
    "\n",
    "def getSubdf(scomplex, shape, df):\n",
    "    \"\"\"\n",
    "    Returns the part of the data frame from the particular shape in the simplicial complex.\n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    shape: the particular shape being inspected (within the simplicial complex)\n",
    "    df: the entire data frame\n",
    "    \n",
    "    Description:\n",
    "    1. Get all the nodes from the particular simplicial complex. \n",
    "    2. Generate the indices we care about from the particular shape. To do this, we read each node and append it's \n",
    "    indices to a list. Then, we convert the list to a set and then back to a list to eliminate duplicates.\n",
    "    3. Return the dataframe with only those indices.\n",
    "    \"\"\"\n",
    "    nodes = scomplex.get('nodes')\n",
    "    indices = []\n",
    "    npShape = np.array(shape).flatten()\n",
    "    for node in npShape:\n",
    "        indices.append(nodes.get(node))\n",
    "    indices = list(set([item for sublist in indices for item in sublist]))\n",
    "    subdf = df.loc[indices]\n",
    "    return subdf\n",
    "\n",
    "\n",
    "def adjacent(v, scomplex):\n",
    "    \"\"\"\n",
    "    Determines the nodes adjacent to a given vertex\n",
    "    \n",
    "    params:\n",
    "    v: vertex\n",
    "    scomlex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    Determines the nodes that are adjacent to a given vertex.\n",
    "    \"\"\"\n",
    "    \n",
    "    simplices = scomplex.get('simplices')\n",
    "    edges = [item for item in simplices if len(item) == 2]\n",
    "    result = []\n",
    "    for edge in edges:\n",
    "        if v in edge:\n",
    "            for item in edge:\n",
    "                if item != v:\n",
    "                    result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def bfs(node, scomplex):\n",
    "    \"\"\"\n",
    "    Conducts a breadth first search to obtain the entire shape from a given node\n",
    "    params:\n",
    "    node: the start node\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    Preforms a breadth first search to obtain the entire shape for a given start node.\n",
    "    \"\"\"\n",
    "    Q = queue.Queue()\n",
    "    result = []\n",
    "    result.append(node)\n",
    "    Q.put(node)\n",
    "    while not Q.empty():\n",
    "        v = Q.get()\n",
    "        adjacentEdges = adjacent(v, scomplex)\n",
    "        for edge in adjacentEdges:\n",
    "            if edge not in result:\n",
    "                result.append(edge)\n",
    "                Q.put(edge)\n",
    "    return result\n",
    "\n",
    "\n",
    "def condenseShape(shape, scomplex):\n",
    "    \"\"\"\n",
    "    \n",
    "    params:\n",
    "    shape: a shape of two nodes. must be 2\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    description:\n",
    "    gets the two nodes a and b\n",
    "    gets the indices for a and b (what is inside the nodes)\n",
    "    if a \\subseteq b, return b\n",
    "    elif b \\subseteq a, return a \n",
    "    else return shape \n",
    "    \n",
    "    \"\"\"\n",
    "    nodes = scomplex.get('nodes')\n",
    "    a = shape[0]\n",
    "    b = shape[1]\n",
    "    aIndices = set(nodes.get(a))\n",
    "    bIndices = set(nodes.get(b))\n",
    "    \n",
    "    if aIndices.issubset(bIndices):\n",
    "        return b\n",
    "    elif bIndices.issubset(aIndices):\n",
    "        return a\n",
    "    else:\n",
    "        return shape\n",
    "\n",
    "\n",
    "def getShapes(scomplex):\n",
    "    \"\"\"\n",
    "    Gets all of the shapes from a given simplicial complex.\n",
    "    \n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    1. Obtain all the nodes for the entire complex\n",
    "    2. For each node, preform a breadth first search to obtain everything in that particular shape. \n",
    "    If this entire shape has not already been discovered, add it to the set of results. \n",
    "    The result item is a set as the order of the shapes does not matter. The resulting shape is a frozenset\n",
    "    which means items cannot be added or removed once created, and is needed to allow the set object to have other sets within it.\n",
    "    3. Convert each shape to a list and the result to a list for easier navigation outside of the function.\n",
    "    4. Return the result\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = list(scomplex.get('nodes').keys())\n",
    "    result = set()\n",
    "    for node in nodes: # currently does more computations than necessary due to going through every node without considering it is already in a shape\n",
    "        bfsResult = frozenset(bfs(node, scomplex))\n",
    "        result.add(bfsResult)\n",
    "    result = [list(x) for x in result]\n",
    "    # Sort the list depending on what is decided: nodes or indices. Currently doing it by number of nodes\n",
    "    result.sort(key = len, reverse = True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def clean_getShapes(scomplex):\n",
    "    \"\"\"\n",
    "    Condenses 1-simplices down to 0-simplices when each node \n",
    "    is a subset of the other \n",
    "    \n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    1. Get all the shapes from the original getShapes function\n",
    "    2. For shapes that of length 2, if one is a subset of the other, return the larger of the two\n",
    "        Otherwise, do nothing\n",
    "    3. return the clean Shapes list \n",
    "    \n",
    "    \"\"\"\n",
    "    shapes = getShapes(scomplex)\n",
    "    cleanShapes = []\n",
    "    for shape in shapes:\n",
    "        if len(shape) == 2:\n",
    "            shape = condenseShape(shape, scomplex)\n",
    "            cleanShapes.append([shape])\n",
    "        else:\n",
    "            cleanShapes.append(shape)\n",
    "    return cleanShapes\n",
    "\n",
    "\n",
    "def append_states(scomplex, shape, df):\n",
    "    for maximum in scomplex['maxima']:\n",
    "        entries = [0 for x in range(df.shape[0])]\n",
    "        for node in scomplex['states'][maximum]:\n",
    "            for entry in scomplex['nodes'][node]:\n",
    "                entries[entry] = 1\n",
    "        df[maximum] = entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d479aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Data\\water_full.csv\")\n",
    "continuous_variables = [\"WDP\", \"SECCHI\", \"TEMP\", \"DO\", \"TURB\", \"VEL\", \"TP\", \"TN\", \"SS\", \"CHLcal\"]\n",
    "#df = df[df['FLDNUM']=='Havana, IL']\n",
    "df_years = df.copy()\n",
    "df = df[continuous_variables]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df_years.reset_index(drop = True, inplace = True)\n",
    "stratum = {'Main channel' : 1, 'Side channel' : 2, 'Backwater area contiguous to the main channel' : 3}\n",
    "df_years = df_years.replace({\"STRATUM\" : stratum})\n",
    "k = int(df.shape[0] / 10) + 1\n",
    "\n",
    "epsilons = {'River' : 1.2, 'LaGrange' : 1.75, 'Doug' : 2.3}\n",
    "cubes = {'River' : [125,125], 'LaGrange' : [88,38]}\n",
    "\n",
    "scomplex = generate_scomplex(df, epsilon = epsilons['LaGrange'],\n",
    "                             min_samples = 20, n_cubes = cubes['LaGrange'], perc_overlap = [0.40,0.40])\n",
    "scomplex['density'] = {}\n",
    "largestShape = clean_getShapes(scomplex)[0]\n",
    "print(\"Number of Nodes in Largest Shape: \", len(largestShape))\n",
    "i = 1\n",
    "X = pd.DataFrame(RobustScaler().fit_transform(df))\n",
    "for node in largestShape:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    scomplex['density'][node] = calculate_density(scomplex, node, X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09848ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scomplex['graph'] = generate_graph(scomplex, largestShape)\n",
    "scomplex['maxima'] = get_local_maxima(scomplex['graph'])\n",
    "print(\"Number of Maxima: \", len(scomplex['maxima']))\n",
    "filepath =  r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Mapper\\LaGrange\\States.png\"\n",
    "draw_graph(scomplex, filepath, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Mapper\\LaGrange\\States.html\"\n",
    "append_states(scomplex, largestShape, df)\n",
    "visualize_by_state(scomplex, df, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scomplex['maxima']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state1 = df[df['cube41_cluster0']==1]\n",
    "#state2 = df[df['cube48_cluster0']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333261ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#var = 'VEL'\n",
    "#my_dict = {'State 1 ': state1[var], 'State 2 ': state2[var]}\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.boxplot(my_dict.values())\n",
    "#ax.set_xticklabels(my_dict.keys())\n",
    "#plt.rc('font', size=20)\n",
    "#plt.savefig(r\"C:\\Users\\killiad\\Documents\\Senior\\REU\\Mapper\\LaGrange\\boxplot_VEL.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d33d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
