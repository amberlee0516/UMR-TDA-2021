{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8917a773-86a7-4a3b-8663-2a006d34eac4",
   "metadata": {},
   "source": [
    "# Forrest TDA mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f88b7094-878b-4e95-b2a2-d732a252abb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports\n"
     ]
    }
   ],
   "source": [
    "import kmapper as km\n",
    "from kmapper.plotlyviz import *\n",
    "import sklearn\n",
    "#from sklearn import ensemble\n",
    "# DBSCAN from sklearn for clustering algorithms\n",
    "from sklearn.cluster import DBSCAN\n",
    "# PCA from sklearn for projection/lens creation\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import MDS\n",
    "# scipy for interpolation\n",
    "# import scipy \n",
    "# from scipy.interpolate import *\n",
    "# Plotly and Dash\n",
    "import plotly.graph_objs as go\n",
    "from kmapper.plotlyviz import plotlyviz\n",
    "from kmapper.plotlyviz import *\n",
    "from ipywidgets import (HBox, VBox)\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash\n",
    "from ipywidgets import interactive, HBox, VBox, widgets, interact\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "print(\"Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb1e1a-9266-4d7d-a523-4e269ca59716",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "Time periods creation & obtaining the datasets for each time period and strata and season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3764fa8-b9ad-4c5c-bc48-880213a503bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non empty strata are:  [1, 2, 3, 4, 5]\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "predicted_df = pd.read_csv(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\interpolatedPool26.csv\")\n",
    "### Creating three main time spans and two overlapping time spans,\n",
    "### a total of five time spans\n",
    "\n",
    "# defining different time periods\n",
    "# first decade\n",
    "time_dec1 = [1993, 1994, 1995, 1997, 1998, 1999, 2000]\n",
    "# second decade\n",
    "time_dec2 = [2001, 2002,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]\n",
    "# third decade\n",
    "time_dec3 = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# overlap time periods for continuity\n",
    "time_overlap1 = [1998, 1999, 2000, 2001, 2002,2003, 2004]\n",
    "time_overlap2 = [2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "time_list = [time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "\n",
    "time_list_names = ['93-00', '98-04', '01-13', '10-16', '14-20']        \n",
    "time_list =[time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "stratum_list = [1, 2, 3, 4, 5, 6, 7, 9]\n",
    "Season_names = [\"SUMMER\"] # can add other seasons later\n",
    "\n",
    "nonempty_stratum = []\n",
    "for i in stratum_list:\n",
    "    if predicted_df[predicted_df['STRATUM'] == i].shape[0]!=0:\n",
    "        nonempty_stratum.append(i)\n",
    "print(\"Non empty strata are: \",nonempty_stratum) \n",
    "\n",
    "\n",
    "df_stratum_season_time_dict_list = []\n",
    "df_stratum_season_time_dict = {}\n",
    "s=\"\"\n",
    "\n",
    "for i in range(len(time_list)): # for every time period\n",
    "    for j in nonempty_stratum: # for every strata\n",
    "        for k in Season_names: # for every season\n",
    "            s=str(\"Stratum \") + str(j)+ \" \" + k + \" \" + time_list_names[i] + str(\": \")\n",
    "            df_stratum_season_time_dict[s] = predicted_df[(predicted_df['YEAR'].isin(time_list[i])) &\n",
    "                                                             (predicted_df['STRATUM'].isin([j])) & \n",
    "                                                             (predicted_df['SEASON'].isin([k]))]\n",
    "            df_stratum_season_time_dict_list.append(df_stratum_season_time_dict)\n",
    "            df_stratum_season_time_dict = {}\n",
    "            # obtain the subdata frame for the year set, strata, and season. Places that in a list\n",
    "            s=\"\"\n",
    "print(len(df_stratum_season_time_dict_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77186cb1-21a4-405d-bed1-f66fe0b66405",
   "metadata": {},
   "source": [
    "# TDA mapper function and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1107ac8-fcb6-4248-a0a9-4f8656dd993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "def cluster_fun(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [10,10], PERC_OVERLAP = [.35,.35]):\n",
    "    \"\"\"\n",
    "    How to cluster the data\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    keys = list(dict_df.keys())\n",
    "    print(keys)\n",
    "    X = dict_df.get(keys[0]) # The dataset\n",
    "    X = X[[\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\",\"PREDICTED_COND\", \"PREDICTED_VEL\", \"PREDICTED_TP\", \n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]] # obtaining only the continuous variables\n",
    "    if X.shape[0]<DBSCAN_MIN_SAMPLES: # makes sure there is enough data\n",
    "        #print(X)\n",
    "        print(\"Not enough data to cluster in \", keys, \"_size = \", X.shape[0])\n",
    "        print(\"DBSCAN_MIN_SAMPLES\", DBSCAN_MIN_SAMPLES)\n",
    "        return([DBSCAN_MIN_SAMPLES, X.shape[0]])\n",
    "    \n",
    "    \n",
    "    db = DBSCAN(eps=20, min_samples=2).fit(X) # does the DBSCAN algorithm and fits it to the data\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0) # number of clusters\n",
    "    n_noise_ = list(labels).count(-1) # number of 0/1-simplices\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    \n",
    "    return(db)\n",
    "\n",
    "    \n",
    "    \n",
    "def mapper_func(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [10,10], PERC_OVERLAP = [.25,.25]):\n",
    "    \"\"\"\n",
    "    str(df_stratum_season_time_dict_list[1].keys())\n",
    "    \"\"\"\n",
    "    \n",
    "    # grab dataset\n",
    "    keys = list(dict_df.keys())\n",
    "    print(keys)\n",
    "    X = dict_df.get(keys[0])\n",
    "    X = X[[\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\",\"PREDICTED_COND\", \"PREDICTED_VEL\", \"PREDICTED_TP\", \n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]] \n",
    "    \n",
    "    if X.shape[0]<10:\n",
    "        #print(X)\n",
    "        print(\"Not enough data in \", keys, \"_size = \", X.shape[0])\n",
    "        return(X.shape[0])\n",
    "\n",
    "    \n",
    "    # create instance of clustering alg\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps=DBSCAN_EPSILON, min_samples=DBSCAN_MIN_SAMPLES, metric='euclidean')\n",
    "\n",
    "    # Instantiate kepler mapper object\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "    # defining filter function as projection on to the first 2 component axis\n",
    "    pca = PCA(n_components=2) # set to 1 for now \n",
    "    lens = pca.fit_transform(X)\n",
    "    print(\"The pca explained variance is: \",pca.explained_variance_ratio_)\n",
    "    \n",
    "    # Generate the simplicial complex\n",
    "    scomplex = mapper.map(lens, X, cover=km.Cover(n_cubes=N_CUBES, perc_overlap=PERC_OVERLAP), clusterer=cluster_alg)  \n",
    "    \n",
    "    \n",
    "    pl_brewer = [[0.0, '#006837'],\n",
    "             [0.1, '#1a9850'],\n",
    "             [0.2, '#66bd63'],\n",
    "             [0.3, '#a6d96a'],\n",
    "             [0.4, '#d9ef8b'],\n",
    "             [0.5, '#ffffbf'],\n",
    "             [0.6, '#fee08b'],\n",
    "             [0.7, '#fdae61'],\n",
    "             [0.8, '#f46d43'],\n",
    "             [0.9, '#d73027'],\n",
    "             [1.0, '#a50026']]\n",
    "    color_function_name = ['Distance to x-min']\n",
    "    color_values = lens [:,0] - lens[:,0].min()\n",
    "    my_colorscale = pl_brewer\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                     color_values,  \n",
    "                                                                     color_function_name='Distance to x-min', \n",
    "                                                                     colorscale=my_colorscale)\n",
    "\n",
    "    bgcolor = 'rgba(10,10,10, 0.9)'\n",
    "    # y_gridcolor = 'rgb(150,150,150)'# on a black background the gridlines are set on  grey\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout='fr', colorscale=my_colorscale, \n",
    "                                     factor_size=2.5, edge_linewidth=0.5)\n",
    "    plot_title = str(keys[0]) + str(DBSCAN_EPSILON) + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    # plot_title = 'Pool 13, Summer 1993-1999; Epsilon ' + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    layout = plot_layout(title=plot_title,  \n",
    "                         width=620, height=570,\n",
    "                         annotation_text=get_kmgraph_meta(mapper_summary),  \n",
    "                         bgcolor=bgcolor)\n",
    "\n",
    "    # FigureWidget is responsible for event listeners\n",
    "\n",
    "    fw_graph = go.FigureWidget(data=plotly_graph_data, layout=layout)\n",
    "    fw_hist = node_hist_fig(colorf_distribution, bgcolor=bgcolor)\n",
    "    fw_summary = summary_fig(mapper_summary, height=300)\n",
    "\n",
    "    dashboard = hovering_widgets(kmgraph, \n",
    "                                 fw_graph, \n",
    "                                 bgcolor=bgcolor, \n",
    "                                 member_textbox_width=600)\n",
    "\n",
    "    # DESIRED FILE PATH, CHANGE TO FIT YOUR LOCAL MACHINE\n",
    "    \n",
    "    directory_path = \"Users\\\\forre\\\\Desktop\\\\REU\\\\TDA\\\\Data\\\\Test\" # test output\n",
    "    html_output_path = directory_path + \"\\\\\" + str(keys[0]) + 'PCA_2' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES) + 'PEROvLp_' + str(PERC_OVERLAP) + '.html'\n",
    "    html_output_path = html_output_path.replace(\" \",\"-\")\n",
    "    html_output_path = html_output_path.replace(\":\",\"_\")\n",
    "    html_output_path = \"C:\\\\\"+html_output_path\n",
    "    #print(html_output_path)\n",
    "    mapper.visualize(scomplex, color_values = color_values, color_function_name = color_function_name, path_html=html_output_path)\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    fw_graph.data[1].marker.colorbar.title = 'dist to<br>x-min'\n",
    "    return(scomplex)\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6841651-25bf-4e83-8ffd-f9551542ca30",
   "metadata": {},
   "source": [
    "PCA 2 would be ideal since it is able to explain ~ 85% <br>\n",
    "Challenge with this introduces a lot more nodes and edges. So, how do we minimize that? <br>\n",
    "One way to is to play with the number in `perc_overlap`. The other one is try to collapse them after the fact. After the TDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c1be21d-c22a-4686-8fec-e28127311d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stratum 1 SUMMER 93-00: ']\n",
      "The pca explained variance is:  [0.65968257 0.20580024]\n",
      "['Stratum 2 SUMMER 93-00: ']\n",
      "The pca explained variance is:  [0.58092376 0.30652974]\n",
      "['Stratum 3 SUMMER 93-00: ']\n",
      "The pca explained variance is:  [0.5911372  0.31285556]\n",
      "['Stratum 4 SUMMER 93-00: ']\n",
      "The pca explained variance is:  [0.60086965 0.28198494]\n",
      "['Stratum 5 SUMMER 93-00: ']\n",
      "The pca explained variance is:  [0.66505294 0.17443502]\n",
      "['Stratum 1 SUMMER 98-04: ']\n",
      "The pca explained variance is:  [0.62999262 0.24288759]\n",
      "['Stratum 2 SUMMER 98-04: ']\n",
      "The pca explained variance is:  [0.53269787 0.27536347]\n",
      "['Stratum 3 SUMMER 98-04: ']\n",
      "The pca explained variance is:  [0.55155719 0.36610169]\n",
      "['Stratum 4 SUMMER 98-04: ']\n",
      "The pca explained variance is:  [0.59793361 0.35478416]\n",
      "['Stratum 5 SUMMER 98-04: ']\n",
      "The pca explained variance is:  [0.80040225 0.1121895 ]\n",
      "['Stratum 1 SUMMER 01-13: ']\n",
      "The pca explained variance is:  [0.56220989 0.37379344]\n",
      "['Stratum 2 SUMMER 01-13: ']\n",
      "The pca explained variance is:  [0.6414958  0.28121554]\n",
      "['Stratum 3 SUMMER 01-13: ']\n",
      "The pca explained variance is:  [0.55293874 0.34880022]\n",
      "['Stratum 4 SUMMER 01-13: ']\n",
      "The pca explained variance is:  [0.74495171 0.18861008]\n",
      "['Stratum 5 SUMMER 01-13: ']\n",
      "The pca explained variance is:  [0.6248529  0.21179486]\n",
      "['Stratum 1 SUMMER 10-16: ']\n",
      "The pca explained variance is:  [0.68377271 0.28991114]\n",
      "['Stratum 2 SUMMER 10-16: ']\n",
      "The pca explained variance is:  [0.64000559 0.33526415]\n",
      "['Stratum 3 SUMMER 10-16: ']\n",
      "The pca explained variance is:  [0.47336043 0.42077443]\n",
      "['Stratum 4 SUMMER 10-16: ']\n",
      "The pca explained variance is:  [0.7257381  0.23630766]\n",
      "['Stratum 5 SUMMER 10-16: ']\n",
      "The pca explained variance is:  [0.55082509 0.31348669]\n",
      "['Stratum 1 SUMMER 14-20: ']\n",
      "The pca explained variance is:  [0.72087579 0.22165965]\n",
      "['Stratum 2 SUMMER 14-20: ']\n",
      "The pca explained variance is:  [0.67490777 0.27357306]\n",
      "['Stratum 3 SUMMER 14-20: ']\n",
      "The pca explained variance is:  [0.64871952 0.29576991]\n",
      "['Stratum 4 SUMMER 14-20: ']\n",
      "The pca explained variance is:  [0.93023435 0.04110101]\n",
      "['Stratum 5 SUMMER 14-20: ']\n",
      "The pca explained variance is:  [0.54785842 0.24134166]\n"
     ]
    }
   ],
   "source": [
    "# def mapper_func(dict_df, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [7,7], PERC_OVERLAP = [.5,.5]):\n",
    "# N_cubes = [5,10,15], PERC_OVERLAP = [.35,.45,.55]\n",
    "mapper_output_dict = {}\n",
    "for i in df_stratum_season_time_dict_list:\n",
    "        mapper_output_dict[str(list(i.keys()))] = mapper_func(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c6587-eb47-44f8-b240-6fd76522081b",
   "metadata": {},
   "source": [
    "# `.json` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae883ec-eb42-4622-a553-d4fad2fc9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "json = json.dumps(mapper_pca_output_dict)\n",
    "f = open(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\NAMEFILEHERE.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
