{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "harmful-display",
   "metadata": {},
   "source": [
    "# Simplicial Complex Analysis\n",
    "\n",
    "<span style='color:Red'>TODO: Generate box plots for the entire shape (on each stat) as well as the box plots for each shape on the nodes.</span> <br>\n",
    "<span style='color:Red'> Currently using the largest number of nodes in each shape. </span> <br> \n",
    "Written by Frederick Miller, Casey McKean, and Wako Bungula. <br>\n",
    "The kepler mapper object gives an output that is not easily navigatible. To resolve this, we wish to create shapes that are easier to navigate and understand, and reveal the data inside of them. <br>\n",
    "We generate all the shapes in the simplicial complex, condense 1-simplices where possible, and obtain summary statistics on the shapes and the nodes within the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjacent-chuck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import queue\n",
    "import animation\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)\n",
    "import pickle\n",
    "print(\"Imports Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-holmes",
   "metadata": {},
   "source": [
    "# File paths, `.p`, and `.json` import\n",
    "\n",
    "From the `kmapper_demo` file, I added one extra code block to place the resulting simplicial complices in a `.json` file, which is a way to store dictionaries in long term storage. Additionally, it stores the dictionary of dataframes in a `.p` file, which is similar. The code below only needs to have the file paths changed, and then it will read the simplicial complices generated from kepler mapper. <br>\n",
    "Here, we also import the actual data set, with data interpolated for the specific pool. <br>\n",
    "Lastly, a list of the 11 continuous variables (the interpolated versions) is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stupid-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Json file imported\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "jsonFilePath = r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\TDA1PCA10Cubes30perc_complices.json\"\n",
    "jsonFile = open(jsonFilePath, \"r\")\n",
    "jsonData = json.load(jsonFile) \n",
    "jsonFile.close()\n",
    "\n",
    "dataFilePath = r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\TDA1PCA10Cubes30perc_dfs.p\"\n",
    "df_dict = pickle.load(open(dataFilePath, \"rb\"))\n",
    "\n",
    "variables = [\"PredictedWDP\", \"PredictedSECCHI\", \"PredictedTEMP\", \"PredictedDO\", \n",
    "           \"PredictedTURB\", \"PredictedVEL\", \"PredictedTP\", #\"PREDICTED_COND\",\n",
    "           \"PredictedTN\", \"PredictedSS\", \"PredictedCHLcal\"]\n",
    "\n",
    "variables = [\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\", \"PREDICTED_VEL\", \"PREDICTED_TP\", #\"PREDICTED_COND\",\n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Json file imported\")\n",
    "\n",
    "print(len(jsonData.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-estate",
   "metadata": {},
   "source": [
    "# Functions\n",
    "See the `docstring`'s for what each function does and how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absent-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions loaded\n"
     ]
    }
   ],
   "source": [
    "def getSubdf(scomplex, shape, df):\n",
    "    \"\"\"\n",
    "    Returns the part of the data frame from the particular shape in the simplicial complex.\n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    shape: the particular shape being inspected (within the simplicial complex)\n",
    "    df: the entire data frame\n",
    "    \n",
    "    Description:\n",
    "    1. Get all the nodes from the particular simplicial complex. \n",
    "    2. Generate the indices we care about from the particular shape. To do this, we read each node and append it's \n",
    "    indices to a list. Then, we convert the list to a set and then back to a list to eliminate duplicates.\n",
    "    3. Return the dataframe with only those indices.\n",
    "    \"\"\"\n",
    "    nodes = scomplex.get('nodes')\n",
    "    indices = []\n",
    "    npShape = np.array(shape).flatten()\n",
    "    for node in npShape:\n",
    "        indices.append(nodes.get(node))\n",
    "    indices = list(set([item for sublist in indices for item in sublist]))\n",
    "    subdf = df.loc[indices]\n",
    "    return subdf\n",
    "\n",
    "def shapeDataSummary(scomplex, shape, df, variables, verbose = False):\n",
    "    \"\"\"\n",
    "    Generates summary statistics of the given variables for a given shape in the simplicial.\n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    shape: the particular shape being inspected (within the simplicial complex) at this function call.\n",
    "    df: the entire dataframe\n",
    "    variables: the variables of interest\n",
    "    verbose: Determines if the function will print out extra information. False by default\n",
    "    \n",
    "    Description:\n",
    "    1. Create an empty result dataframe to store the summary statistics.\n",
    "    2. Get the sub dataframe (see getSubdf) for the particular shape\n",
    "    3. For each variable we are analzying, generate summary statistics from the sub dataframe and place them\n",
    "    inside the result dataframe.\n",
    "    4. Return the result dataframe\n",
    "    \n",
    "    NOTE: this only creates summaries for one particular shape. In executing this method, it is done for each shape \n",
    "    outside of the function.\n",
    "    \n",
    "    \"\"\"\n",
    "    result = pd.DataFrame()\n",
    "    if verbose == True:\n",
    "        print(\"Obtaining sub dataframe for: \", shape)\n",
    "        print(\"The number of nodes in this shape is: \", len(shape))\n",
    "    subdf = getSubdf(scomplex, shape, df)\n",
    "    if verbose == True:\n",
    "        print(\"The number of datapoints in this shape is: \", subdf.shape[0])\n",
    "    for var in variables:\n",
    "        result[var] = subdf[var].describe()\n",
    "    return result\n",
    "    \n",
    "    \n",
    "\n",
    "def adjacent(v, scomplex):\n",
    "    \"\"\"\n",
    "    Determines the nodes adjacent to a given vertex\n",
    "    \n",
    "    params:\n",
    "    v: vertex\n",
    "    scomlex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    Determines the nodes that are adjacent to a given vertex.\n",
    "    \"\"\"\n",
    "    \n",
    "    simplices = scomplex.get('simplices')\n",
    "    edges = [item for item in simplices if len(item) == 2]\n",
    "    result = []\n",
    "    for edge in edges:\n",
    "        if v in edge:\n",
    "            for item in edge:\n",
    "                if item != v:\n",
    "                    result.append(item)\n",
    "    return result\n",
    "\n",
    "def bfs(node, scomplex):\n",
    "    \"\"\"\n",
    "    Conducts a breadth first search to obtain the entire shape from a given node\n",
    "    params:\n",
    "    node: the start node\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    Preforms a breadth first search to obtain the entire shape for a given start node.\n",
    "    \"\"\"\n",
    "    Q = queue.Queue()\n",
    "    result = []\n",
    "    result.append(node)\n",
    "    Q.put(node)\n",
    "    while not Q.empty():\n",
    "        v = Q.get()\n",
    "        adjacentEdges = adjacent(v, scomplex)\n",
    "        for edge in adjacentEdges:\n",
    "            if edge not in result:\n",
    "                result.append(edge)\n",
    "                Q.put(edge)\n",
    "    return result\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "def getShapes(scomplex):\n",
    "    \"\"\"\n",
    "    Gets all of the shapes from a given simplicial complex.\n",
    "    \n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    1. Obtain all the nodes for the entire complex\n",
    "    2. For each node, preform a breadth first search to obtain everything in that particular shape. \n",
    "    If this entire shape has not already been discovered, add it to the set of results. \n",
    "    The result item is a set as the order of the shapes does not matter. The resulting shape is a frozenset\n",
    "    which means items cannot be added or removed once created, and is needed to allow the set object to have other sets within it.\n",
    "    3. Convert each shape to a list and the result to a list for easier navigation outside of the function.\n",
    "    4. Return the result\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = list(scomplex.get('nodes').keys())\n",
    "    result = set()\n",
    "    for node in nodes: # currently does more computations than necessary due to going through every node without considering it is already in a shape\n",
    "        bfsResult = frozenset(bfs(node, scomplex))\n",
    "        result.add(bfsResult)\n",
    "    result = [list(x) for x in result]\n",
    "    # Sort the list depending on what is decided: nodes or indices. Currently doing it by number of nodes\n",
    "    result.sort(key = len, reverse = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "def nodeDataSummary(node, scomplex, variables,df):\n",
    "    \"\"\"\n",
    "    Returns a data summary of a particular node\n",
    "    params:\n",
    "    node: node in question\n",
    "    scomplex: The entire simplicial complex\n",
    "    variables: The variables to obtain summaries\n",
    "    df: the entire dataframe \n",
    "    \n",
    "    description:\n",
    "    1. Creates a result dataframe\n",
    "    2. Get all the indices from the node from the simplicial complex\n",
    "    3. Generate summaries for each variable\n",
    "    4. Return the result\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame()\n",
    "    indices = scomplex.get('nodes').get(node)\n",
    "    subdf = df.loc[indices]\n",
    "    for var in variables:\n",
    "        result[var] = subdf[var].describe()\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def condenseShape(shape, scomplex):\n",
    "    \"\"\"\n",
    "    \n",
    "    params:\n",
    "    shape: a shape of two nodes. must be 2\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    description:\n",
    "    gets the two nodes a and b\n",
    "    gets the indices for a and b (what is inside the nodes)\n",
    "    if a \\subseteq b, return b\n",
    "    elif b \\subseteq a, return a \n",
    "    else return shape \n",
    "    \n",
    "    \"\"\"\n",
    "    nodes = scomplex.get('nodes')\n",
    "    a = shape[0]\n",
    "    b = shape[1]\n",
    "    aIndices = set(nodes.get(a))\n",
    "    bIndices = set(nodes.get(b))\n",
    "    \n",
    "    if aIndices.issubset(bIndices):\n",
    "        return b\n",
    "    elif bIndices.issubset(aIndices):\n",
    "        return a\n",
    "    else:\n",
    "        return shape\n",
    "\n",
    "def clean_getShapes(scomplex):\n",
    "    \"\"\"\n",
    "    Condenses 1-simplices down to 0-simplices when each node \n",
    "    is a subset of the other \n",
    "    \n",
    "    params:\n",
    "    scomplex: the entire simplicial complex\n",
    "    \n",
    "    Description:\n",
    "    1. Get all the shapes from the original getShapes function\n",
    "    2. For shapes that of length 2, if one is a subset of the other, return the larger of the two\n",
    "        Otherwise, do nothing\n",
    "    3. return the clean Shapes list \n",
    "    \n",
    "    \"\"\"\n",
    "    shapes = getShapes(scomplex)\n",
    "    cleanShapes = []\n",
    "    for shape in shapes:\n",
    "        if len(shape) == 2:\n",
    "            shape = condenseShape(shape, scomplex)\n",
    "            cleanShapes.append([shape])\n",
    "        else:\n",
    "            cleanShapes.append(shape)\n",
    "    return cleanShapes\n",
    "\n",
    "\n",
    "def getBoxplots(subdf, shape, key,filePath):\n",
    "    \"\"\"\n",
    "    Generates box plots for 10 of the 11 continuous variables\n",
    "    NOTE: CONDUCTIVITY IS NOT INCLUDED\n",
    "    \n",
    "    params:\n",
    "    subdf: the sub dataframe of the particular shape\n",
    "    shape: the shape in question\n",
    "    key: what strata year season combo we are looking at \n",
    "    filePath: the output file path for all the box plots \n",
    "    \n",
    "    description:\n",
    "    clears the current plot \n",
    "    generates the sub dataframes for the respective variables.\n",
    "    the reason they are grouped is based upon the numerical outputs for making the boxplots readable\n",
    "    create a box plot, and then save it based upon the file path\n",
    "    clear the plot\n",
    "    repeat for the second set of variables\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    varDf1 = subdf[[\"PREDICTED_SS\",\"PREDICTED_TURB\",\"PREDICTED_CHLcal\"]]\n",
    "    varDf2 = subdf[[\"PREDICTED_TP\",\"PREDICTED_TN\",\"PREDICTED_TEMP\",\"PREDICTED_DO\",\"PREDICTED_VEL\",\"PREDICTED_WDP\",\n",
    "                  \"PREDICTED_SECCHI\"]]\n",
    "    plot1 = varDf1.boxplot()\n",
    "    plt.savefig(filePath + \"\\\\\" + key +\"_\" + str(shape)  + \"_SS_TURB_CHLcal\"  + \".png\")\n",
    "    plt.clf()\n",
    "    plot2 = varDf2.boxplot(rot = 45)\n",
    "    plt.savefig(filePath + \"\\\\\" + key +\"_\" + str(shape)  + \"_\" + \"TP_TN_TEMP_etc\" + \".png\")\n",
    "    return plot1, plot2\n",
    "print(\"Functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-processing",
   "metadata": {},
   "source": [
    "# Generating Summary Statistics on the entire simplicial complex\n",
    "For each `mapper` output from `kepler-mapper`, we can generate the summary statistics for each of the continuous variables. This is done by first obtaining a list of the keys from the `.json` file, and then iterating through each complex, generating the shape and obtaining data summaries on each shape."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "9b125a72-c484-45ed-a304-0028003907f4",
=======
   "execution_count": 4,
   "id": "civilian-musician",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "allComplices = list(jsonData.keys())\n",
    "for key in allComplices: # remove indices here to get all the strata for all the time periods\n",
    "    print(\"Current Simplical Complex: \", key)\n",
    "    scomplex = jsonData.get(key)\n",
    "    shapes = clean_getShapes(scomplex)\n",
    "    for shape in shapes:\n",
    "        summaries = shapeDataSummary(scomplex, shape, df_dict.get(key), variables, verbose = False)\n",
    "        if summaries.loc['count'][0] > 5 and len(shape)  > 2: # at least 6 datapoints and 3 nodes to see info\n",
    "            print(\"The shape is: \",shape)\n",
    "            print(\"The number of nodes in the shape is: \", len(shape))\n",
    "            display(summaries) # Uncomment to see summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-chorus",
   "metadata": {},
   "source": [
    "# Analyzing the largest structure\n",
    "Largest = Node count of the shape. The largest structure is likely to be the dominant feature of the stratum during this particular time period. As such, it is important to analyze the nodes within it. To do this, we generate all the shapes, and since the shapes are returned in descending order of the number of nodes per shape, we pull the first shape. From here, we can preform an analysis on each one."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "b26adfc0-e51d-41bc-a1a4-ceeac2603a91",
=======
   "execution_count": 5,
   "id": "talented-tuesday",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "allComplices = list(jsonData.keys())\n",
    "for key in allComplices[0:3]: # remove the indices here to get all the strata for all the time periods\n",
    "    print(\"Current Simplical Complex: \", key)\n",
    "    scomplex = jsonData.get(key)\n",
    "    largestShape = clean_getShapes(scomplex)[0]\n",
    "    nodes = scomplex.get('nodes')\n",
    "    print(\"Largest shape is: \", largestShape)\n",
    "    print(\"Number of nodes is: \", len(largestShape))\n",
    "    for node in largestShape:\n",
    "        summary = nodeDataSummary(node, scomplex,variables,df_dict.get(key))\n",
    "        if summary.loc['count'][0] > 5: # 5 is chosen arbitraily\n",
    "            print(\"Information for: \", node)\n",
    "            display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-detective",
   "metadata": {},
   "source": [
    "# Condensing 1-simplices\n",
    "Currently, many one simplices that we have contain information that means one of them is a subset of the other. To resolve this, we replace them with one cluster with all the indices in one node.\n",
    "\n",
    "This is stored in the function `clean_getShapes(scomplex)` function. Below is a comparison of running the two functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "8281a652-07ae-4846-b5e9-29e87be93a78",
=======
   "execution_count": 6,
   "id": "ahead-cattle",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "allComplices = list(jsonData.keys())\n",
    "print(\"Standard shape version\")\n",
    "for key in allComplices[0:1]:\n",
    "    print(\"Current Simplical Complex: \", key)\n",
    "    scomplex = jsonData.get(key)\n",
    "    nodes = scomplex.get('nodes')\n",
    "    shapes = getShapes(scomplex)\n",
    "    for shape in shapes:\n",
    "        indices = []\n",
    "        for node in shape:\n",
    "            indices.append(nodes.get(node))\n",
    "        indices = list(set([item for sublist in indices for item in sublist]))\n",
    "        print(str(shape) + \" : \" + str(indices))\n",
    "\n",
    "print(\"Clean shape version\")\n",
    "for key in allComplices[0:1]:\n",
    "    print(\"Current Simplical Complex: \", key)\n",
    "    scomplex = jsonData.get(key)\n",
    "    nodes = scomplex.get('nodes')\n",
    "    cleanShapes = clean_getShapes(scomplex)\n",
    "    for shape in cleanShapes:\n",
    "        indices = []\n",
    "        npShape = np.array(shape).flatten()\n",
    "        for node in npShape:\n",
    "            indices.append(nodes.get(node))\n",
    "        indices = list(set([item for sublist in indices for item in sublist]))\n",
    "        print(str(shape) + \" : \" + str(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-feedback",
   "metadata": {},
   "source": [
    "# Box plot per shape\n",
    "Here, we generate box plots for the variables of interest. for each shape in the simplicial complex <br>\n",
    "TODO: Plot output ideas: <br>\n",
    "SS, Turb, CHLCal <br>\n",
    "Vel, TN, TP <br>\n",
    "Temp, DO, SECCHI <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "allComplices = list(jsonData.keys())\n",
    "for key in allComplices[0:1]: # remove the indices here to get all the strata for all the time periods\n",
    "    print(\"Current Simplical Complex: \", key)\n",
    "    scomplex = jsonData.get(key)\n",
    "    shapes = clean_getShapes(scomplex)\n",
    "    print(\"number of shapes: \", len(shapes))\n",
    "    for shape in shapes:\n",
    "        \"\"\"\n",
    "        Hello whoever is using this function\n",
    "        getBoxplots takes a couple arguments. \n",
    "        the big thing that matters here is the \n",
    "        strataYear variable. Essentially, the key that allows us to access each simplicial complex is weird.\n",
    "        Depending on your file system, using the str(key) conversion may cause errors. to resolve this, \n",
    "        below is a potential example. Feel free to change it as you go for your use.\n",
    "        \"\"\"\n",
    "        strataYear = str(key).replace(\" \",\"-\").replace(\":\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\")\n",
    "        print(strataYear)\n",
    "        \"\"\"\n",
    "        before: \n",
    "        ['Stratum 1 SUMMER 93-00: ']\n",
    "        after:\n",
    "        Stratum-1-SUMMER-93-00-\n",
    "        \"\"\"\n",
    "        subdf = getSubdf(scomplex, shape, df_dict.get(key))\n",
    "        plots = getBoxplots(subdf, shape, strataYear,  \n",
    "                            filePath = r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\TDAOutputs\\Boxplots\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820b1b7-4c9f-4ee4-9916-0bea6e968876",
   "metadata": {},
   "source": [
    "# Discovering which indices within the nodes overlap\n",
    "This code will determine what points in the nodes are overlapping within two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b727b-a4ff-44a3-9f19-3985f65bf117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17d78975-dbbf-41da-a4ce-922b3a6df1d9",
   "metadata": {},
   "source": [
    "# See compare shapes over the years\n",
    "NOTE: Comparing the largest shape in each."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
