---
title: "Filtering water quality dataset"
author: "Amber Lee"
date: "6/15/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Unfinished

Is it okay if, after filtering/processing the original data, we only have 105,267 rows? We are only keeping about half of the original data...

## Summary

One important goal before we interpolate missing values is to filter the data, to decide on the scope of our analysis. Filtering the data to what is necessary will also reduce the amount of interpolation needed. We will see that removing duplicate rows will greatly reduce the missing values (that aren't actually missing), thus making the interpolation step significantly easier. 

In cleaning the LTRM Water Quality dataset, we encounter the following questions:

* Which variables (columns) are the most important for us to keep (out of the 133 total variables)?

* Why do duplicate rows happen, and how do we deal with them?

* Which samples (rows) are high enough quality for us to keep? (This involves the QF codes.)


The LTRM Water Quality dataset has duplicate rows for the same `SHEETBAR`, which is problematic because `SHEETBAR` is a unique identifier for a water data sheet (sample at a date, time, and location). 


```{r}
library(tidyverse)
library(ggplot2)
library(lubridate)
library(corrplot)
library(RColorBrewer)
library(kableExtra)
```

```{r}
# set working directory to source file location
# setwd("~/Documents/GitHub/UMR-TDA-2021") 

water20 <- read.csv(file = "../LTRM data/ltrm_water_data_lat_long.csv")
```

## Important variables

```{r}

water_var <- c('TN','TP','TEMP','DO','TURB',
               'COND','VEL','SS','WDP','CHLcal','SECCHI')

waterQF_var <- paste(water_var, "QF", sep = "")

identifier_var <- c('SHEETBAR', 'DATE', 'LATITUDE', 'LONGITUDE', 'FLDNUM', 'STRATUM', 'LOCATCD', 'SITETYPE')

```

We decided that the 11 continuous variables of importance were: total nitrogen, total phosphorous, temperature, dissolved oxygen, turbidity, water condition, velocity, suspended solids, water depth, chlorophyll-a, and Secchi distance. 

In addition, we will want to include the QA/QC codes, along with identifier variables like `SHEETBAR` and date. 

Lastly, we manually edit these variable strings because:

* The water depth variable is `WDP`, but the corresponding quality factor is `ZMAXQF` rather than `WDPQF`.

* `CHLcal`, calibrated fluorometric chlorophyll a, does not have a corresponding quality factor code. According to the metadata: "`CHLcal` is generated by calibration of fluorometric chlorophyll readings (`CHLF`) 
to season and year specific measurements of spectrophotometric chlorophyll  (`CHLS`). Data from sites where CHLS and CHLF are both collected 
are used to build river-specific calibration curves for these data. Values are corrected for pheophytin. Units are micrograms per liter.``

```{r}

waterQF_var <- waterQF_var[waterQF_var != "WDPQF" & 
                             waterQF_var != "CHLcalQF"]

waterQF_var <- c(waterQF_var, "ZMAXQF")

```


## Duplicate rows

There are `r dim(water20)[1]` total rows in the LTRM water quality dataset. Of these rows, there are `r dim(water20 %>% distinct(SHEETBAR))[1]` distinct `SHEETBAR` codes. 

We visualize duplicates as follows. To identify the duplicate rows, we count the number of occurences of each unique `SHEETBAR` value in the dataset. Then, we can calculate and plot the distribution of `SHEETBAR` duplicates. 

```{r}

duplicates <- water20 %>% 
  select(SHEETBAR) %>%
  group_by(SHEETBAR) %>%
  dplyr::summarize(count = n()) 

duplicates %>% head()

count_n_duplicates <- function(n, df) {
  return((df %>% filter(count == n) %>% dim())[1]/156474) #156k distinct sheetbars
}

count_duplicates <- data.frame(proportion = sapply(1:8, count_n_duplicates,
                                                   duplicates),
                               number_duplicates = 1:8)

ggplot(count_duplicates, aes(x = number_duplicates, y = proportion)) +
  geom_bar(stat = "identity") 

count_duplicates %>% kbl(booktabs = T) 

```

The proportion of `SHEETBAR`s with at least one duplicated row is`r 1 - count_duplicates$proportion[1]` (representing about 47,000 rows). When do duplicated rows occur?

We look at two `SHEETBAR`s with duplicated rows. 

```{r}

water20 %>% 
  filter(SHEETBAR == -4604347) %>% 
  select(SHEETBAR, Z, CALCZCD, DO, TP, TN) %>%
  kbl(booktabs = T) %>%
  kable_styling(latex_options = "striped")

```

```{r}

water20 %>% 
  filter(SHEETBAR == 41015929	) %>% 
  select(SHEETBAR, Z, CALCZCD, DO, TP, TN) %>%
  kbl(booktabs = T) %>%
  kable_styling(latex_options = "striped")

```

Here, we see that `TP` and `TN`, total phosphorous and total nitrogen, are measured only at the surface level (when `CALCZCD == "SF"`). The variable `CALCZCD` is a categorical variable with levels surface, middle, bottom, and other. It is calculated with the sample depth and the total water depth (of the river site). 

In contrast, dissolved oxygen `DO` is measured at various depths (denoted by `Z`) because different parts of the water column have different levels of `DO`. It would be inappropriate to average the dissolved oxygen levels because they were taken at different sample depths. 

Thus, this missing values of `TP` and `TN` are occuring at different sample depths at the same sampling site. These missing values aren't *really* missing values; they would be redundant to interpolate.

## We can reasonably keep only the samples taken at the surface level

We decided to filter for rows that were labelled as surface level,`CALCZCD == "SF"`. Implicitly, this filtering step removes samples for which the sample depth is missing.

```{r}
table(water20$CALCZCD)
```

More than 70% of the samples were taken on the surface level. Of these measurements taken at the surface level, the eleven important continuous variables (in `water_var`) were recorded with a recording rate of at least 50%. This is a good sanity check because `TN` and `TP` are never recorded in the middle and bottom water depths. we checked to see the recording rate of the eleven important variables and found recording rates greater than 50%. 

```{r}

filterwater <- water20 %>%
  filter(CALCZCD == "SF") %>%
  select(all_of(water_var))

sapply(filterwater, function(x) sum(is.na(x)/length(x)))

```

### What if CALCZCD is missing?

```{r}
(water20 %>%
  filter(CALCZCD == "") %>%
  dim())[1]
```

There are are about 8000 samples with missing `CALCZCD`. 

But this is okay because when `CALCZCD` is missing, nearly all of our continuous variables are missing too.

```{r}
sapply((water20 %>% 
  filter(CALCZCD == "") %>%
  select(all_of(water_var))), function(x) sum(is.na(x)/length(x)))
```
When `CALCZCD` isn't recorded, the rest of the variables aren't recorded. Since these samples represent `r round(8436/204305, digits = 3)` percent of the original data, we decide that it is okay to exclude these observations.

```{r}
water20 <- water20 %>% filter(CALCZCD == "SF")
```

We also will not be using any of the fixed sites for interpolation or TDA. We will remove these rows with the SITETYPE value '2'

```{r}
water20 <- water20 %>% filter(SITETYPE != 2)
```


## Water column variables

What is the difference between WDP, ZMAX, CALCZCD, SAMPZCD? (Could be answered later because not all these variables will be used in our analysis)

## Filter for QA/QC

[Explain the rules]

```{r}

badqf7 <- water20 %>% 
  filter_at(vars(c(TURBQF, TEMPQF, DOQF, VELQF, ZMAXQF,
                   SECCHIQF, CONDQF)),
            any_vars(. == "A" | . == "0"))
  
badqf3 <- water20 %>% 
  filter_at(vars(c(TNQF,TPQF,SSQF)), 
            any_vars(. == 8 | . == 64))

# These can be put in the same line
badqf <- rbind(badqf7, badqf3) 
badqf <- unique(badqf)

# If 


# take !badqf & water20

badqf %>%
  group_by(SHEETBAR) %>%
  dplyr::summarize(count = n()) %>%
  arrange(-count)


water20 %>%
  group_by(SHEETBAR) %>%
  dplyr::summarize(count = n()) %>%
  arrange(-count)

```

## Combine the rows that have the same SHEETBAR code
The purpose of this next component is to clean the current data set and remove the remaining rows with non-unique barcodes (SHEETBAR). This will be done by combining or "collapsing" the rows with he same barcode. While filtering for the samples taken at the surface of the river (CALCZCD == "SF") accounted for a majority of the rows with identical barcodes, there are still several rows that need to be removed.

It is important that our data sets consists only of unique barcodes because it removes issues when using interpolating the data and predicting our missing continuous variable values. Some of the TN and TP values that appear to be missing for a sample sites are in fact not missing and can be found in a different row of the data with the same sample site. In other words, if a missing value is actually just misplaced, there is no need to interpolate it. 

In each instance of multiple rows with the same SHEETBAR, there will be some combinations of sample and NA values for each continuous variable. Since our goal is combine it to combine the rows with the same SHEETBAR, we will find the average for each column, excluding the DATE, STRATUM, LOCATCD, LATITUDE and LONGITUDE columns.

The data set at this point should have already been filtered for the surface samples and bad QF codes.

```{r}
# Collapse the rows with the same SHEETBAR code
row_collapse <- function(data, water_var, identifier_var) {
  
# Count how many rows each sheetbar has
sheetbar_counts <- data %>%
  group_by(SHEETBAR) %>%
  dplyr::summarize(count = n()) %>%
  arrange(-count)

# Filter for the sheetbars that have multiple rows
sheetbar_dups <- sheetbar_counts %>% filter(count > 1)
data_dups <- data[data$SHEETBAR %in% sheetbar_dups$SHEETBAR, ]
#data_dups <- match_df(water20, sheetbar_dups, on = 'SHEETBAR') 

# Set aside the rows with sheetbars that only occur once
water_cleaned <- data[!(data$SHEETBAR %in% sheetbar_dups$SHEETBAR), ]


# Average the continuous vars and re-merge the identifiers to the collapsed rows
data_dups_ids <- data_dups[identifier_var]

# Find the mean of the continuous variables
data_dups <- aggregate(data_dups[water_var], 
                       by = list(data_dups$SHEETBAR), 
                       FUN = mean,
                       na.rm = TRUE,
                       na.action = na.pass)
colnames(data_dups)[colnames(data_dups) == 'Group.1'] <- 'SHEETBAR'

# Rounds the data frame
is.num <-sapply(data_dups, is.numeric)
data_dups[is.num] <- lapply(data_dups[is.num], round, 2)

# Replace NaN with Na to be consistent with the rest of the data
data_dups[is.na(data_dups)] <- NA

# Merge the ids back to the water_vars
data_dups <- unique(merge(data_dups, data_dups_ids, by = 'SHEETBAR'))

# Add the collapsed rows to the cleaned data
water_cleaned <- rbind(water_cleaned, data_dups) 
  
return(water_cleaned)
}
```


```{r}
# Just continuous vars and identifiers
water20 <- water20[c(water_var, identifier_var)]

water20 <- row_collapse(water20, water_var, identifier_var)

```

## Replace negative values with NA
Due to bad readings when sampling, there are negative values for some of the continuous variables. Since we do not want to throw away data that is mostly usable, we will replace the negative value and instead interpolate the value.

```{r}
#replace(water_cleaned[water_var], which(water_cleaned[water_var] < 0), NA)
water20[water_var][water20[water_var] < 0 ] <- NA
```


## Combine

```{r}

badfilterwater <- water20 %>%
  filter(CALCZCD == "SF") %>%
  select(all_of(c(identifier_var, water_var, waterQF_var))) %>%
  filter_at(vars(c("TURBQF","TEMPQF","DOQF","VELQF",
                   "ZMAXQF","SECCHIQF","CONDQF")),
            any_vars(. != "A" | . != 0)) %>%
  # forrest, edit this
  filter_at(vars(c("TNQF","TPQF","SSQF")), 
            any_vars(. != 8 | . != 64))
# THIS IS BUGGY BECAUSE WE WANT THE LAST TWO FILTER CODES TO BE OR
filterwater %>% head() %>%
  kbl(booktabs = T) %>%
  kable_styling(latex_options = "striped")
```

```{r}
dim(filterwater)
```

use this tutorial about `filter_at`
https://suzan.rbind.io/2018/02/dplyr-tutorial-3/

```{r}
write.csv(filterwater, "../LTRM data/water_data_filtered.csv", row.names = FALSE)
```
