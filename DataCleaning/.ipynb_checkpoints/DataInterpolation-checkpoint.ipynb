{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87c781e-8976-419f-af92-ac530be44642",
   "metadata": {},
   "source": [
    "# Imports\n",
    "This the script for prepossing the data to create data ready for the TDA mapper algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d64290-971e-48ad-9936-1b7a5bc911ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "import math\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"imports done\")\n",
    "pd.set_option(\"display.max_rows\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c69c28-a65d-4ce0-9661-b825903b1efe",
   "metadata": {},
   "source": [
    "# File\n",
    "From the resulting `R` script written by Amber and `python` script written by Alaina, grab the cleaned data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9065e317-a269-44eb-8f38-ad5c3e238f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataFrame Made\n"
     ]
    }
   ],
   "source": [
    "filePath = r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\github\\UMR-TDA-2021\\LTRM data\\cleaned_data.csv\"\n",
    "dataFrame = pd.read_csv(filePath, low_memory = False)\n",
    "print(\"dataFrame Made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61798da6-fb95-40d6-860a-14bfeda431fe",
   "metadata": {},
   "source": [
    "# Filter for your pool\n",
    "Resets the index as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b712a0a-ed16-41f8-8243-dace94110f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14953, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>STRATUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44002201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>9.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-90.683117</td>\n",
       "      <td>39.004773</td>\n",
       "      <td>11/29/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>M241.4K</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44002202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-90.673138</td>\n",
       "      <td>38.940668</td>\n",
       "      <td>11/29/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>M237.2G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44002759</td>\n",
       "      <td>1.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.9</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.549129</td>\n",
       "      <td>38.852878</td>\n",
       "      <td>06/24/1996</td>\n",
       "      <td>4</td>\n",
       "      <td>DC01.0M</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44002760</td>\n",
       "      <td>2.562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.748878</td>\n",
       "      <td>38.924233</td>\n",
       "      <td>06/24/1996</td>\n",
       "      <td>4</td>\n",
       "      <td>CU11.6M</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44002761</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.657982</td>\n",
       "      <td>38.883755</td>\n",
       "      <td>06/24/1996</td>\n",
       "      <td>4</td>\n",
       "      <td>PE01.8M</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR     TN  TP  TEMP    DO  TURB   COND  VEL    SS   WDP  CHLcal  \\\n",
       "0  44002201    NaN NaN   2.4  14.2  15.0  455.0  NaN  -0.2  9.50     NaN   \n",
       "1  44002202    NaN NaN   2.2  14.1  11.0  459.0  0.0  -2.0  0.94     NaN   \n",
       "2  44002759  1.323 NaN  28.6   3.8  66.0  306.0  NaN  76.9  3.20     NaN   \n",
       "3  44002760  2.562 NaN  30.6   6.3  93.0  270.0  NaN  54.6   NaN     NaN   \n",
       "4  44002761  2.625 NaN  30.1  10.0  29.0  337.0  NaN  35.6   NaN     NaN   \n",
       "\n",
       "   SECCHI  LONGITUDE   LATITUDE        DATE  FLDNUM  LOCATCD  STRATUM  \n",
       "0    53.0 -90.683117  39.004773  11/29/1995       4  M241.4K      NaN  \n",
       "1    64.0 -90.673138  38.940668  11/29/1995       4  M237.2G      NaN  \n",
       "2     NaN -90.549129  38.852878  06/24/1996       4  DC01.0M      NaN  \n",
       "3     NaN -90.748878  38.924233  06/24/1996       4  CU11.6M      NaN  \n",
       "4     NaN -90.657982  38.883755  06/24/1996       4  PE01.8M      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = dataFrame[dataFrame['FLDNUM'] == 4]\n",
    "print(dataFrame.shape)\n",
    "dataFrame  = dataFrame.reset_index(drop = True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083e674a-6336-4ae2-9c3f-0308064c7464",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Here, we interpolate for missing data values. These occur when the ltrm data set has a missing value. The way it is is computed utilizes a $k$-nearest neighbors approach. A weighted average using the $k$ nearest points is used to compute the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d580f6f3-79f5-4c18-ad89-ce4e695028b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions have been loaded\n"
     ]
    }
   ],
   "source": [
    "def predict_years(df, hashtable, naVar, year, k):\n",
    "    df[\"PREDICTED_\" + naVar] = df[naVar]\n",
    "    df_year = df.copy()\n",
    "    df_year = df_year[df_year[\"YEAR\"] == year]\n",
    "    naIndices = df_year[(df_year[naVar].isnull())]\n",
    "    print(\"For \" + naVar + \" we will interpolate \" + str(len(naIndices)) + \" points.\")\n",
    "    for index, row in naIndices.iterrows():\n",
    "        distances, neighbors = k_nearest_neighbors(df, index, naVar, hashtable, k)\n",
    "        df.loc[index, \"PREDICTED_\" + naVar] = interpolate(df, distances, neighbors, naVar)\n",
    "    print(naVar + \" interpolation success\")\n",
    "\n",
    "def predict(df, hashtable, naVar, k):\n",
    "    df[\"PREDICTED_\" + naVar] = df[naVar]\n",
    "    naIndices = df[(df[naVar].isnull())]\n",
    "    print(\"For \" + naVar + \" we will interpolate \" + str(len(naIndices)) + \" points.\")\n",
    "    for index, row in naIndices.iterrows():\n",
    "        distances, neighbors = k_nearest_neighbors(df, index, naVar, hashtable, k)\n",
    "        df.loc[index, \"PREDICTED_\" + naVar] = interpolate(df, distances, neighbors, naVar)\n",
    "    print(naVar + \" interpolation success\")\n",
    "\n",
    "def transform(minimum, maximum, x):\n",
    "    return (1 / (maximum - minimum) ) * (x - minimum)\n",
    "\n",
    "def dist(point1, point2):\n",
    "    return distance.distance(point1, point2).km\n",
    "    \n",
    "def construct_hashtable(df):\n",
    "    #get hashtable information\n",
    "    data_length = math.sqrt(df.shape[0])\n",
    "    #print(\"data_length: \" + str(data_length))\n",
    "    interval_length = 1 / data_length\n",
    "    lat_minimum = df[[\"LATITUDE\"]].min()[0] - 1\n",
    "    lat_maximum = df[[\"LATITUDE\"]].max()[0] + 1\n",
    "    long_minimum = df[[\"LONGITUDE\"]].min()[0] - 1\n",
    "    long_maximum = df[[\"LONGITUDE\"]].max()[0] + 1\n",
    "    \n",
    "    #construct hashtable\n",
    "    hashtable = [[[] for x in range(int(data_length)+1)] for y in range(int(data_length)+1)]\n",
    "    \n",
    "    #populate hashtable\n",
    "    for index, row in df.iterrows():\n",
    "        r_lat = row['LATITUDE']\n",
    "        r_long = row['LONGITUDE']\n",
    "        lat = math.floor(transform(lat_minimum, lat_maximum, r_lat) / interval_length)\n",
    "        long = math.floor(transform(long_minimum, long_maximum, r_long) / interval_length)\n",
    "        #print(\"lat: \" + str(lat))\n",
    "        #print(\"long: \" + str(long))\n",
    "        hashtable[lat][long].append((index, r_lat, r_long))\n",
    "\n",
    "    return hashtable\n",
    "\n",
    "def k_nearest_neighbors(df, index, naVar, hashtable, k):\n",
    "\n",
    "    distances = []\n",
    "    neighbor_indices = []\n",
    "    neighbors = {}\n",
    "    \n",
    "    data_length = math.sqrt(df.shape[0])\n",
    "    interval_length = 1 / data_length\n",
    "    lat_minimum = df[[\"LATITUDE\"]].min()[0] - 1\n",
    "    lat_maximum = df[[\"LATITUDE\"]].max()[0] + 1\n",
    "    long_minimum = df[[\"LONGITUDE\"]].min()[0] - 1\n",
    "    long_maximum = df[[\"LONGITUDE\"]].max()[0] + 1\n",
    "    \n",
    "    \n",
    "    row_na = df.loc[index]\n",
    "    point_na = (row_na['LATITUDE'], row_na['LONGITUDE'])\n",
    "    lat = math.floor(transform(lat_minimum, lat_maximum, point_na[0]) / interval_length)\n",
    "    long = math.floor(transform(long_minimum, long_maximum, point_na[1]) / interval_length)\n",
    "    season = row_na['SEASON']\n",
    "    \n",
    "    for inx, latitude, longitude in hashtable[lat][long]:\n",
    "        distance_km = dist(point_na, (latitude, longitude))\n",
    "        if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "            distances.append(distance_km)\n",
    "            if distance_km in neighbors.keys():\n",
    "                neighbors[distance_km].append(inx)\n",
    "            else:\n",
    "                neighbors[distance_km] = [inx]\n",
    "    \n",
    "    if lat != 0:\n",
    "        \n",
    "        for inx, latitude, longitude in hashtable[lat - 1][long]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "                    \n",
    "        if long != 0:\n",
    "            for inx, latitude, longitude in hashtable[lat - 1][long - 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "        if long + 1 != len(hashtable):\n",
    "            for inx, latitude, longitude in hashtable[lat - 1][long + 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if lat + 1 != len(hashtable):\n",
    "        \n",
    "        for inx, latitude, longitude in hashtable[lat + 1][long]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "                    \n",
    "        if long != 0:\n",
    "            for inx, latitude, longitude in hashtable[lat + 1][long - 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "        if long + 1 != len(hashtable):\n",
    "            for inx, latitude, longitude in hashtable[lat + 1][long + 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if long != 0:\n",
    "        for inx, latitude, longitude in hashtable[lat][long - 1]:\n",
    "            distance_km = dist(point_na, (latitude, longitude))\n",
    "            if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                distances.append(distance_km)\n",
    "                if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "                else:\n",
    "                    neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if long + 1 != len(hashtable):\n",
    "        for inx, latitude, longitude in hashtable[lat][long + 1]:\n",
    "            distance_km = dist(point_na, (latitude, longitude))\n",
    "            if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                distances.append(distance_km)\n",
    "                if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "                else:\n",
    "                    neighbors[distance_km] = [inx]\n",
    "    \n",
    "    distances.sort()\n",
    "    distances = distances[0:k]\n",
    "    for distance_km in distances:\n",
    "        for inx in neighbors[distance_km]:\n",
    "            neighbor_indices.append(inx)\n",
    "    neighbor_indices = neighbor_indices[0:k]\n",
    "    if len(neighbor_indices) < k and len(neighbor_indices) != 0:\n",
    "        print(\"INTERPOLATING WITH \" + str(len(neighbor_indices)) + \" POINTS INSTEAD OF \" + str(k) + \" POINTS\")\n",
    "    if len(neighbor_indices) >= 2:\n",
    "        return (distances, neighbor_indices)\n",
    "    \n",
    "    distances = []\n",
    "    neighbors = {}\n",
    "    neighbor_indices = []\n",
    "    for inx, row in df.iterrows():\n",
    "        distance_km = dist(point_na, (row['LATITUDE'], row['LONGITUDE']))\n",
    "        if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "            distances.append(distance_km)\n",
    "            if distance_km in neighbors.keys():\n",
    "                neighbors[distance_km].append(inx)\n",
    "            else:\n",
    "                neighbors[distance_km] = [inx]\n",
    "    distances.sort()\n",
    "    distances = distances[0:k]\n",
    "    for distance_km in distances:\n",
    "        for inx in neighbors[distance_km]:\n",
    "            neighbor_indices.append(inx)\n",
    "    neighbor_indices = neighbor_indices[0:k]\n",
    "    return (distances, neighbor_indices)            \n",
    "    \n",
    "\n",
    "def interpolate(df, distances, neighbors, naVar):\n",
    "    result = 0\n",
    "    denominator = [1 / x for x in distances]\n",
    "    denominator = sum(denominator)\n",
    "    for i in range(len(distances)):\n",
    "        result += ((1/distances[i]) / denominator) * df.loc[neighbors[i]][naVar]\n",
    "    return result\n",
    "print(\"Functions have been loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758dc8e-bbe2-4c67-bae9-6c12b116bc03",
   "metadata": {},
   "source": [
    "# Creates a season data column\n",
    "Utilizes the date recorded to get the season. This allows predictions to be made within the same season (across several years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b8ee74-b4e1-4a9b-8a88-6092e8ff9348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44002201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>9.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-90.683117</td>\n",
       "      <td>39.004773</td>\n",
       "      <td>11/29/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>M241.4K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44002202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-90.673138</td>\n",
       "      <td>38.940668</td>\n",
       "      <td>11/29/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>M237.2G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44002759</td>\n",
       "      <td>1.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.9</td>\n",
       "      <td>3.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.549129</td>\n",
       "      <td>38.852878</td>\n",
       "      <td>06/24/1996</td>\n",
       "      <td>4</td>\n",
       "      <td>DC01.0M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44002760</td>\n",
       "      <td>2.562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>93.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.748878</td>\n",
       "      <td>38.924233</td>\n",
       "      <td>06/24/1996</td>\n",
       "      <td>4</td>\n",
       "      <td>CU11.6M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44002761</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-90.657982</td>\n",
       "      <td>38.883755</td>\n",
       "      <td>06/24/1996</td>\n",
       "      <td>4</td>\n",
       "      <td>PE01.8M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR     TN  TP  TEMP    DO  TURB   COND  VEL    SS   WDP  CHLcal  \\\n",
       "0  44002201    NaN NaN   2.4  14.2  15.0  455.0  NaN  -0.2  9.50     NaN   \n",
       "1  44002202    NaN NaN   2.2  14.1  11.0  459.0  0.0  -2.0  0.94     NaN   \n",
       "2  44002759  1.323 NaN  28.6   3.8  66.0  306.0  NaN  76.9  3.20     NaN   \n",
       "3  44002760  2.562 NaN  30.6   6.3  93.0  270.0  NaN  54.6   NaN     NaN   \n",
       "4  44002761  2.625 NaN  30.1  10.0  29.0  337.0  NaN  35.6   NaN     NaN   \n",
       "\n",
       "   SECCHI  LONGITUDE   LATITUDE        DATE  FLDNUM  LOCATCD  STRATUM  MONTH  \\\n",
       "0    53.0 -90.683117  39.004773  11/29/1995       4  M241.4K      NaN     11   \n",
       "1    64.0 -90.673138  38.940668  11/29/1995       4  M237.2G      NaN     11   \n",
       "2     NaN -90.549129  38.852878  06/24/1996       4  DC01.0M      NaN      6   \n",
       "3     NaN -90.748878  38.924233  06/24/1996       4  CU11.6M      NaN      6   \n",
       "4     NaN -90.657982  38.883755  06/24/1996       4  PE01.8M      NaN      6   \n",
       "\n",
       "   SEASON  \n",
       "0    FALL  \n",
       "1    FALL  \n",
       "2  SUMMER  \n",
       "3  SUMMER  \n",
       "4  SUMMER  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = dataFrame.copy()\n",
    "newData[\"MONTH\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).month\n",
    "newData[\"SEASON\"] = newData[\"MONTH\"]\n",
    "seasons = {3 : 'SPRING',\n",
    "           4 : 'SPRING',\n",
    "           5 : 'SPRING',\n",
    "           6 : 'SUMMER',\n",
    "           7 : 'SUMMER',\n",
    "           8 : 'SUMMER',\n",
    "           9 : 'FALL',\n",
    "           10 : 'FALL',\n",
    "           11: 'FALL',\n",
    "           12: 'WINTER',\n",
    "           1: 'WINTER',\n",
    "           2: 'WINTER'}\n",
    "newData = newData.replace({\"SEASON\" : seasons})\n",
    "# for index, row in newData.iterrows():\n",
    "#     newData.loc[index, 'SEASON'] = seasons\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efc40f-f858-4723-9854-11497ace52e7",
   "metadata": {},
   "source": [
    "# Prediction Group by Season and several years\n",
    "Edit the years range start based upon the particular pool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4a0fe-6d56-4693-bf46-54bbd97cfc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of years: [1994, 1995, 1996]\n",
      "Year to interpolate missing data: 1995\n",
      "SPRING\n",
      "SUMMER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 2 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 2 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 1995\n",
      "Set of years: [1995, 1996, 1997]\n",
      "Year to interpolate missing data: 1996\n",
      "SPRING\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 35 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 145 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 1996\n",
      "Set of years: [1996, 1997, 1998]\n",
      "Year to interpolate missing data: 1997\n",
      "SPRING\n",
      "For TN we will interpolate 55 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 55 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 53 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 53 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 51 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 51 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 41 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 41 points.\n",
      "TP interpolation success\n",
      "Predicted for 1997\n",
      "Set of years: [1997, 1998, 1999]\n",
      "Year to interpolate missing data: 1998\n",
      "SPRING\n",
      "For TN we will interpolate 52 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 52 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 52 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 52 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 52 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 52 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 48 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 48 points.\n",
      "TP interpolation success\n",
      "Predicted for 1998\n",
      "Set of years: [1998, 1999, 2000]\n",
      "Year to interpolate missing data: 1999\n",
      "SPRING\n",
      "For TN we will interpolate 54 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 53 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 42 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 42 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 51 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 51 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 43 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 43 points.\n",
      "TP interpolation success\n",
      "Predicted for 1999\n",
      "Set of years: [1999, 2000, 2001]\n",
      "Year to interpolate missing data: 2000\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 78 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 68 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 67 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 42 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 42 points.\n",
      "TP interpolation success\n",
      "Predicted for 2000\n",
      "Set of years: [2000, 2001, 2002]\n",
      "Year to interpolate missing data: 2001\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 84 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 66 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 66 points.\n",
      "TP interpolation success\n",
      "Predicted for 2001\n",
      "Set of years: [2001, 2002, 2003]\n",
      "Year to interpolate missing data: 2002\n",
      "SPRING\n",
      "For TN we will interpolate 66 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 66 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 75 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 74 points.\n",
      "TP interpolation success\n",
      "Predicted for 2002\n",
      "Set of years: [2002, 2003, 2004]\n",
      "Year to interpolate missing data: 2003\n",
      "SPRING\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 2003\n",
      "Set of years: [2003, 2004, 2005]\n",
      "Year to interpolate missing data: 2004\n",
      "SPRING\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 79 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 27 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 27 points.\n",
      "TP interpolation success\n",
      "Predicted for 2004\n",
      "Set of years: [2004, 2005, 2006]\n",
      "Year to interpolate missing data: 2005\n",
      "SPRING\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 78 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 73 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 73 points.\n"
     ]
    }
   ],
   "source": [
    "years = [[x-1, x, x+1] for x in range(1995, 2021)]\n",
    "newData[\"YEAR\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).year\n",
    "result = pd.DataFrame()\n",
    "for setOfYears in years:\n",
    "    print(\"Set of years: \" + str(setOfYears))\n",
    "    print(\"Year to interpolate missing data: \" + str(setOfYears[1]))\n",
    "    threeYearFrame = newData[newData['YEAR'].isin(setOfYears)]\n",
    "    seasons = ['SPRING','SUMMER','FALL','WINTER']\n",
    "    for season in seasons:\n",
    "        print(season)\n",
    "        seasonalFrame = threeYearFrame[threeYearFrame['SEASON'] == season]\n",
    "        if (seasonalFrame.shape[0] > 1):\n",
    "            seasonalHash = construct_hashtable(seasonalFrame)\n",
    "            predict_years(seasonalFrame, seasonalHash, \"TN\",setOfYears[1],2)\n",
    "            predict_years(seasonalFrame, seasonalHash, \"TP\", setOfYears[1],2)\n",
    "            yearToAdd = seasonalFrame[seasonalFrame['YEAR'] == setOfYears[1]]\n",
    "            result = result.append(yearToAdd, ignore_index = True)\n",
    "            result = result.reset_index(drop = True)\n",
    "            \n",
    "            \n",
    "    print(\"Predicted for \" + str(setOfYears[1]))\n",
    "    \n",
    "result.to_csv(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\predicted_tn_tp_OverlappingYearsAndSeasons.csv\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ccaef-6363-4640-b538-e40c187b8613",
   "metadata": {},
   "source": [
    "# Prediction group year by year\n",
    "\n",
    "\n",
    "Here, we filter for the pool we are curious about, then run the interpolation code for the missing values. Copy the \"predict\" function for the new variables, and the number is the number of nearest neighbors that you want. When it is done, the data is displayed. To save the output, use pd.to_csv(path = ), and set the path to where you want the data frame to be saved.\n",
    "\n",
    "If you want to predict for one specific year only using data from that year, filter your data frame by the desired year, then also pass in that year to that predict function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "392d9b8e-84df-4e67-9fd5-7db91d25397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For TN we will interpolate 2 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 2 points.\n",
      "TP interpolation success\n",
      "Predicted for 1995\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 180 points.\n",
      "TP interpolation success\n",
      "Predicted for 1996\n",
      "For TN we will interpolate 200 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 200 points.\n",
      "TP interpolation success\n",
      "Predicted for 1997\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "newData = dataFrame.copy()\n",
    "newData[\"YEAR\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).year\n",
    "years = newData[\"YEAR\"].unique()\n",
    "result = pd.DataFrame()\n",
    "for year in years:\n",
    "    currentSet = newData[(newData[\"YEAR\"] == year)]\n",
    "    currentSet = currentSet.reset_index(drop = True)\n",
    "    hashTable = construct_hashtable(currentSet)\n",
    "    predict(currentSet, hashTable, \"TN\",2)\n",
    "    predict(currentSet, hashTable, \"TP\",2)\n",
    "    print(\"Predicted for \" + str(year))\n",
    "    result = result.append(currentSet)\n",
    "\n",
    "result = result.reset_index(drop = True)\n",
    "result.to_csv(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\predicted_tn_tp_years.csv\")\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
