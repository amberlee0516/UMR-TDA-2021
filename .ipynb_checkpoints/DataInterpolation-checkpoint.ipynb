{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87c781e-8976-419f-af92-ac530be44642",
   "metadata": {},
   "source": [
    "# Imports\n",
    "This the script for prepossing the data to create data ready for the TDA mapper algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d64290-971e-48ad-9936-1b7a5bc911ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "import math\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "print(\"imports done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c69c28-a65d-4ce0-9661-b825903b1efe",
   "metadata": {},
   "source": [
    "# File\n",
    "From the resulting `R` script written by Amber and `python` script written by Alaina, grab the cleaned data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9065e317-a269-44eb-8f38-ad5c3e238f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataFrame Made\n"
     ]
    }
   ],
   "source": [
    "filePath = r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\github\\UMR-TDA-2021\\pools EDA\\pool data\\cleaned_data.csv\"\n",
    "dataFrame = pd.read_csv(filePath, low_memory = False)\n",
    "print(\"dataFrame Made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61798da6-fb95-40d6-860a-14bfeda431fe",
   "metadata": {},
   "source": [
    "# Filter for your pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b712a0a-ed16-41f8-8243-dace94110f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14963, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>STRATUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44000527</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>0.082</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-90.664712</td>\n",
       "      <td>38.920056</td>\n",
       "      <td>12/22/1993</td>\n",
       "      <td>4</td>\n",
       "      <td>M235.5D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44000719</td>\n",
       "      <td>1.834</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>32.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-90.233998</td>\n",
       "      <td>38.900486</td>\n",
       "      <td>07/06/1994</td>\n",
       "      <td>4</td>\n",
       "      <td>M206.0S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44001941</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.4</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-90.140035</td>\n",
       "      <td>38.830625</td>\n",
       "      <td>09/20/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>MO02.0X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44002201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>9.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-90.683117</td>\n",
       "      <td>39.004773</td>\n",
       "      <td>11/29/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>M241.4K</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44002202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-90.673138</td>\n",
       "      <td>38.940668</td>\n",
       "      <td>11/29/1995</td>\n",
       "      <td>4</td>\n",
       "      <td>M237.2G</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR     TN     TP  TEMP    DO  TURB   COND  VEL     SS   WDP  CHLcal  \\\n",
       "0  44000527 -0.200  0.082   3.9  10.4  32.0  223.0  0.0    NaN  1.10     NaN   \n",
       "1  44000719  1.834 -0.001  32.1  11.8  50.0  424.0  0.0  122.8  0.83     NaN   \n",
       "2  44001941 -0.200 -0.001  22.2   8.4  35.0  824.0  NaN   61.4  6.00     NaN   \n",
       "3  44002201    NaN    NaN   2.4  14.2  15.0  455.0  NaN   -0.2  9.50     NaN   \n",
       "4  44002202    NaN    NaN   2.2  14.1  11.0  459.0  0.0   -2.0  0.94     NaN   \n",
       "\n",
       "   SECCHI  LONGITUDE   LATITUDE        DATE  FLDNUM  LOCATCD  STRATUM  \n",
       "0    40.0 -90.664712  38.920056  12/22/1993       4  M235.5D      NaN  \n",
       "1    19.0 -90.233998  38.900486  07/06/1994       4  M206.0S      NaN  \n",
       "2    30.0 -90.140035  38.830625  09/20/1995       4  MO02.0X      NaN  \n",
       "3    53.0 -90.683117  39.004773  11/29/1995       4  M241.4K      NaN  \n",
       "4    64.0 -90.673138  38.940668  11/29/1995       4  M237.2G      NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = dataFrame[dataFrame['FLDNUM'] == 4]\n",
    "print(dataFrame.shape)\n",
    "dataFrame  = dataFrame.reset_index(drop = True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083e674a-6336-4ae2-9c3f-0308064c7464",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Here, we interpolate for missing data values. These occur when the ltrm data set has a missing value. The way it is is computed utilizes a $k$-nearest neighbors approach. A weighted average using the $k$ nearest points is used to compute the missing value. The current algorithm does not occur for temporal differences, however. To resolve this, data can be inputed one year at a time (or another time interval), and that way only data close in the point of time will be considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d580f6f3-79f5-4c18-ad89-ce4e695028b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions have been loaded\n"
     ]
    }
   ],
   "source": [
    "def predict(df, hashtable, naVar, k):\n",
    "    df[\"PREDICTED_\" + naVar] = df[naVar]\n",
    "    naIndices = np.argwhere(np.isnan(np.array(df[naVar]))).flatten()\n",
    "    print(\"For \" + naVar + \" we will interpolate \" + str(len(naIndices)) + \" points.\")\n",
    "    for index in naIndices:\n",
    "        distances, neighbors = k_nearest_neighbors(df, index, naVar, hashtable, k)\n",
    "        df.loc[index, \"PREDICTED_\" + naVar] = interpolate(df, distances, neighbors, naVar)\n",
    "    print(naVar + \" interpolation success\")\n",
    "\n",
    "def transform(minimum, maximum, x):\n",
    "    return (1 / (maximum - minimum) ) * (x - minimum)\n",
    "\n",
    "def dist(point1, point2):\n",
    "    return distance.distance(point1, point2).km\n",
    "    \n",
    "def construct_hashtable(df):\n",
    "    #get hashtable information\n",
    "    data_length = math.sqrt(df.shape[0])\n",
    "    #print(\"data_length: \" + str(data_length))\n",
    "    interval_length = 1 / data_length\n",
    "    lat_minimum = df[[\"LATITUDE\"]].min()[0] - 1\n",
    "    lat_maximum = df[[\"LATITUDE\"]].max()[0] + 1\n",
    "    long_minimum = df[[\"LONGITUDE\"]].min()[0] - 1\n",
    "    long_maximum = df[[\"LONGITUDE\"]].max()[0] + 1\n",
    "    \n",
    "    #construct hashtable\n",
    "    hashtable = [[[] for x in range(int(data_length)+1)] for y in range(int(data_length)+1)]\n",
    "    \n",
    "    #populate hashtable\n",
    "    for index, row in df.iterrows():\n",
    "        r_lat = row['LATITUDE']\n",
    "        r_long = row['LONGITUDE']\n",
    "        lat = math.floor(transform(lat_minimum, lat_maximum, r_lat) / interval_length)\n",
    "        long = math.floor(transform(long_minimum, long_maximum, r_long) / interval_length)\n",
    "        #print(\"lat: \" + str(lat))\n",
    "        #print(\"long: \" + str(long))\n",
    "        hashtable[lat][long].append((index, r_lat, r_long))\n",
    "\n",
    "    return hashtable\n",
    "\n",
    "def k_nearest_neighbors(df, index, naVar, hashtable, k):\n",
    "\n",
    "    distances = []\n",
    "    neighbor_indices = []\n",
    "    neighbors = {}\n",
    "    \n",
    "    data_length = math.sqrt(df.shape[0])\n",
    "    interval_length = 1 / data_length\n",
    "    lat_minimum = df[[\"LATITUDE\"]].min()[0] - 1\n",
    "    lat_maximum = df[[\"LATITUDE\"]].max()[0] + 1\n",
    "    long_minimum = df[[\"LONGITUDE\"]].min()[0] - 1\n",
    "    long_maximum = df[[\"LONGITUDE\"]].max()[0] + 1\n",
    "    \n",
    "    \n",
    "    row_na = df.loc[index]\n",
    "    point_na = (row_na['LATITUDE'], row_na['LONGITUDE'])\n",
    "    lat = math.floor(transform(lat_minimum, lat_maximum, point_na[0]) / interval_length)\n",
    "    long = math.floor(transform(long_minimum, long_maximum, point_na[1]) / interval_length)\n",
    "\n",
    "    for inx, latitude, longitude in hashtable[lat][long]:\n",
    "        distance_km = dist(point_na, (latitude, longitude))\n",
    "        if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "            distances.append(distance_km)\n",
    "            if distance_km in neighbors.keys():\n",
    "                neighbors[distance_km].append(inx)\n",
    "            else:\n",
    "                neighbors[distance_km] = [inx]\n",
    "    \n",
    "    if lat != 0:\n",
    "        \n",
    "        for inx, latitude, longitude in hashtable[lat - 1][long]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "                    \n",
    "        if long != 0:\n",
    "            for inx, latitude, longitude in hashtable[lat - 1][long - 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "        if long + 1 != len(hashtable):\n",
    "            for inx, latitude, longitude in hashtable[lat - 1][long + 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if lat + 1 != len(hashtable):\n",
    "        \n",
    "        for inx, latitude, longitude in hashtable[lat + 1][long]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "                    \n",
    "        if long != 0:\n",
    "            for inx, latitude, longitude in hashtable[lat + 1][long - 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "        if long + 1 != len(hashtable):\n",
    "            for inx, latitude, longitude in hashtable[lat + 1][long + 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if long != 0:\n",
    "        for inx, latitude, longitude in hashtable[lat][long - 1]:\n",
    "            distance_km = dist(point_na, (latitude, longitude))\n",
    "            if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                distances.append(distance_km)\n",
    "                if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "                else:\n",
    "                    neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if long + 1 != len(hashtable):\n",
    "        for inx, latitude, longitude in hashtable[lat][long + 1]:\n",
    "            distance_km = dist(point_na, (latitude, longitude))\n",
    "            if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                distances.append(distance_km)\n",
    "                if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "                else:\n",
    "                    neighbors[distance_km] = [inx]\n",
    "    \n",
    "    distances.sort()\n",
    "    distances = distances[0:k]\n",
    "    for distance_km in distances:\n",
    "        for inx in neighbors[distance_km]:\n",
    "            neighbor_indices.append(inx)\n",
    "    neighbor_indices = neighbor_indices[0:k]\n",
    "    if len(neighbor_indices) < k and len(neighbor_indices) != 0:\n",
    "        print(\"INTERPOLATING WITH \" + str(len(neighbor_indices)) + \" POINTS INSTEAD OF \" + str(k) + \" POINTS\")\n",
    "    if len(neighbor_indices) >= 2:\n",
    "        return (distances, neighbor_indices)\n",
    "    \n",
    "    distances = []\n",
    "    neighbors = {}\n",
    "    neighbor_indices = []\n",
    "    for inx, row in df.iterrows():\n",
    "        distance_km = dist(point_na, (row['LATITUDE'], row['LONGITUDE']))\n",
    "        if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "            distances.append(distance_km)\n",
    "            if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "            else:\n",
    "                neighbors[distance_km] = [inx]\n",
    "    distances.sort()\n",
    "    distances = distances[0:k]\n",
    "    for distance_km in distances:\n",
    "        for inx in neighbors[distance_km]:\n",
    "            neighbor_indices.append(inx)\n",
    "    neighbor_indices = neighbor_indices[0:k]\n",
    "    return (distances, neighbor_indices)            \n",
    "    \n",
    "\n",
    "def interpolate(df, distances, neighbors, naVar):\n",
    "    result = 0\n",
    "    denominator = [1 / x for x in distances]\n",
    "    denominator = sum(denominator)\n",
    "    for i in range(len(distances)):\n",
    "        result += ((1/distances[i]) / denominator) * df.loc[neighbors[i]][naVar]\n",
    "    return result\n",
    "print(\"Functions have been loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ccaef-6363-4640-b538-e40c187b8613",
   "metadata": {},
   "source": [
    "Here, we filter for the pool we are curious about, then run the interpolation code for the missing values. Copy the \"predict\" function for the new variables, and the number is the number of nearest neighbors that you want. When it is done, the data is displayed. To save the output, use pd.to_csv(path = ), and set the path to where you want the data frame to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d9b8e-84df-4e67-9fd5-7db91d25397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 1993\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 1994\n",
      "For TN we will interpolate 2 points.\n",
      "INTERPOLATING WITH 1 POINTS INSTEAD OF 2 POINTS\n",
      "INTERPOLATING WITH 1 POINTS INSTEAD OF 2 POINTS\n",
      "TN interpolation success\n",
      "For TP we will interpolate 2 points.\n",
      "INTERPOLATING WITH 1 POINTS INSTEAD OF 2 POINTS\n",
      "INTERPOLATING WITH 1 POINTS INSTEAD OF 2 POINTS\n",
      "TP interpolation success\n",
      "Predicted for 1995\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 180 points.\n",
      "TP interpolation success\n",
      "Predicted for 1996\n",
      "For TN we will interpolate 200 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 200 points.\n",
      "TP interpolation success\n",
      "Predicted for 1997\n",
      "For TN we will interpolate 204 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 204 points.\n",
      "TP interpolation success\n",
      "Predicted for 1998\n",
      "For TN we will interpolate 190 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 189 points.\n",
      "TP interpolation success\n",
      "Predicted for 1999\n",
      "For TN we will interpolate 268 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 267 points.\n",
      "TP interpolation success\n",
      "Predicted for 2000\n",
      "For TN we will interpolate 310 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 306 points.\n",
      "TP interpolation success\n",
      "Predicted for 2001\n",
      "For TN we will interpolate 211 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 210 points.\n",
      "TP interpolation success\n",
      "Predicted for 2002\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 2003\n",
      "For TN we will interpolate 265 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 267 points.\n",
      "TP interpolation success\n",
      "Predicted for 2004\n",
      "For TN we will interpolate 311 points.\n"
     ]
    }
   ],
   "source": [
    "newData = dataFrame\n",
    "newData[\"YEAR\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).year\n",
    "years = newData[\"YEAR\"].unique()\n",
    "result = pd.DataFrame()\n",
    "for year in years:\n",
    "    currentSet = newData[(newData[\"YEAR\"] == year)]\n",
    "    currentSet = currentSet.reset_index(drop = True)\n",
    "    #display(currentSet)\n",
    "    hashTable = construct_hashtable(currentSet)\n",
    "    predict(currentSet, hashTable, \"TN\", 2)\n",
    "    predict(currentSet, hashTable, \"TP\", 2)\n",
    "    print(\"Predicted for \" + str(year))\n",
    "    result.append(currentSet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a905bb1-ffc0-45ff-bbb6-cdb1601ed4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
