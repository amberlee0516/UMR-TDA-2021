{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd00adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608",
   "display_name": "Python 3.8.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this program is to combine any rows that have the same barcode (SHEETBAR). While filtering by the categorical river depth (CALCZCD) removed many duplicate barcodes that consisted of samples at the same site with varying CALCZCD values, there are still several samples that have the same barcode.\n",
    "\n",
    "# It is important that our data sets consists only of unqiue barcodes because it removes issues when interpolating the data and predicting our missing continuous variable values. For example, if two samples have the same barcode, then their latitude and longitude points are going to be equal. Say one of these two records has a missing TP value. When the interpolation algorithm tries to predict the missing TP value, it will search for the closest samples and create a new TP value as a linear combination of those closets points. Since we have two identcal lat and long points, the distance will be 0 and thus, by definition of our weights in the linear combination, we will be diving by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data at this point will have already been filtered by its QF code and by its CALCZCD\n",
    "# The data set should consist of only surface level points \n",
    "data = pd.read_csv(\"../pool data/water_data_filtered.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the continous variables that we want\n",
    "data = data[['SHEETBAR','TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI', 'LONGITUDE', 'LATITUDE', 'DATE', 'FLDNUM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which columns are duplicates and count how many duplicates there are\n",
    "duplicates = data.groupby(['SHEETBAR']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of duplicates and rename the column to \"count\" \n",
    "duplicates = pd.DataFrame(duplicates, columns = ['count']).reset_index()\n",
    "duplicates = duplicates[duplicates['count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe that will store the new collapsed data set\n",
    "collapsed_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we only need to examine the data that has duplicate barcodes, we can set aside the unique barcodes\n",
    "collapsed_data = data[-pd.Series(data[\"SHEETBAR\"]).isin(duplicates[\"SHEETBAR\"])]\n",
    "\n",
    "# Store the duplicated data in its own data set called data_dups\n",
    "data_dups = data[pd.Series(data[\"SHEETBAR\"]).isin(duplicates[\"SHEETBAR\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know based on inspection that there may be negative TP values. We are going to remove these samples\n",
    "data_dups = data_dups.drop(data_dups.index[data_dups['TP'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average of each variable by barcode\n",
    "# If there is only na values, na will be returned\n",
    "# For any number of values per variable, the average will be found\n",
    "temp = data_dups.groupby(['SHEETBAR'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([-4604347, -4604346, -4604345, -4604343, -4604341, -4604339,\\n            -4604337, -4604336, -4604335, -4604334,\\n            ...\\n            46020726, 46020728, 46020731, 46022545, 46022547, 46022567,\\n            46025292, 47000506, 47000663, 47000678],\\n           dtype='int64', length=40784)] are in the [index]\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-82a4f5a0cbbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For reference, this method of adding the date was not working\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SHEETBAR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1055\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([-4604347, -4604346, -4604345, -4604343, -4604341, -4604339,\\n            -4604337, -4604336, -4604335, -4604334,\\n            ...\\n            46020726, 46020728, 46020731, 46022545, 46022547, 46022567,\\n            46025292, 47000506, 47000663, 47000678],\\n           dtype='int64', length=40784)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "# For reference, this method of adding the date was not working\n",
    "temp['DATE'] = data_dups['DATE'][temp['SHEETBAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate dataframe that stores the date of each barcode \n",
    "# Drops duplicates so that we will only have one date per barcode\n",
    "date = pd.DataFrame(data_dups, columns = ['SHEETBAR','DATE']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the date to the collapsed data by the sheetbar\n",
    "temp = temp.merge(date, on = ['SHEETBAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       SHEETBAR        TN        TP  TEMP         DO   TURB        COND   VEL  \\\n",
       "0      41004753  2.897000  0.121000   0.1  11.600000    4.0  490.000000   NaN   \n",
       "1      41004755  3.054000  0.112000   0.1  11.900000    4.0  484.000000   NaN   \n",
       "2      41004757  1.282000  0.066000   0.1  11.000000    4.0  175.000000   NaN   \n",
       "3      41004761  3.266000  0.115000   0.1  11.700000    3.0  478.000000   NaN   \n",
       "4      41004763  2.908000  0.105000   0.1  10.600000    3.0  446.000000  0.07   \n",
       "...         ...       ...       ...   ...        ...    ...         ...   ...   \n",
       "59149  47001268  1.430000  0.094000  23.4  11.000000   16.0  280.000000   NaN   \n",
       "59150  47001269  8.620000  0.193000  17.3   8.800000   28.0  727.000000   NaN   \n",
       "0      46015274  1.599000  0.664000  24.5   6.200000  140.0  461.000000  0.01   \n",
       "1      47000506  1.705333  0.116667  10.4  12.166667   11.0  353.666667  0.05   \n",
       "2      47000678  2.165000  0.180333  28.3   5.300000   19.0  447.000000   NaN   \n",
       "\n",
       "               SS   WDP      CHLcal  SECCHI  LONGITUDE   LATITUDE        DATE  \\\n",
       "0        2.900000  7.82         NaN   119.0 -92.226798  44.447461  12/30/1996   \n",
       "1        2.400000  5.50         NaN   187.0 -92.100458  44.412100  12/30/1996   \n",
       "2        2.400000  0.71         NaN    89.0 -92.084185  44.410152  12/30/1996   \n",
       "3        2.200000  5.33         NaN   123.0 -92.134004  44.423271  12/30/1996   \n",
       "4        1.800000  1.10         NaN   119.0 -91.932921  44.326994  12/30/1996   \n",
       "...           ...   ...         ...     ...        ...        ...         ...   \n",
       "59149   28.000000   NaN   74.572080     NaN -91.049424  43.000181  06/16/2006   \n",
       "59150   24.300000   NaN    3.917360     NaN -91.197341  43.093663  06/16/2006   \n",
       "0      164.900000  0.57  113.298125    13.0 -90.103645  40.253465  08/07/2009   \n",
       "1       14.933333   NaN   12.040600    45.0 -91.205630  43.370779  10/29/1999   \n",
       "2             NaN  0.91    9.197013    45.0 -91.248337  43.415769  07/24/2001   \n",
       "\n",
       "       FLDNUM  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "59149       7  \n",
       "59150       7  \n",
       "0           6  \n",
       "1           7  \n",
       "2           7  \n",
       "\n",
       "[59145 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SHEETBAR</th>\n      <th>TN</th>\n      <th>TP</th>\n      <th>TEMP</th>\n      <th>DO</th>\n      <th>TURB</th>\n      <th>COND</th>\n      <th>VEL</th>\n      <th>SS</th>\n      <th>WDP</th>\n      <th>CHLcal</th>\n      <th>SECCHI</th>\n      <th>LONGITUDE</th>\n      <th>LATITUDE</th>\n      <th>DATE</th>\n      <th>FLDNUM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41004753</td>\n      <td>2.897000</td>\n      <td>0.121000</td>\n      <td>0.1</td>\n      <td>11.600000</td>\n      <td>4.0</td>\n      <td>490.000000</td>\n      <td>NaN</td>\n      <td>2.900000</td>\n      <td>7.82</td>\n      <td>NaN</td>\n      <td>119.0</td>\n      <td>-92.226798</td>\n      <td>44.447461</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>41004755</td>\n      <td>3.054000</td>\n      <td>0.112000</td>\n      <td>0.1</td>\n      <td>11.900000</td>\n      <td>4.0</td>\n      <td>484.000000</td>\n      <td>NaN</td>\n      <td>2.400000</td>\n      <td>5.50</td>\n      <td>NaN</td>\n      <td>187.0</td>\n      <td>-92.100458</td>\n      <td>44.412100</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41004757</td>\n      <td>1.282000</td>\n      <td>0.066000</td>\n      <td>0.1</td>\n      <td>11.000000</td>\n      <td>4.0</td>\n      <td>175.000000</td>\n      <td>NaN</td>\n      <td>2.400000</td>\n      <td>0.71</td>\n      <td>NaN</td>\n      <td>89.0</td>\n      <td>-92.084185</td>\n      <td>44.410152</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41004761</td>\n      <td>3.266000</td>\n      <td>0.115000</td>\n      <td>0.1</td>\n      <td>11.700000</td>\n      <td>3.0</td>\n      <td>478.000000</td>\n      <td>NaN</td>\n      <td>2.200000</td>\n      <td>5.33</td>\n      <td>NaN</td>\n      <td>123.0</td>\n      <td>-92.134004</td>\n      <td>44.423271</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41004763</td>\n      <td>2.908000</td>\n      <td>0.105000</td>\n      <td>0.1</td>\n      <td>10.600000</td>\n      <td>3.0</td>\n      <td>446.000000</td>\n      <td>0.07</td>\n      <td>1.800000</td>\n      <td>1.10</td>\n      <td>NaN</td>\n      <td>119.0</td>\n      <td>-91.932921</td>\n      <td>44.326994</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59149</th>\n      <td>47001268</td>\n      <td>1.430000</td>\n      <td>0.094000</td>\n      <td>23.4</td>\n      <td>11.000000</td>\n      <td>16.0</td>\n      <td>280.000000</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>NaN</td>\n      <td>74.572080</td>\n      <td>NaN</td>\n      <td>-91.049424</td>\n      <td>43.000181</td>\n      <td>06/16/2006</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>59150</th>\n      <td>47001269</td>\n      <td>8.620000</td>\n      <td>0.193000</td>\n      <td>17.3</td>\n      <td>8.800000</td>\n      <td>28.0</td>\n      <td>727.000000</td>\n      <td>NaN</td>\n      <td>24.300000</td>\n      <td>NaN</td>\n      <td>3.917360</td>\n      <td>NaN</td>\n      <td>-91.197341</td>\n      <td>43.093663</td>\n      <td>06/16/2006</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>46015274</td>\n      <td>1.599000</td>\n      <td>0.664000</td>\n      <td>24.5</td>\n      <td>6.200000</td>\n      <td>140.0</td>\n      <td>461.000000</td>\n      <td>0.01</td>\n      <td>164.900000</td>\n      <td>0.57</td>\n      <td>113.298125</td>\n      <td>13.0</td>\n      <td>-90.103645</td>\n      <td>40.253465</td>\n      <td>08/07/2009</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47000506</td>\n      <td>1.705333</td>\n      <td>0.116667</td>\n      <td>10.4</td>\n      <td>12.166667</td>\n      <td>11.0</td>\n      <td>353.666667</td>\n      <td>0.05</td>\n      <td>14.933333</td>\n      <td>NaN</td>\n      <td>12.040600</td>\n      <td>45.0</td>\n      <td>-91.205630</td>\n      <td>43.370779</td>\n      <td>10/29/1999</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47000678</td>\n      <td>2.165000</td>\n      <td>0.180333</td>\n      <td>28.3</td>\n      <td>5.300000</td>\n      <td>19.0</td>\n      <td>447.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.91</td>\n      <td>9.197013</td>\n      <td>45.0</td>\n      <td>-91.248337</td>\n      <td>43.415769</td>\n      <td>07/24/2001</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n<p>59145 rows Ã— 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "# Add the combined duplicate samples to the single row samples\n",
    "collapsed_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_data.to_csv(\"../pool data/cleaned_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}