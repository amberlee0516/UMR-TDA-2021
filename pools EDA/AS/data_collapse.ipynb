{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd00adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608",
   "display_name": "Python 3.8.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The purpose of this program is to combine any rows that have the same barcode (SHEETBAR). While filtering by the categorical river depth (CALCZCD) removed many duplicate barcodes that consisted of samples at the same site with varying CALCZCD values, there are still several samples that have the same barcode.\n",
    "\n",
    "# It is important that our data sets consists only of unqiue barcodes because it removes issues when interpolating the data and predicting our missing continuous variable values. For example, if two samples have the same barcode, then their latitude and longitude points are going to be equal. Say one of these two records has a missing TP value. When the interpolation algorithm tries to predict the missing TP value, it will search for the closest samples and create a new TP value as a linear combination of those closets points. Since we have two identcal lat and long points, the distance will be 0 and thus, by definition of our weights in the linear combination, we will be diving by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data at this point will have already been filtered by its QF code and by its CALCZCD\n",
    "# The data set should consist of only surface level points \n",
    "data = pd.read_csv(\"../pool data/water_data_filtered.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the continous variables that we want\n",
    "# Wont need this step since the columns were filtered earlier\n",
    "data = data[['SHEETBAR','TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI', 'LONGITUDE', 'LATITUDE', 'DATE', 'FLDNUM', 'LOCATCD', 'STRATUM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which columns are duplicates and count how many duplicates there are\n",
    "duplicates = data.groupby(['SHEETBAR']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of duplicates and rename the column to \"count\" \n",
    "duplicates = pd.DataFrame(duplicates, columns = ['count']).reset_index()\n",
    "duplicates = duplicates[duplicates['count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe that will store the new collapsed data set\n",
    "collapsed_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we only need to examine the data that has duplicate barcodes, we can set aside the unique barcodes\n",
    "collapsed_data = data[-pd.Series(data[\"SHEETBAR\"]).isin(duplicates[\"SHEETBAR\"])]\n",
    "\n",
    "# Store the duplicated data in its own data set called data_dups\n",
    "data_dups = data[pd.Series(data[\"SHEETBAR\"]).isin(duplicates[\"SHEETBAR\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know based on inspection that there may be negative TP values. We are going to remove these samples\n",
    "data_dups = data_dups.drop(data_dups.index[data_dups['TP'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average of each variable by barcode\n",
    "# If there is only na values, na will be returned\n",
    "# For any number of values per variable, the average will be found\n",
    "temp = data_dups.groupby(['SHEETBAR'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate dataframe that stores the date of each barcode \n",
    "# Drops duplicates so that we will only have one date per barcode\n",
    "identifiers = pd.DataFrame(data_dups, columns = ['SHEETBAR','DATE', 'STRATUM', 'LOCATCD']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the date to the collapsed data by the sheetbar\n",
    "temp = temp.merge(identifiers, on = ['SHEETBAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       SHEETBAR        TN        TP  TEMP         DO   TURB        COND   VEL  \\\n",
       "0      41004753  2.897000  0.121000   0.1  11.600000    4.0  490.000000   NaN   \n",
       "1      41004755  3.054000  0.112000   0.1  11.900000    4.0  484.000000   NaN   \n",
       "2      41004757  1.282000  0.066000   0.1  11.000000    4.0  175.000000   NaN   \n",
       "3      41004761  3.266000  0.115000   0.1  11.700000    3.0  478.000000   NaN   \n",
       "4      41004763  2.908000  0.105000   0.1  10.600000    3.0  446.000000  0.07   \n",
       "...         ...       ...       ...   ...        ...    ...         ...   ...   \n",
       "59149  47001268  1.430000  0.094000  23.4  11.000000   16.0  280.000000   NaN   \n",
       "59150  47001269  8.620000  0.193000  17.3   8.800000   28.0  727.000000   NaN   \n",
       "0      46015274  1.599000  0.664000  24.5   6.200000  140.0  461.000000  0.01   \n",
       "1      47000506  1.705333  0.116667  10.4  12.166667   11.0  353.666667  0.05   \n",
       "2      47000678  2.165000  0.180333  28.3   5.300000   19.0  447.000000   NaN   \n",
       "\n",
       "               SS   WDP      CHLcal  SECCHI  LONGITUDE   LATITUDE        DATE  \\\n",
       "0        2.900000  7.82         NaN   119.0 -92.226798  44.447461  12/30/1996   \n",
       "1        2.400000  5.50         NaN   187.0 -92.100458  44.412100  12/30/1996   \n",
       "2        2.400000  0.71         NaN    89.0 -92.084185  44.410152  12/30/1996   \n",
       "3        2.200000  5.33         NaN   123.0 -92.134004  44.423271  12/30/1996   \n",
       "4        1.800000  1.10         NaN   119.0 -91.932921  44.326994  12/30/1996   \n",
       "...           ...   ...         ...     ...        ...        ...         ...   \n",
       "59149   28.000000   NaN   74.572080     NaN -91.049424  43.000181  06/16/2006   \n",
       "59150   24.300000   NaN    3.917360     NaN -91.197341  43.093663  06/16/2006   \n",
       "0      164.900000  0.57  113.298125    13.0 -90.103645  40.253465  08/07/2009   \n",
       "1       14.933333   NaN   12.040600    45.0 -91.205630  43.370779  10/29/1999   \n",
       "2             NaN  0.91    9.197013    45.0 -91.248337  43.415769  07/24/2001   \n",
       "\n",
       "       FLDNUM  LOCATCD  STRATUM  STRATUM_x  STRATUM_y  \n",
       "0           1  M771.2P      NaN        NaN        NaN  \n",
       "1           1  M764.3A      NaN        NaN        NaN  \n",
       "2           1  CH00.1M      NaN        NaN        NaN  \n",
       "3           1  M766.0I      NaN        NaN        NaN  \n",
       "4           1  M753.1X      NaN        NaN        NaN  \n",
       "...       ...      ...      ...        ...        ...  \n",
       "59149       7  WS05.0Y      NaN        NaN        NaN  \n",
       "59150       7  YL01.5Y      NaN        NaN        NaN  \n",
       "0           6  0962021      NaN        3.0        3.0  \n",
       "1           7  M663.4E      NaN        NaN        NaN  \n",
       "2           7  M667.8F      NaN        NaN        NaN  \n",
       "\n",
       "[59145 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SHEETBAR</th>\n      <th>TN</th>\n      <th>TP</th>\n      <th>TEMP</th>\n      <th>DO</th>\n      <th>TURB</th>\n      <th>COND</th>\n      <th>VEL</th>\n      <th>SS</th>\n      <th>WDP</th>\n      <th>CHLcal</th>\n      <th>SECCHI</th>\n      <th>LONGITUDE</th>\n      <th>LATITUDE</th>\n      <th>DATE</th>\n      <th>FLDNUM</th>\n      <th>LOCATCD</th>\n      <th>STRATUM</th>\n      <th>STRATUM_x</th>\n      <th>STRATUM_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41004753</td>\n      <td>2.897000</td>\n      <td>0.121000</td>\n      <td>0.1</td>\n      <td>11.600000</td>\n      <td>4.0</td>\n      <td>490.000000</td>\n      <td>NaN</td>\n      <td>2.900000</td>\n      <td>7.82</td>\n      <td>NaN</td>\n      <td>119.0</td>\n      <td>-92.226798</td>\n      <td>44.447461</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n      <td>M771.2P</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>41004755</td>\n      <td>3.054000</td>\n      <td>0.112000</td>\n      <td>0.1</td>\n      <td>11.900000</td>\n      <td>4.0</td>\n      <td>484.000000</td>\n      <td>NaN</td>\n      <td>2.400000</td>\n      <td>5.50</td>\n      <td>NaN</td>\n      <td>187.0</td>\n      <td>-92.100458</td>\n      <td>44.412100</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n      <td>M764.3A</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41004757</td>\n      <td>1.282000</td>\n      <td>0.066000</td>\n      <td>0.1</td>\n      <td>11.000000</td>\n      <td>4.0</td>\n      <td>175.000000</td>\n      <td>NaN</td>\n      <td>2.400000</td>\n      <td>0.71</td>\n      <td>NaN</td>\n      <td>89.0</td>\n      <td>-92.084185</td>\n      <td>44.410152</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n      <td>CH00.1M</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>41004761</td>\n      <td>3.266000</td>\n      <td>0.115000</td>\n      <td>0.1</td>\n      <td>11.700000</td>\n      <td>3.0</td>\n      <td>478.000000</td>\n      <td>NaN</td>\n      <td>2.200000</td>\n      <td>5.33</td>\n      <td>NaN</td>\n      <td>123.0</td>\n      <td>-92.134004</td>\n      <td>44.423271</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n      <td>M766.0I</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41004763</td>\n      <td>2.908000</td>\n      <td>0.105000</td>\n      <td>0.1</td>\n      <td>10.600000</td>\n      <td>3.0</td>\n      <td>446.000000</td>\n      <td>0.07</td>\n      <td>1.800000</td>\n      <td>1.10</td>\n      <td>NaN</td>\n      <td>119.0</td>\n      <td>-91.932921</td>\n      <td>44.326994</td>\n      <td>12/30/1996</td>\n      <td>1</td>\n      <td>M753.1X</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59149</th>\n      <td>47001268</td>\n      <td>1.430000</td>\n      <td>0.094000</td>\n      <td>23.4</td>\n      <td>11.000000</td>\n      <td>16.0</td>\n      <td>280.000000</td>\n      <td>NaN</td>\n      <td>28.000000</td>\n      <td>NaN</td>\n      <td>74.572080</td>\n      <td>NaN</td>\n      <td>-91.049424</td>\n      <td>43.000181</td>\n      <td>06/16/2006</td>\n      <td>7</td>\n      <td>WS05.0Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>59150</th>\n      <td>47001269</td>\n      <td>8.620000</td>\n      <td>0.193000</td>\n      <td>17.3</td>\n      <td>8.800000</td>\n      <td>28.0</td>\n      <td>727.000000</td>\n      <td>NaN</td>\n      <td>24.300000</td>\n      <td>NaN</td>\n      <td>3.917360</td>\n      <td>NaN</td>\n      <td>-91.197341</td>\n      <td>43.093663</td>\n      <td>06/16/2006</td>\n      <td>7</td>\n      <td>YL01.5Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>46015274</td>\n      <td>1.599000</td>\n      <td>0.664000</td>\n      <td>24.5</td>\n      <td>6.200000</td>\n      <td>140.0</td>\n      <td>461.000000</td>\n      <td>0.01</td>\n      <td>164.900000</td>\n      <td>0.57</td>\n      <td>113.298125</td>\n      <td>13.0</td>\n      <td>-90.103645</td>\n      <td>40.253465</td>\n      <td>08/07/2009</td>\n      <td>6</td>\n      <td>0962021</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47000506</td>\n      <td>1.705333</td>\n      <td>0.116667</td>\n      <td>10.4</td>\n      <td>12.166667</td>\n      <td>11.0</td>\n      <td>353.666667</td>\n      <td>0.05</td>\n      <td>14.933333</td>\n      <td>NaN</td>\n      <td>12.040600</td>\n      <td>45.0</td>\n      <td>-91.205630</td>\n      <td>43.370779</td>\n      <td>10/29/1999</td>\n      <td>7</td>\n      <td>M663.4E</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47000678</td>\n      <td>2.165000</td>\n      <td>0.180333</td>\n      <td>28.3</td>\n      <td>5.300000</td>\n      <td>19.0</td>\n      <td>447.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.91</td>\n      <td>9.197013</td>\n      <td>45.0</td>\n      <td>-91.248337</td>\n      <td>43.415769</td>\n      <td>07/24/2001</td>\n      <td>7</td>\n      <td>M667.8F</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>59145 rows × 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "# Add the combined duplicate samples to the single row samples\n",
    "collapsed_data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsed_data.to_csv(\"../pool data/cleaned_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}