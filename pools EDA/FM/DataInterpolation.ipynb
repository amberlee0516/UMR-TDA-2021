{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "912d88f5-48db-49aa-b6a1-3c284b073fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "pd.set_option('display.max_columns', None)\n",
    "# useful functions and classes\n",
    "\n",
    "# This class stores the latitude and longitude of a sample, and indicates \n",
    "# if this location has the desired variable we are estimating\n",
    "class Location:\n",
    "    def __init__(self,latitude,longitude,hasv,ID,value):\n",
    "        self.ID = ID\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.hasv = hasv\n",
    "        self.value = value\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.ID)\n",
    "\n",
    "# Calculates the distance between 2 samples in km\n",
    "def getdist(S1,S2):\n",
    "    # radius of earth in km\n",
    "    coords_1 = (S1.latitude, S1.longitude)\n",
    "    coords_2 = (S2.latitude, S2.longitude)\n",
    "    dist = distance.distance(coords_1, coords_2).km\n",
    "    return dist\n",
    "\n",
    "# filters out data if a point is missing in one of the colunns\n",
    "def filterblanks(columns,data,blank):\n",
    "    # if blank is true, rows with blanks in these columns\n",
    "    # if blank is false, remove rows with non blanks or non zeros in these columns\n",
    "    for c in columns:\n",
    "        if blank:\n",
    "            data = data[data[c].notnull()]\n",
    "        else:\n",
    "            data = data[data[c].isnull()]\n",
    "    return data\n",
    "\n",
    "# PRE: all locations in the dataframe are\n",
    "# unique\n",
    "def DistanceMatrix(dataframe,variable):\n",
    "    # the list of location objects\n",
    "    locations = []\n",
    "    # the list of indexes where the the row is located in the dataframe\n",
    "    #indexes = []\n",
    "    for index,row in dataframe.iterrows():\n",
    "        # make a location object on this row\n",
    "        if pd.isnull(row[variable]):\n",
    "            hasv = False\n",
    "        else:\n",
    "            hasv = True\n",
    "        locations.append(Location(row[\"LATITUDE\"],row[\"LONGITUDE\"],hasv,row[\"LOCATCD\"],row[variable]))\n",
    "        #indexes.append(index)\n",
    "        \n",
    "    matrix = pd.DataFrame(0,index=locations,columns=locations)\n",
    "    for ci,column in enumerate(locations):\n",
    "        for ri,row in enumerate(locations):\n",
    "            if ri>ci:\n",
    "                # compute distance between column and row\n",
    "                dist = getdist(row,column)\n",
    "            elif ci>ri:\n",
    "                dist = matrix.iloc[ci,ri]\n",
    "            # put this distance in the dataframe\n",
    "            else:\n",
    "                continue\n",
    "            matrix.iloc[ri,ci] = dist\n",
    "    return matrix\n",
    "\n",
    "def changeVar(DM,data,variable):\n",
    "    locations = DM.index\n",
    "    # loop through each location\n",
    "    for i,loc in enumerate(locations):\n",
    "        ID = loc.ID\n",
    "        row = data[data[\"LOCATCD\"]==ID]\n",
    "        if pd.isnull(row[variable]):\n",
    "            locations[i].hasv = False\n",
    "            locations[i].value = None\n",
    "        else:\n",
    "            locations[i].hasv = True\n",
    "            locations[i].value = row[variable]\n",
    "            \n",
    "    DM.index = locations\n",
    "    DM.columns = locations\n",
    "        \n",
    "def getclosest(numclosest,distancematrix,location):\n",
    "    # Make a set of the closest locations that contain variable\n",
    "    closest = {}\n",
    "    column = distancematrix.loc[:,location].copy()\n",
    "    #print(type(distancematrix.index[0]))\n",
    "    # Filter the locations that dont have the desired variable\n",
    "    doesnthavev = []\n",
    "    for i in range(len(column)):\n",
    "        if not column.index[i].hasv:\n",
    "            doesnthavev.append(column.index[i])\n",
    "    column.drop(doesnthavev,inplace = True)\n",
    "    #print(type(column))\n",
    "    column.sort_values(inplace = True)\n",
    "    # The current location wouldnt be in column because\n",
    "    # it doesnt have the variable\n",
    "    \n",
    "    return column.iloc[0:numclosest]\n",
    "\n",
    "# Key: Location Code\n",
    "# Value: List of tuples (locatcd,distance,value)\n",
    "def makeDict(data,variable,numclosest=2):\n",
    "    D = DistanceMatrix(data,variable)\n",
    "    # Loop through each location without a value for variable\n",
    "    closestDict = {}\n",
    "    for loc in D.columns:\n",
    "        if not loc.hasv:\n",
    "            # Get the closest locations to loc\n",
    "            closest = getclosest(numclosest,D,loc)\n",
    "            # The list of tuples that contain location id, the distance, and the value for variable\n",
    "            tuples = []\n",
    "            for i,dist in enumerate(closest):\n",
    "                ID = closest.index[i].ID\n",
    "                val = closest.index[i].value\n",
    "                tuples.append((ID,dist,val))\n",
    "            closestDict[loc.ID] = tuples\n",
    "    return closestDict\n",
    "\n",
    "def predict(tuples,numclosest = 2):\n",
    "    loc2 = tuples[0]\n",
    "    loc3 = tuples[1]\n",
    "    d12 = loc2[1]\n",
    "    val2 = loc2[2]\n",
    "    d13 = loc3[1]\n",
    "    val3 = loc3[2]\n",
    "    \n",
    "    c2 = d12/(d12+d13)\n",
    "    c3 = d13/(d12+d13)\n",
    "    \n",
    "    predicted = c2*val2+c3*val3\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "# NEEDS WORK\n",
    "def addpredictions(df,variables,numclosest):\n",
    "    # make prediction and insert for each variable\n",
    "    first = True\n",
    "    for var in variables:\n",
    "        if first:\n",
    "            DM = DistanceMatrix(df,var)\n",
    "        else:\n",
    "            changeVar(DM,df,var)\n",
    "            \n",
    "        for loc in DM.columns:\n",
    "            if not loc.hasv:\n",
    "                # Get the closest locations to loc\n",
    "                closest = getclosest(numclosest,DM,loc)\n",
    "                # The list of tuples that contain location id, the distance, and the value for variable\n",
    "                tuples = []\n",
    "                for i,dist in enumerate(closest):\n",
    "                    ID = closest.index[i].ID\n",
    "                    val = closest.index[i].value\n",
    "                    tuples.append((ID,dist,val))\n",
    "                closestDict[loc.ID] = tuples\n",
    "                \n",
    "def run():\n",
    "    DictTN = makeDict(data,\"TN\")\n",
    "    DictTP = makeDict(data,\"TP\")\n",
    "    #put in predicted TN\n",
    "    data[\"PredictedTN\"] = 0\n",
    "    for index,row in data.iterrows():\n",
    "        if pd.isnull(row[\"TN\"]):\n",
    "            data.loc[index,\"PredictedTN\"] = predict(DictTN[row[\"LOCATCD\"]])\n",
    "        else:\n",
    "            data.loc[index,\"PredictedTN\"] = row[\"TN\"]\n",
    "\n",
    "    data[\"PredictedTP\"] = 0\n",
    "    for index,row in data.iterrows():\n",
    "        if pd.isnull(row[\"TP\"]):\n",
    "            data.loc[index,\"PredictedTP\"] = predict(DictTP[row[\"LOCATCD\"]])\n",
    "        else:\n",
    "            data.loc[index,\"PredictedTP\"] = row[\"TP\"]   \n",
    "        \n",
    "    print(data.shape)\n",
    "    print(\"Filtering out points with blank entries in at least one of the columns\")\n",
    "    cols = ['PredictedTN','PredictedTP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "    #for col in cols:\n",
    "    #    print(col,data[col].isna().sum())\n",
    "    qualdata_prediction = filterblanks(cols,data,True)\n",
    "    print(qualdata_prediction.shape)\n",
    "\n",
    "    \n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a012040-58fc-4eb6-b28c-346c464f368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# FILE PATH FOR ORIGINAL LTRM WATER DATA\n",
    "ltrm_water_path =  r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\ltrm_water_data_lat_long_06072021.csv\"\n",
    "df = pd.read_csv(ltrm_water_path, low_memory = False)\n",
    "df['YEAR'] = pd.DatetimeIndex(df['DATE']).year\n",
    "\n",
    "# Pool Names\n",
    "df.loc[df['FLDNUM'] == 1, 'POOL_NAME'] = 'Pool 4'\n",
    "df.loc[df['FLDNUM'] == 2, 'POOL_NAME'] = 'Pool 8'\n",
    "df.loc[df['FLDNUM'] == 3, 'POOL_NAME'] = 'Pool 13'\n",
    "df.loc[df['FLDNUM'] == 4, 'POOL_NAME'] = 'Pool 26'\n",
    "df.loc[df['FLDNUM'] == 5, 'POOL_NAME'] = 'Open River'\n",
    "df.loc[df['FLDNUM'] == 6, 'POOL_NAME'] = 'LaGrange'\n",
    "df.loc[df['FLDNUM'] == 7, 'POOL_NAME'] = 'Pool 9'\n",
    "# Stratum Type\n",
    "df.loc[df['STRATUM'] == 1, 'STRATUM_NAME'] = 'Main Channel'\n",
    "df.loc[df['STRATUM'] == 2, 'STRATUM_NAME'] = 'Side Channel'\n",
    "df.loc[df['STRATUM'] == 3, 'STRATUM_NAME'] = 'Backwater Area'\n",
    "df.loc[df['STRATUM'] == 4, 'STRATUM_NAME'] = 'Pepin/Swan Lake'\n",
    "df.loc[df['STRATUM'] == 5, 'STRATUM_NAME'] = 'Impounded'\n",
    "df.loc[df['STRATUM'] == 6, 'STRATUM_NAME'] = 'Isolated'\n",
    "df.loc[df['STRATUM'] == 7, 'STRATUM_NAME'] = 'New Terrestrial'\n",
    "df.loc[df['STRATUM'] == 9, 'STRATUM_NAME'] = 'Pool 13'\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cef372e3-6fd4-44fd-a593-2a7610a2556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129205\n"
     ]
    }
   ],
   "source": [
    "print(data[\"TP\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "600d53e6-46b8-40a4-9e1b-1c67f61d63ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering columns:  (0, 30)\n",
      "After filtering sampling design:  (0, 30)\n",
      "After filtering Pool 26:  (0, 30)\n",
      "Now adding a year column\n",
      "(0, 31)\n",
      "Adding a timecode column\n",
      "(0, 32)\n",
      "Filtering by backwater lakes\n",
      "(0, 32)\n",
      "Dropping data with SSQF=8 or 64\n",
      "(0, 32)\n",
      "Dropping all blank columns\n",
      "(0, 20)\n",
      "Filtering out points with blank entries in columns other than TP and TN\n",
      "(0, 20)\n"
     ]
    }
   ],
   "source": [
    "data.drop(data.columns.difference(['SHEETBAR','TN','TP','TPQF','TNQF','SS','SSQF',\n",
    "                                         'TURB','TURBQF','WDP',\n",
    "                                         'TEMP','TEMPQF','DO','DOQF','COND',\n",
    "                                         'CONDQF','VEL','VELQF','FLDEAST',\n",
    "                                         'FLDNORTH','PROJCD','FLDNUM','DATE',\n",
    "                                  'LOCATCD','STRATUM','CHLcal','SECCHI','SECCHIQF','LATITUDE','LONGITUDE']), 1, inplace=True)\n",
    "print(\"After filtering columns: \",data.shape)\n",
    "data = data[(data.PROJCD == \"M-\")]\n",
    "print(\"After filtering sampling design: \",data.shape)\n",
    "data = data[(data.FLDNUM == 4)]\n",
    "print(\"After filtering Pool 26: \",data.shape)\n",
    "print(\"Now adding a year column\")\n",
    "data[\"YEAR\"] = pd.DatetimeIndex(data[\"DATE\"]).year\n",
    "print(data.shape)\n",
    "print(\"Adding a timecode column\")\n",
    "data[\"TIME CODE\"] = data[\"LOCATCD\"].astype(str).apply(lambda x: x[3])\n",
    "print(data.shape)\n",
    "print(\"Filtering by backwater lakes\")\n",
    "data = data[data.STRATUM == 3]\n",
    "print(data.shape)\n",
    "#print(\"Filtering by summer\")\n",
    "#data = data[data[\"TIME CODE\"] == '2']\n",
    "#print(data.shape)\n",
    "print(\"Dropping data with SSQF=8 or 64\")\n",
    "qualdata = data[(data[\"SSQF\"]!=8)&(data[\"SSQF\"]!=64)]\n",
    "print(qualdata.shape)\n",
    "print(\"Dropping all blank columns\")\n",
    "qualdata.drop(['PROJCD','FLDEAST','FLDNORTH','TPQF','TNQF','SSQF','TURBQF','TEMPQF','DOQF',\n",
    "                                        'CONDQF','VELQF','SECCHIQF'], 1, inplace=True)\n",
    "print(qualdata.shape)\n",
    "print(\"Filtering out points with blank entries in columns other than TP and TN\")\n",
    "f_cols = ['SS','CHLcal']\n",
    "s_cols = ['VEL','TEMP']\n",
    "all_cols = ['TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "qualdata_noprediction = filterblanks(all_cols,qualdata,True)\n",
    "print(qualdata_noprediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cb7b404-36ec-4cb6-b6fa-812c6979abcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SHEETBAR', 'FLDNUM', 'DATE', 'LOCATCD', 'WDP', 'SECCHI', 'STRATUM',\n",
       "       'TEMP', 'DO', 'TURB', 'COND', 'VEL', 'TP', 'TN', 'SS', 'CHLcal',\n",
       "       'LATITUDE', 'LONGITUDE', 'YEAR', 'TIME CODE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualdata_noprediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc2162df-1d0f-46ee-a244-31cdc8fb2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a new dataframe with predicted TP and TN values\n",
      "Final data set size is  (0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Building a new dataframe with predicted TP and TN values\")\n",
    "#s = qualdata_noprediction[\"LOCATCD\"].duplicated(keep=False)\n",
    "# get the years and timecodes for this dataset\n",
    "#predictions can only be made if the point is in the same year and time code\n",
    "years = qualdata_noprediction[\"YEAR\"].unique()\n",
    "timecodes = qualdata_noprediction[\"TIME CODE\"].unique()\n",
    "qualdata_prediction = pd.DataFrame()\n",
    "for year in years:\n",
    "    for timecode in timecodes:\n",
    "        print(\"Appending predicted data for \",year,\" timecode \",timecode)\n",
    "        # curset is the current set of rows we are predicting for\n",
    "        curset = qualdata_noprediction[qualdata_noprediction[\"YEAR\"]==year]\n",
    "        curset = curset[curset[\"TIME CODE\"]==timecode]\n",
    "        curset[\"PredictedTN\"] = 0\n",
    "        curset[\"PredictedTP\"] = 0\n",
    "        print(curset.shape)\n",
    "        DictTN = makeDict(curset,\"TN\")\n",
    "        DictTP = makeDict(curset,\"TP\")\n",
    "        #check to see if there are valid locations\n",
    "        # that can be used to predict\n",
    "        bad = bool((curset[\"TN\"].isnull().sum()>(curset.shape[0]-2))|(curset[\"TP\"].isnull().sum()>(curset.shape[0]-2)))\n",
    "        print(curset[\"TN\"].isnull().sum(),curset[\"TP\"].isnull().sum())\n",
    "        if(bad):\n",
    "            print(\"Less than 2 locations have the variables in this set, dropping rows without variable\")\n",
    "            curset = curset[(curset[\"TP\"].notnull())&(curset[\"TN\"].notnull())]\n",
    "            curset[\"PredictedTN\"] = curset[\"TN\"]\n",
    "            curset[\"PredictedTP\"] = curset[\"TP\"]\n",
    "            print(\"Cur set is now \",curset.shape)\n",
    "        else:\n",
    "            #put in predicted TN\n",
    "            for index,row in curset.iterrows():\n",
    "                if pd.isnull(row[\"TN\"]):\n",
    "                    #print(\"Predicting \",row[\"LOCATCD\"])\n",
    "                    curset.loc[index,\"PredictedTN\"] = predict(DictTN[row[\"LOCATCD\"]])\n",
    "                else:\n",
    "                    curset.loc[index,\"PredictedTN\"] = row[\"TN\"]\n",
    "            #put in predicted TP\n",
    "            for index,row in curset.iterrows():\n",
    "                if pd.isnull(row[\"TP\"]):\n",
    "                    curset.loc[index,\"PredictedTP\"] = predict(DictTP[row[\"LOCATCD\"]])\n",
    "                else:\n",
    "                    curset.loc[index,\"PredictedTP\"] = row[\"TP\"] \n",
    "                    \n",
    "        qualdata_prediction = qualdata_prediction.append(curset,ignore_index=True)  \n",
    "print(\"Final data set size is \",qualdata_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3635446a-4b36-4c15-9812-4bb1dafb5c15",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'pandas._libs.properties.AxisProperty' object has no attribute 'difference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-04dcd64d9e41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqualdata_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqualdata_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TEMP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'VEL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PredictedTN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'pandas._libs.properties.AxisProperty' object has no attribute 'difference'"
     ]
    }
   ],
   "source": [
    "qualdata_prediction.drop(qualdata_prediction.columns.difference(['TEMP','VEL','PredictedTN']), 1, inplace=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c38fd7-890e-4686-9e1e-25506309dc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TEMP           0\n",
       "VEL            0\n",
       "PredictedTN    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualdata_prediction.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b8908a5-7b6d-4bd5-8468-78f5c553205a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qualdata_prediction.to_excel(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\Predicted_allyear_backwater_Barcode.xlsx\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "974937e9-d515-4351-a46d-c8fc0e04d6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5670, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualdata_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58483f3f-e5da-4cec-af3c-3ae3ea902bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.185, 46.989)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TN\"].min(),data[\"TN\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c25b067-5c9e-44ac-b6e5-eff06b8b5c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "qualdata_prediction = pd.DataFrame\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8195944-a4af-4ccc-a89a-ec79aada843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "pure = filterblanks(cols,data,True)\n",
    "pure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e98c6baa-adf5-4d93-9cef-e95c8208c977",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-32b727685a59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqualdata_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilterblanks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mqualdata_prediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqualdata_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-75293c4ac902>\u001b[0m in \u001b[0;36mfilterblanks\u001b[1;34m(columns, data, blank)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
