{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cleared-politics",
   "metadata": {},
   "source": [
    "Running regression again with mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "played-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wooden-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now adding a year column\n",
      "Now adding a month column\n",
      "Now adding a season column\n",
      "\n",
      " Water data\n",
      "Index(['SHEETBAR', 'DATE', 'LATITUDE', 'LONGITUDE', 'FLDNUM', 'STRATUM',\n",
      "       'LOCATCD', 'TN', 'TP', 'TEMP', 'DO', 'TURB', 'COND', 'VEL', 'SS', 'WDP',\n",
      "       'CHLcal', 'SECCHI', 'YEAR', 'MONTH', 'SEASON'],\n",
      "      dtype='object')\n",
      "(82481, 21)\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "water_path = r\"..\\LTRM data\\water_data_qfneg.csv\"\n",
    "water_data = pd.read_csv(water_path, low_memory = False)\n",
    "\n",
    "continuous = ['TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "seasons = {3:\"SPRING\",4:\"SPRING\",5:\"SPRING\",6:\"SUMMER\",7:\"SUMMER\",8:\"SUMMER\",9:\"FALL\",10:\"FALL\",11:\"FALL\",12:\"WINTER\",1:\"WINTER\",2:\"WINTER\"}\n",
    "\n",
    "print(\"Now adding a year column\")\n",
    "water_data[\"YEAR\"] = pd.DatetimeIndex(water_data[\"DATE\"]).year\n",
    "print(\"Now adding a month column\")\n",
    "water_data[\"MONTH\"] = pd.DatetimeIndex(water_data[\"DATE\"]).month\n",
    "print(\"Now adding a season column\")\n",
    "water_data[\"SEASON\"] = water_data[\"MONTH\"]\n",
    "water_data = water_data.replace({\"SEASON\":seasons})\n",
    "\n",
    "print(\"\\n Water data\")\n",
    "print(water_data.columns)\n",
    "print(water_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "colonial-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing multivariate polynomial interpolation, using every other variable as a predictor besides target variable\n",
      "Imputing Means into missing variables\n",
      "(82481, 21)\n",
      "Filtering out colums that we dont need\n",
      "(82481, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing multivariate polynomial interpolation, using every other variable as a predictor besides target variable\")\n",
    "print(\"Imputing Means into missing variables\")\n",
    "imputed_water_data = water_data.copy()\n",
    "\n",
    "for col in continuous:\n",
    "    imputed_water_data[col].fillna(value=imputed_water_data[col].mean,inplace=True)\n",
    "\n",
    "# Checking to see if we lost any values\n",
    "qualdata = imputed_water_data.dropna(axis=0, how='any', thresh=None, subset=continuous, inplace=False).copy()\n",
    "print(qualdata.shape)\n",
    "print(\"Filtering out colums that we dont need\")\n",
    "qualdata.drop(qualdata.columns.difference(continuous), 1, inplace=True)\n",
    "print(qualdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-interest",
   "metadata": {},
   "source": [
    "Water dataset has no missing variables in any variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "burning-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Building model for  TN\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5491891172e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Good idea to standardize predictor attributes - assumes each variable has a decently normal distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mX_standard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# at fit, convert sparse matrices to csc for optimized computation of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;31m# the quantiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m         X = self._validate_data(X, accept_sparse='csc', estimator=self,\n\u001b[0m\u001b[0;32m   1201\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                                 force_all_finite='allow-nan')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'method'"
     ]
    }
   ],
   "source": [
    "models = [\"TN\",\"TP\",\"VEL\"]\n",
    "degs = [1,2]\n",
    "\n",
    "for var in models:\n",
    "    for deg in degs:\n",
    "        print(\"\\n-----------------------------------\")\n",
    "        print(\"Building model for \",var)\n",
    "        predictors = continuous.copy()\n",
    "        predictors.remove(var)\n",
    "\n",
    "        X = np.array(qualdata[predictors])\n",
    "        y = np.array(qualdata[var])\n",
    "\n",
    "        # Good idea to standardize predictor attributes - assumes each variable has a decently normal distribution\n",
    "        scaler = RobustScaler().fit(X)\n",
    "        X_standard = scaler.transform(X)\n",
    "\n",
    "        # Save the scaler for this model\n",
    "        os.mkdir(\"Regression Models\\\\Imputed_data\\\\\"+var+\"\\\\degree\"+deg)\n",
    "        path = \"Regression Models\\\\Imputed_data\\\\\"+var+\"\\\\degree\"+deg+\"\\\\\"\n",
    "        pickle.dump(scaler,open(path+\"scaler.p\", \"wb\" ))\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_standard, y, train_size=0.8)\n",
    "\n",
    "        # Save train and test sets\n",
    "        pickle.dump(X_train,open(path+\"X_train.p\",\"wb\"))\n",
    "        pickle.dump(X_test,open(path+\"X_test.p\",\"wb\"))\n",
    "        pickle.dump(y_train,open(path+\"y_train.p\",\"wb\"))\n",
    "        pickle.dump(y_test,open(path+\"y_test.p\",\"wb\"))\n",
    "\n",
    "\n",
    "        # Finally, we build the model, fit it to the full training data, and\n",
    "        # estimate its out-of-sample performance by applying it to the test set\n",
    "        best_poly = PolynomialFeatures(deg)\n",
    "        best_lm = LinearRegression(fit_intercept=False)\n",
    "        best_lm.fit(best_poly.fit_transform(X_train), y_train)\n",
    "\n",
    "        pickle.dump(best_lm,open(path+\"best_model_deg\"+str(deg)+\".p\",\"wb\"))\n",
    "        pickle.dump(best_poly,open(path+\"best_poly.p\",\"wb\"))\n",
    "\n",
    "\n",
    "        # Estimate performance on test set:\n",
    "        MSE = np.mean((y_test - best_lm.predict(best_poly.transform(X_test))) ** 2)\n",
    "        RMSE = np.sqrt(MSE)\n",
    "        MAE = np.mean(abs(y_test - best_lm.predict(best_poly.transform(X_test))))\n",
    "        print(f'Degree {deg} polynomial has RMSE = {RMSE:.5f}')\n",
    "        print(f'Degree {deg} polynomial has MAE = {MAE:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-entertainment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
