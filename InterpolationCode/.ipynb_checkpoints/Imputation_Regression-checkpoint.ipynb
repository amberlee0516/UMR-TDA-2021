{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "first-complaint",
   "metadata": {},
   "source": [
    "Running regression again with mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "apart-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "known-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now adding a year column\n",
      "Now adding a month column\n",
      "Now adding a season column\n",
      "\n",
      " Water data\n",
      "Index(['SHEETBAR', 'DATE', 'LATITUDE', 'LONGITUDE', 'FLDNUM', 'STRATUM',\n",
      "       'LOCATCD', 'TN', 'TP', 'TEMP', 'DO', 'TURB', 'COND', 'VEL', 'SS', 'WDP',\n",
      "       'CHLcal', 'SECCHI', 'YEAR', 'MONTH', 'SEASON'],\n",
      "      dtype='object')\n",
      "(82481, 21)\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "water_path = r\"..\\LTRM data\\water_data_qfneg.csv\"\n",
    "water_data = pd.read_csv(water_path, low_memory = False)\n",
    "\n",
    "continuous = ['TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "seasons = {3:\"SPRING\",4:\"SPRING\",5:\"SPRING\",6:\"SUMMER\",7:\"SUMMER\",8:\"SUMMER\",9:\"FALL\",10:\"FALL\",11:\"FALL\",12:\"WINTER\",1:\"WINTER\",2:\"WINTER\"}\n",
    "\n",
    "print(\"Now adding a year column\")\n",
    "water_data[\"YEAR\"] = pd.DatetimeIndex(water_data[\"DATE\"]).year\n",
    "print(\"Now adding a month column\")\n",
    "water_data[\"MONTH\"] = pd.DatetimeIndex(water_data[\"DATE\"]).month\n",
    "print(\"Now adding a season column\")\n",
    "water_data[\"SEASON\"] = water_data[\"MONTH\"]\n",
    "water_data = water_data.replace({\"SEASON\":seasons})\n",
    "\n",
    "print(\"\\n Water data\")\n",
    "print(water_data.columns)\n",
    "print(water_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "awful-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping rows with missing values in target variables\n",
      "(21354, 21)\n"
     ]
    }
   ],
   "source": [
    "target = [\"TP\",\"TN\",\"VEL\"]\n",
    "print(\"Dropping rows with missing values in target variables\")\n",
    "qualdata = water_data.dropna(axis=0,how='any',thresh=None,subset=target,inplace=False)\n",
    "print(qualdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-pontiac",
   "metadata": {},
   "source": [
    "Example for imputing medians into each column, not used after ambers suggesting of imputing separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "coupled-boston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing multivariate polynomial interpolation, using every other variable as a predictor besides target variable\n",
      "Imputing Means into missing variables\n",
      "Median for  TN  is  2.531\n",
      "Median for  TP  is  0.163\n",
      "Median for  TEMP  is  14.7\n",
      "Median for  DO  is  9.7\n",
      "Median for  TURB  is  21.0\n",
      "Median for  COND  is  462.0\n",
      "Median for  VEL  is  0.1\n",
      "Median for  SS  is  25.7\n",
      "Median for  WDP  is  2.24\n",
      "Median for  CHLcal  is  16.65\n",
      "Median for  SECCHI  is  41.0\n",
      "(82481, 21)\n",
      "Filtering out colums that we dont need\n",
      "(82481, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing multivariate polynomial interpolation, using every other variable as a predictor besides target variable\")\n",
    "print(\"Imputing medians\")\n",
    "imputed_water_data = water_data.copy()\n",
    "\n",
    "for col in continuous:\n",
    "    median = imputed_water_data[col].median()\n",
    "    print(\"Median for \",col,\" is \",round(median,4))\n",
    "    imputed_water_data[col].fillna(value=median,inplace=True)\n",
    "\n",
    "# Checking to see if we lost any values\n",
    "qualdata = imputed_water_data.dropna(axis=0, how='any', thresh=None, subset=continuous, inplace=False)\n",
    "print(qualdata.shape)\n",
    "print(\"Filtering out colums that we dont need\")\n",
    "qualdata.drop(qualdata.columns.difference(continuous), axis=1, inplace=True)\n",
    "print(qualdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-twenty",
   "metadata": {},
   "source": [
    "Water dataset has no missing variables in any variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "satisfactory-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"Regression Models\\\\Imputed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "funny-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = continuous.copy()\n",
    "predictors.remove(var)\n",
    "\n",
    "X = np.array(qualdata[predictors])\n",
    "y = np.array(qualdata[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "thick-brooks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get median of first attribute\n",
    "np.median([item[2] for item in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bearing-collapse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "instructional-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Building model for  TN\n",
      "Degree 1 polynomial has RMSE = 1.66223\n",
      "Degree 1 polynomial has MAE = 0.51931\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  TN\n",
      "Degree 2 polynomial has RMSE = 2.00489\n",
      "Degree 2 polynomial has MAE = 0.52310\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  TP\n",
      "Degree 1 polynomial has RMSE = 0.09866\n",
      "Degree 1 polynomial has MAE = 0.05231\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  TP\n",
      "Degree 2 polynomial has RMSE = 0.10723\n",
      "Degree 2 polynomial has MAE = 0.05288\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  VEL\n",
      "Degree 1 polynomial has RMSE = 0.30540\n",
      "Degree 1 polynomial has MAE = 0.18037\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  VEL\n",
      "Degree 2 polynomial has RMSE = 0.28660\n",
      "Degree 2 polynomial has MAE = 0.16802\n"
     ]
    }
   ],
   "source": [
    "models = [\"TN\",\"TP\",\"VEL\"]\n",
    "degs = [1,2]\n",
    "\n",
    "for var in models:\n",
    "    os.mkdir(\"Regression Models\\\\Imputed_data\\\\\"+var)\n",
    "    for deg in degs:\n",
    "        print(\"\\n-----------------------------------\")\n",
    "        print(\"Building model for \",var)\n",
    "        predictors = continuous.copy()\n",
    "        predictors.remove(var)\n",
    "\n",
    "        X = np.array(qualdata[predictors])\n",
    "        y = np.array(qualdata[var])\n",
    "\n",
    "\n",
    "        # Save the scaler for this model\n",
    "        os.mkdir(\"Regression Models\\\\Imputed_data\\\\\"+var+\"\\\\degree\"+str(deg))\n",
    "        path = \"Regression Models\\\\Imputed_data\\\\\"+var+\"\\\\degree\"+str(deg)+\"\\\\\"\n",
    "\n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "        \n",
    "        # Impute medians for X_train\n",
    "        for index in len\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Good idea to standardize predictor attributes - assumes each variable has a decently normal distribution\n",
    "        scaler = RobustScaler().fit(X_train)\n",
    "        X_standard = scaler.transform(X_train)\n",
    "        \n",
    "        pickle.dump(scaler,open(path+\"scaler.p\", \"wb\" ))\n",
    "\n",
    "        # Save train and test sets\n",
    "        pickle.dump(X_train,open(path+\"X_train.p\",\"wb\"))\n",
    "        pickle.dump(X_test,open(path+\"X_test.p\",\"wb\"))\n",
    "        pickle.dump(y_train,open(path+\"y_train.p\",\"wb\"))\n",
    "        pickle.dump(y_test,open(path+\"y_test.p\",\"wb\"))\n",
    "\n",
    "\n",
    "        # Finally, we build the model, fit it to the full training data, and\n",
    "        # estimate its out-of-sample performance by applying it to the test set\n",
    "        best_poly = PolynomialFeatures(deg)\n",
    "        best_lm = LinearRegression(fit_intercept=False)\n",
    "        best_lm.fit(best_poly.fit_transform(X_train), y_train)\n",
    "\n",
    "        pickle.dump(best_lm,open(path+\"best_model_deg\"+str(deg)+\".p\",\"wb\"))\n",
    "        pickle.dump(best_poly,open(path+\"best_poly.p\",\"wb\"))\n",
    "\n",
    "\n",
    "        # Estimate performance on test set:\n",
    "        MSE = np.mean((y_test - best_lm.predict(best_poly.transform(X_test))) ** 2)\n",
    "        RMSE = np.sqrt(MSE)\n",
    "        MAE = np.mean(abs(y_test - best_lm.predict(best_poly.transform(X_test))))\n",
    "        print(f'Degree {deg} polynomial has RMSE = {RMSE:.5f}')\n",
    "        print(f'Degree {deg} polynomial has MAE = {MAE:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-defendant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
