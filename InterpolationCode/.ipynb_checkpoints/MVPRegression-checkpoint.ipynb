{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "helpful-biodiversity",
   "metadata": {},
   "source": [
    "# Multivariate Polynomial Regression Interpolation\n",
    "## Degrees 1 and 2\n",
    "### Written and compiled by Casey McKean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-dietary",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metric-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler,PolynomialFeatures\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-field",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addressed-karaoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns we don't need\n",
      "Setting TN outliers to NA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.44875</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.876</td>\n",
       "      <td>0.229</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.24230</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.72488</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.257</td>\n",
       "      <td>0.212</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.48359</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.52918</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TN     TP  TEMP   DO  TURB   COND  VEL    SS  WDP   CHLcal  SECCHI\n",
       "0    NaN    NaN  23.0  6.6  28.0  550.0  NaN  42.3  2.2  9.44875    40.0\n",
       "1  4.876  0.229  23.0  6.6  28.0  554.0  NaN  37.6  8.2  8.24230    42.0\n",
       "2    NaN    NaN  22.9  6.3  24.0  564.0  NaN  34.1  4.3  8.72488    43.0\n",
       "3  4.257  0.212  22.9  6.4  28.0  563.0  NaN  33.4  9.1  8.48359    38.0\n",
       "4    NaN    NaN  23.0  6.6  33.0  556.0  NaN  48.0  6.7  9.52918    45.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"..\\LTRM data\\water_data_qfneg.csv\"\n",
    "water_data = pd.read_csv(filepath, low_memory = False)\n",
    "\n",
    "# Define our continuous variables\n",
    "continuous = ['TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "\n",
    "print(\"Dropping columns we don't need\")\n",
    "water_data.drop(water_data.columns.difference(continuous), axis = 1, inplace=True)\n",
    "\n",
    "# Set to NA\n",
    "print(\"Setting TN outliers to NA\")\n",
    "water_data.loc[46795,\"TN\"] = None\n",
    "water_data.loc[46545,\"TN\"] = None\n",
    "water_data.loc[46727,\"TN\"] = None\n",
    "\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-azerbaijan",
   "metadata": {},
   "source": [
    "### Build models and report errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fifteen-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Building model for  TN  degree  1\n",
      "Removing rows with missing  TN  values\n",
      "Imputing missing values with median for predictor variables\n",
      "Train set size:  25748\n",
      "Test set size:  6437\n",
      "The MAE is 0.852447\n",
      "The RMSE is 1.176410\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  TN  degree  2\n",
      "Removing rows with missing  TN  values\n",
      "Imputing missing values with median for predictor variables\n",
      "Train set size:  25748\n",
      "Test set size:  6437\n",
      "The MAE is 0.816302\n",
      "The RMSE is 1.126301\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  TP  degree  1\n",
      "Removing rows with missing  TP  values\n",
      "Imputing missing values with median for predictor variables\n",
      "Train set size:  25160\n",
      "Test set size:  6290\n",
      "The MAE is 0.067799\n",
      "The RMSE is 0.124557\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  TP  degree  2\n",
      "Removing rows with missing  TP  values\n",
      "Imputing missing values with median for predictor variables\n",
      "Train set size:  25160\n",
      "Test set size:  6290\n",
      "The MAE is 0.056976\n",
      "The RMSE is 0.110062\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  VEL  degree  1\n",
      "Removing rows with missing  VEL  values\n",
      "Imputing missing values with median for predictor variables\n",
      "Train set size:  44944\n",
      "Test set size:  11236\n",
      "The MAE is 0.181757\n",
      "The RMSE is 0.330505\n",
      "\n",
      "-----------------------------------\n",
      "Building model for  VEL  degree  2\n",
      "Removing rows with missing  VEL  values\n",
      "Imputing missing values with median for predictor variables\n",
      "Train set size:  44944\n",
      "Test set size:  11236\n",
      "The MAE is 0.167653\n",
      "The RMSE is 0.316970\n"
     ]
    }
   ],
   "source": [
    "degrees = [1,2]\n",
    "models = ['TN','TP','VEL']\n",
    "\n",
    "# Pick a random seed to ensure reproducability\n",
    "seed = 13\n",
    "\n",
    "\n",
    "for var in models:\n",
    "    for deg in degrees:\n",
    "        print(\"\\n-----------------------------------\")\n",
    "        print(\"Building model for \",var,\" degree \",str(deg))\n",
    "        \n",
    "        # Predictors for this variable are every other variable\n",
    "        predictors = continuous.copy()\n",
    "        predictors.remove(var)\n",
    "        \n",
    "        print(\"Removing rows with missing \",var,\" values\")\n",
    "        cur_data = water_data[water_data[var].notna()].copy()\n",
    "        print(\"Imputing missing values with median for predictor variables\")\n",
    "        cur_data.fillna(cur_data.median(),inplace=True)\n",
    "    \n",
    "        X = np.array(cur_data[predictors])\n",
    "        y = np.array(cur_data[var])\n",
    "    \n",
    "        # Good idea to standardize predictor attributes for numerical stability\n",
    "        scaler = RobustScaler().fit(X)\n",
    "        X_standard = scaler.transform(X)\n",
    "\n",
    "        # Optional save scaler for this model (adjust path accordingly)\n",
    "        #path = \"Regression Models\\\\\"+var+\"extra\\\\\"\n",
    "        #pickle.dump(scaler,open(path+\"scaler.p\", \"wb\" ))\n",
    "    \n",
    "        # Split data into training and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_standard, y, train_size=0.8,random_state=seed)\n",
    "    \n",
    "        # Save train and test sets\n",
    "        #pickle.dump(X_train,open(path+\"X_train.p\",\"wb\"))\n",
    "        #pickle.dump(X_test,open(path+\"X_test.p\",\"wb\"))\n",
    "        #pickle.dump(y_train,open(path+\"y_train.p\",\"wb\"))\n",
    "        #pickle.dump(y_test,open(path+\"y_test.p\",\"wb\"))\n",
    "        print(\"Train set size: \",len(X_train))\n",
    "        print(\"Test set size: \",len(y_test))\n",
    "    \n",
    "        # Create the polynomial features of the current degree\n",
    "        poly = PolynomialFeatures(deg)\n",
    "        \n",
    "        # Create regression model fit intercept isn't needed becuase polynomial features added a 1 feature already\n",
    "        lm = LinearRegression(fit_intercept=False)\n",
    "        lm.fit(poly.fit_transform(X_train), y_train)\n",
    "    \n",
    "        # Save the model\n",
    "        #pickle.dump(best_lm,open(path+\"best_model_deg\"+str(deg)+\".p\",\"wb\"))\n",
    "        #pickle.dump(best_poly,open(path+\"best_poly.p\",\"wb\"))\n",
    "\n",
    "        # Calculate and report errors on the test set\n",
    "        MAE = sklearn.metrics.mean_absolute_error(y_test,lm.predict(poly.transform(X_test)))\n",
    "        RMSE = sklearn.metrics.mean_squared_error(y_test,lm.predict(poly.transform(X_test)),squared=False)\n",
    "        print(f\"The MAE is {MAE:8f}\")\n",
    "        print(f\"The RMSE is {RMSE:8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
