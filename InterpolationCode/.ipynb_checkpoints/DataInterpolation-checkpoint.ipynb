{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dress-underground",
   "metadata": {},
   "source": [
    "# Imports\n",
    "This the script for prepossing the data to create data ready for the TDA mapper algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "applicable-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from geopy import distance\n",
    "import math\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "print(\"imports done\")\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-benchmark",
   "metadata": {},
   "source": [
    "# File\n",
    "From the resulting `R` script written by Amber and `python` script written by Alaina, grab the cleaned data file. The `R` file can be found in the github repository and is called `water cleaning data.Rmd` and is in the WaterCleaning folder. Secondly, run it through the `python` script called `Data_Collapse.ipynb`. From here, this will result in the `cleaned_data.csv` file. This can found in the github repo as well. Download it, and edit the file path if necessary to read in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "focal-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataFrame Made\n"
     ]
    }
   ],
   "source": [
    "filePath = r\"..\\LTRM data\\water_data_qfneg.csv\"\n",
    "dataFrame = pd.read_csv(filePath, low_memory = False)\n",
    "print(\"dataFrame Made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-determination",
   "metadata": {},
   "source": [
    "# Filter for your pool\n",
    "Resets the index as well. This is done through the `FLDNUM` parameter, and can be found in accompanying documentation for the correct pool number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14200, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45000007</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.329886</td>\n",
       "      <td>-89.475046</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>8.45574</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45000008</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.322015</td>\n",
       "      <td>-89.452852</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.67430</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45000009</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.372969</td>\n",
       "      <td>-89.409812</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353048</td>\n",
       "      <td>3.376</td>\n",
       "      <td>0.339</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.06502</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45000010</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.327006</td>\n",
       "      <td>-89.439079</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.50022</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45000011</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.329954</td>\n",
       "      <td>-89.477299</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.80390</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR        DATE   LATITUDE  LONGITUDE  FLDNUM  STRATUM  LOCATCD  \\\n",
       "0  45000007  09/15/1993  37.329886 -89.475046       5        2  9353150   \n",
       "1  45000008  09/15/1993  37.322015 -89.452852       5        2  9353152   \n",
       "2  45000009  09/15/1993  37.372969 -89.409812       5        2  9353048   \n",
       "3  45000010  09/15/1993  37.327006 -89.439079       5        2  9353151   \n",
       "4  45000011  09/15/1993  37.329954 -89.477299       5        2  9353149   \n",
       "\n",
       "      TN     TP  TEMP   DO  TURB   COND  VEL     SS   WDP   CHLcal  SECCHI  \n",
       "0    NaN    NaN  20.7  7.3  69.0  463.0  NaN  125.0  16.1  8.45574    16.0  \n",
       "1    NaN    NaN  20.6  7.4  66.0  465.0  NaN  121.8  11.5  9.67430    16.0  \n",
       "2  3.376  0.339  21.0  7.3  64.0  480.0  NaN  105.3  10.5  9.06502    14.0  \n",
       "3    NaN    NaN  20.7  7.3  66.0  470.0  NaN  127.2   9.9  9.50022    16.0  \n",
       "4    NaN    NaN  20.6  7.3  65.0  463.0  NaN  117.8   8.3  8.80390    16.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame = dataFrame[dataFrame['FLDNUM'] == 5]\n",
    "print(dataFrame.shape)\n",
    "dataFrame  = dataFrame.reset_index(drop = True)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-office",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Here, we interpolate for missing data values. These occur when the data set has a missing value. The way it is computed utilizes a $k$-nearest neighbors algorithm. A weighted average using the $k$ nearest points is used to compute the missing value, and it appends it to a new column in the data set called `\"PREDICTED_\" + variable`, where `variable` is what we wish to interpolate (`TN` or `TP`) for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "soviet-crime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions have been loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Params:\n",
    "df = the dataframe filtered for the pool\n",
    "hashtable = the hash table of distances of each point for the data frame. (Created from construct_hashtable)\n",
    "naVar = the variable we wish to interpolate\n",
    "year = the year we wish to predict for\n",
    "k = the number of terms in the weighted average for interpolation\n",
    "\n",
    "NOTE: for now, set k = 2 due to potential bug for larger k\n",
    "\n",
    "This is one of two predict functions. \n",
    "Here, multiple years worth of data can put in, and only the specified year will be predicted\n",
    "and added to the dataframe. Note that this function will find the k nearnest neighbors using df,\n",
    "regardless of year.\n",
    "\"\"\"\n",
    "def predict_years(df, hashtable, naVar, year, k):\n",
    "    df[\"PREDICTED_\" + naVar] = df[naVar]\n",
    "    df_year = df.copy()\n",
    "    df_year = df_year[df_year[\"YEAR\"] == year]\n",
    "    naIndices = df_year[(df_year[naVar].isnull())]\n",
    "    print(\"For \" + naVar + \" we will interpolate \" + str(len(naIndices)) + \" points.\")\n",
    "    for index, row in naIndices.iterrows():\n",
    "        distances, neighbors = k_nearest_neighbors(df, index, naVar, hashtable, k)\n",
    "        df.loc[index, \"PREDICTED_\" + naVar] = interpolate(df, distances, neighbors, naVar)\n",
    "    print(naVar + \" interpolation success\")\n",
    "\"\"\"\n",
    "Params:\n",
    "df = the dataframe filtered for the pool\n",
    "hashtable = the hash table of distances of each point for the data frame.\n",
    "naVar = the variable we wish to interpolate\n",
    "k = the number of terms in the weighted average for interpolation\n",
    "\n",
    "NOTE: for now, keep k = 2 due to potential bug for k > 2\n",
    "\n",
    "This predict function is more crude than predict_years. It will predict using missing values of naVar for \n",
    "the entire dataframe, using the entire dataframe to locate the k nearnest neighbors.\n",
    "\"\"\"\n",
    "def predict(df, hashtable, naVar, k):\n",
    "    df[\"PREDICTED_\" + naVar] = df[naVar]\n",
    "    naIndices = df[(df[naVar].isnull())]\n",
    "    print(\"For \" + naVar + \" we will interpolate \" + str(len(naIndices)) + \" points.\")\n",
    "    for index, row in naIndices.iterrows():\n",
    "        distances, neighbors = k_nearest_neighbors(df, index, naVar, hashtable, k)\n",
    "        df.loc[index, \"PREDICTED_\" + naVar] = interpolate(df, distances, neighbors, naVar)\n",
    "    print(naVar + \" interpolation success\")\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "params:\n",
    "\n",
    "minimums = lower bound of data, typically latitude or longitude\n",
    "maximums = upper bound of data, typically latitude or longitude\n",
    "x = data we wish to transfrom in to [0,1], typically a latitude or a longitude\n",
    "\n",
    "This is a helper function for construct_hashtable and k_nearest_neighbors. It takes in a latitude or\n",
    "a longitude and maps to in to [0,1] so the point can be plotted properly in the hashtable\n",
    "\"\"\"    \n",
    "    \n",
    "def transform(minimum, maximum, x):\n",
    "    return (1 / (maximum - minimum) ) * (x - minimum)\n",
    "\"\"\"\n",
    "Params:\n",
    "point 1 = First point (latitude and longitude)\n",
    "point 2 = Second point (latitude and longitude)\n",
    "\n",
    "Returns the distance in kilometers between two points in space, using\n",
    "scipy distance function.\n",
    "\"\"\"\n",
    "def dist(point1, point2):\n",
    "    return distance.distance(point1, point2).km\n",
    "\"\"\"\n",
    "params:\n",
    "df = the dataframe\n",
    "\n",
    "returns: hashtable (list of lists of lists of tuples(index, latitude, longitude))\n",
    "\n",
    "Constructs a hash table of locations of points (the position where data is recorded)\n",
    "This is used in the k nearest neighbors algorithm. Locations that are near each other in space\n",
    "are near each other in the hashtable\n",
    "\n",
    "\"\"\"    \n",
    "def construct_hashtable(df):\n",
    "    #get hashtable information\n",
    "    data_length = math.sqrt(df.shape[0])\n",
    "    #print(\"data_length: \" + str(data_length))\n",
    "    interval_length = 1 / data_length\n",
    "    lat_minimum = df[[\"LATITUDE\"]].min()[0] - 1\n",
    "    lat_maximum = df[[\"LATITUDE\"]].max()[0] + 1\n",
    "    long_minimum = df[[\"LONGITUDE\"]].min()[0] - 1\n",
    "    long_maximum = df[[\"LONGITUDE\"]].max()[0] + 1\n",
    "    \n",
    "    #construct hashtable\n",
    "    hashtable = [[[] for x in range(int(data_length)+1)] for y in range(int(data_length)+1)]\n",
    "    \n",
    "    #populate hashtable\n",
    "    for index, row in df.iterrows():\n",
    "        r_lat = row['LATITUDE']\n",
    "        r_long = row['LONGITUDE']\n",
    "        lat = math.floor(transform(lat_minimum, lat_maximum, r_lat) / interval_length)\n",
    "        long = math.floor(transform(long_minimum, long_maximum, r_long) / interval_length)\n",
    "        #print(\"lat: \" + str(lat))\n",
    "        #print(\"long: \" + str(long))\n",
    "        hashtable[lat][long].append((index, r_lat, r_long))\n",
    "\n",
    "    return hashtable\n",
    "\"\"\"\n",
    "Params:\n",
    "df = dataframe\n",
    "index = index of variable we wish to find k nearest neighbors of\n",
    "naVar = variable to predict\n",
    "hashtable = data structure created from construct_hashtable\n",
    "k = number of nearest neighbors\n",
    "\n",
    "Returns: (distances, indices) of k nearnest neighbors\n",
    "\n",
    "This algorithm will find the k nearest neighbors of a desired point using the hashtable, if possible.\n",
    "If there are no valid points near the given point, then the algorithm will use brute force\n",
    "\"\"\"\n",
    "def k_nearest_neighbors(df, index, naVar, hashtable, k):\n",
    "\n",
    "    distances = []\n",
    "    neighbor_indices = []\n",
    "    neighbors = {}\n",
    "    \n",
    "    data_length = math.sqrt(df.shape[0])\n",
    "    interval_length = 1 / data_length\n",
    "    lat_minimum = df[[\"LATITUDE\"]].min()[0] - 1\n",
    "    lat_maximum = df[[\"LATITUDE\"]].max()[0] + 1\n",
    "    long_minimum = df[[\"LONGITUDE\"]].min()[0] - 1\n",
    "    long_maximum = df[[\"LONGITUDE\"]].max()[0] + 1\n",
    "    \n",
    "    \n",
    "    row_na = df.loc[index]\n",
    "    point_na = (row_na['LATITUDE'], row_na['LONGITUDE'])\n",
    "    lat = math.floor(transform(lat_minimum, lat_maximum, point_na[0]) / interval_length)\n",
    "    long = math.floor(transform(long_minimum, long_maximum, point_na[1]) / interval_length)\n",
    "    season = row_na['SEASON']\n",
    "    \n",
    "    for inx, latitude, longitude in hashtable[lat][long]:\n",
    "        distance_km = dist(point_na, (latitude, longitude))\n",
    "        if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "            distances.append(distance_km)\n",
    "            if distance_km in neighbors.keys():\n",
    "                neighbors[distance_km].append(inx)\n",
    "            else:\n",
    "                neighbors[distance_km] = [inx]\n",
    "    \n",
    "    if lat != 0:\n",
    "        \n",
    "        for inx, latitude, longitude in hashtable[lat - 1][long]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "                    \n",
    "        if long != 0:\n",
    "            for inx, latitude, longitude in hashtable[lat - 1][long - 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "        if long + 1 != len(hashtable):\n",
    "            for inx, latitude, longitude in hashtable[lat - 1][long + 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if lat + 1 != len(hashtable):\n",
    "        \n",
    "        for inx, latitude, longitude in hashtable[lat + 1][long]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "                    \n",
    "        if long != 0:\n",
    "            for inx, latitude, longitude in hashtable[lat + 1][long - 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "        if long + 1 != len(hashtable):\n",
    "            for inx, latitude, longitude in hashtable[lat + 1][long + 1]:\n",
    "                distance_km = dist(point_na, (latitude, longitude))\n",
    "                if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                    distances.append(distance_km)\n",
    "                    if distance_km in neighbors.keys():\n",
    "                        neighbors[distance_km].append(inx)\n",
    "                    else:\n",
    "                        neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if long != 0:\n",
    "        for inx, latitude, longitude in hashtable[lat][long - 1]:\n",
    "            distance_km = dist(point_na, (latitude, longitude))\n",
    "            if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                distances.append(distance_km)\n",
    "                if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "                else:\n",
    "                    neighbors[distance_km] = [inx]\n",
    "        \n",
    "    if long + 1 != len(hashtable):\n",
    "        for inx, latitude, longitude in hashtable[lat][long + 1]:\n",
    "            distance_km = dist(point_na, (latitude, longitude))\n",
    "            if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "                distances.append(distance_km)\n",
    "                if distance_km in neighbors.keys():\n",
    "                    neighbors[distance_km].append(inx)\n",
    "                else:\n",
    "                    neighbors[distance_km] = [inx]\n",
    "                    \n",
    "    #Possible bug with neighbor dictionary for k > 2\n",
    "    distances.sort()\n",
    "    distances = distances[0:k]\n",
    "    for distance_km in distances:\n",
    "        for inx in neighbors[distance_km]:\n",
    "            neighbor_indices.append(inx)\n",
    "    neighbor_indices = neighbor_indices[0:k]\n",
    "    if len(neighbor_indices) < k and len(neighbor_indices) != 0:\n",
    "        print(\"INTERPOLATING WITH \" + str(len(neighbor_indices)) + \" POINTS INSTEAD OF \" + str(k) + \" POINTS\")\n",
    "    if len(neighbor_indices) >= 2:\n",
    "        return (distances, neighbor_indices)\n",
    "    \n",
    "    #Possible bug with neighbor dictionary for k > 2\n",
    "    distances = []\n",
    "    neighbors = {}\n",
    "    neighbor_indices = []\n",
    "    for inx, row in df.iterrows():\n",
    "        distance_km = dist(point_na, (row['LATITUDE'], row['LONGITUDE']))\n",
    "        if not np.isnan(df.loc[inx][naVar]) and distance_km != 0:\n",
    "            distances.append(distance_km)\n",
    "            if distance_km in neighbors.keys():\n",
    "                neighbors[distance_km].append(inx)\n",
    "            else:\n",
    "                neighbors[distance_km] = [inx]\n",
    "    distances.sort()\n",
    "    distances = distances[0:k]\n",
    "    for distance_km in distances:\n",
    "        for inx in neighbors[distance_km]:\n",
    "            neighbor_indices.append(inx)\n",
    "    neighbor_indices = neighbor_indices[0:k]\n",
    "    return (distances, neighbor_indices)            \n",
    "    \n",
    "\"\"\"\n",
    "Params:\n",
    "df = dataframe\n",
    "distances = distances of the points being used to interpolate for the missing value \n",
    "neighbors  = the points for prediction\n",
    "naVar = variable to predict\n",
    "\n",
    "Returns the interpolated data value for a missing datapoint.\n",
    "\"\"\"\n",
    "def interpolate(df, distances, neighbors, naVar):\n",
    "    result = 0\n",
    "    denominator = [1 / x for x in distances]\n",
    "    denominator = sum(denominator)\n",
    "    for i in range(len(distances)):\n",
    "        result += ((1/distances[i]) / denominator) * df.loc[neighbors[i]][naVar]\n",
    "    return result\n",
    "print(\"Functions have been loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-trinity",
   "metadata": {},
   "source": [
    "# Season by Season Interpolation\n",
    "Here, we begin the process of interpolating for missing data based upon the season. To do this, the dataframe we input needs a season column. To obtain this, we create a copy of the dataframe, and use this copy throughout the rest of the work. To obtain the season, we utilize the date recorded to get the season. We create a column for the particular month, and then use a dictionary to replace that value with the appropriate season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "single-favorite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45000007</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.329886</td>\n",
       "      <td>-89.475046</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>8.45574</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45000008</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.322015</td>\n",
       "      <td>-89.452852</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.67430</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45000009</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.372969</td>\n",
       "      <td>-89.409812</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353048</td>\n",
       "      <td>3.376</td>\n",
       "      <td>0.339</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.06502</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45000010</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.327006</td>\n",
       "      <td>-89.439079</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>66.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.50022</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45000011</td>\n",
       "      <td>09/15/1993</td>\n",
       "      <td>37.329954</td>\n",
       "      <td>-89.477299</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9353149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.80390</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9</td>\n",
       "      <td>FALL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR        DATE   LATITUDE  LONGITUDE  FLDNUM  STRATUM  LOCATCD  \\\n",
       "0  45000007  09/15/1993  37.329886 -89.475046       5        2  9353150   \n",
       "1  45000008  09/15/1993  37.322015 -89.452852       5        2  9353152   \n",
       "2  45000009  09/15/1993  37.372969 -89.409812       5        2  9353048   \n",
       "3  45000010  09/15/1993  37.327006 -89.439079       5        2  9353151   \n",
       "4  45000011  09/15/1993  37.329954 -89.477299       5        2  9353149   \n",
       "\n",
       "      TN     TP  TEMP   DO  TURB   COND  VEL     SS   WDP   CHLcal  SECCHI  \\\n",
       "0    NaN    NaN  20.7  7.3  69.0  463.0  NaN  125.0  16.1  8.45574    16.0   \n",
       "1    NaN    NaN  20.6  7.4  66.0  465.0  NaN  121.8  11.5  9.67430    16.0   \n",
       "2  3.376  0.339  21.0  7.3  64.0  480.0  NaN  105.3  10.5  9.06502    14.0   \n",
       "3    NaN    NaN  20.7  7.3  66.0  470.0  NaN  127.2   9.9  9.50022    16.0   \n",
       "4    NaN    NaN  20.6  7.3  65.0  463.0  NaN  117.8   8.3  8.80390    16.0   \n",
       "\n",
       "   MONTH SEASON  \n",
       "0      9   FALL  \n",
       "1      9   FALL  \n",
       "2      9   FALL  \n",
       "3      9   FALL  \n",
       "4      9   FALL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = dataFrame.copy()\n",
    "newData[\"MONTH\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).month\n",
    "newData[\"SEASON\"] = newData[\"MONTH\"]\n",
    "seasons = {3 : 'SPRING',\n",
    "           4 : 'SPRING',\n",
    "           5 : 'SPRING',\n",
    "           6 : 'SUMMER',\n",
    "           7 : 'SUMMER',\n",
    "           8 : 'SUMMER',\n",
    "           9 : 'FALL',\n",
    "           10 : 'FALL',\n",
    "           11: 'FALL',\n",
    "           12: 'WINTER',\n",
    "           1: 'WINTER',\n",
    "           2: 'WINTER'}\n",
    "newData = newData.replace({\"SEASON\" : seasons})\n",
    "# for index, row in newData.iterrows():\n",
    "#     newData.loc[index, 'SEASON'] = seasons\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-rental",
   "metadata": {},
   "source": [
    "# Prediction Group by Season and several years\n",
    "\n",
    "Here, we interpolate missing data values for a certain year, grouping data by season. For example, we can use spring data from 2001, 2002, and 2003 to predict spring data for 2002. In the list below, `x` represents the year we predict. Modify the lower bound to be the earliest year of data that you have.\n",
    "\n",
    "Then, we create a year column on the data frame to allow the predict function to get the correct year for prediction purposes. Then, we interpolate data values year by year, season by season. After it is done, it sends the output to a `.csv` file, so modify the path as necessary. The `if (seasonFrame.shape[0] > 1)` is a check to make sure there is enough data present to do any interpolating, since we use `2` points to predict a missing third here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "multiple-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of years: [1994, 1995, 1996]\n",
      "Year to interpolate missing data: 1995\n",
      "SPRING\n",
      "SUMMER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 2 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 2 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 1995\n",
      "Set of years: [1995, 1996, 1997]\n",
      "Year to interpolate missing data: 1996\n",
      "SPRING\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 35 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 145 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 1996\n",
      "Set of years: [1996, 1997, 1998]\n",
      "Year to interpolate missing data: 1997\n",
      "SPRING\n",
      "For TN we will interpolate 55 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 55 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 53 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 53 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 51 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 51 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 41 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 41 points.\n",
      "TP interpolation success\n",
      "Predicted for 1997\n",
      "Set of years: [1997, 1998, 1999]\n",
      "Year to interpolate missing data: 1998\n",
      "SPRING\n",
      "For TN we will interpolate 52 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 52 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 52 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 52 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 52 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 52 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 48 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 48 points.\n",
      "TP interpolation success\n",
      "Predicted for 1998\n",
      "Set of years: [1998, 1999, 2000]\n",
      "Year to interpolate missing data: 1999\n",
      "SPRING\n",
      "For TN we will interpolate 54 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 53 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 42 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 42 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 51 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 51 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 43 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 43 points.\n",
      "TP interpolation success\n",
      "Predicted for 1999\n",
      "Set of years: [1999, 2000, 2001]\n",
      "Year to interpolate missing data: 2000\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 78 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 68 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 67 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 42 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 42 points.\n",
      "TP interpolation success\n",
      "Predicted for 2000\n",
      "Set of years: [2000, 2001, 2002]\n",
      "Year to interpolate missing data: 2001\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 84 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 66 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 66 points.\n",
      "TP interpolation success\n",
      "Predicted for 2001\n",
      "Set of years: [2001, 2002, 2003]\n",
      "Year to interpolate missing data: 2002\n",
      "SPRING\n",
      "For TN we will interpolate 66 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 66 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 75 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 74 points.\n",
      "TP interpolation success\n",
      "Predicted for 2002\n",
      "Set of years: [2002, 2003, 2004]\n",
      "Year to interpolate missing data: 2003\n",
      "SPRING\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "Predicted for 2003\n",
      "Set of years: [2003, 2004, 2005]\n",
      "Year to interpolate missing data: 2004\n",
      "SPRING\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 79 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 27 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 27 points.\n",
      "TP interpolation success\n",
      "Predicted for 2004\n",
      "Set of years: [2004, 2005, 2006]\n",
      "Year to interpolate missing data: 2005\n",
      "SPRING\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 78 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 73 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 73 points.\n",
      "TP interpolation success\n",
      "Predicted for 2005\n",
      "Set of years: [2005, 2006, 2007]\n",
      "Year to interpolate missing data: 2006\n",
      "SPRING\n",
      "For TN we will interpolate 74 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 75 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 75 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 75 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "Predicted for 2006\n",
      "Set of years: [2006, 2007, 2008]\n",
      "Year to interpolate missing data: 2007\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 76 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 76 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 72 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 72 points.\n",
      "TP interpolation success\n",
      "Predicted for 2007\n",
      "Set of years: [2007, 2008, 2009]\n",
      "Year to interpolate missing data: 2008\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 76 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 76 points.\n",
      "TP interpolation success\n",
      "Predicted for 2008\n",
      "Set of years: [2008, 2009, 2010]\n",
      "Year to interpolate missing data: 2009\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 68 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 68 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 77 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 77 points.\n",
      "TP interpolation success\n",
      "Predicted for 2009\n",
      "Set of years: [2009, 2010, 2011]\n",
      "Year to interpolate missing data: 2010\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 79 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 79 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 76 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 76 points.\n",
      "TP interpolation success\n",
      "Predicted for 2010\n",
      "Set of years: [2010, 2011, 2012]\n",
      "Year to interpolate missing data: 2011\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 77 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 77 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 75 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 75 points.\n",
      "TP interpolation success\n",
      "Predicted for 2011\n",
      "Set of years: [2011, 2012, 2013]\n",
      "Year to interpolate missing data: 2012\n",
      "SPRING\n",
      "For TN we will interpolate 42 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 42 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 65 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 65 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 71 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 71 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "Predicted for 2012\n",
      "Set of years: [2012, 2013, 2014]\n",
      "Year to interpolate missing data: 2013\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 79 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 79 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "Predicted for 2013\n",
      "Set of years: [2013, 2014, 2015]\n",
      "Year to interpolate missing data: 2014\n",
      "SPRING\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 81 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 81 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 38 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 38 points.\n",
      "TP interpolation success\n",
      "Predicted for 2014\n",
      "Set of years: [2014, 2015, 2016]\n",
      "Year to interpolate missing data: 2015\n",
      "SPRING\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 78 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 78 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 78 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 81 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 81 points.\n",
      "TP interpolation success\n",
      "Predicted for 2015\n",
      "Set of years: [2015, 2016, 2017]\n",
      "Year to interpolate missing data: 2016\n",
      "SPRING\n",
      "For TN we will interpolate 74 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 76 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 54 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 54 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "Predicted for 2016\n",
      "Set of years: [2016, 2017, 2018]\n",
      "Year to interpolate missing data: 2017\n",
      "SPRING\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 64 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 64 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "Predicted for 2017\n",
      "Set of years: [2017, 2018, 2019]\n",
      "Year to interpolate missing data: 2018\n",
      "SPRING\n",
      "For TN we will interpolate 74 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 74 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 69 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 69 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 58 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 58 points.\n",
      "TP interpolation success\n",
      "Predicted for 2018\n",
      "Set of years: [2018, 2019, 2020]\n",
      "Year to interpolate missing data: 2019\n",
      "SPRING\n",
      "For TN we will interpolate 38 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 38 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 70 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 70 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 80 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 80 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 38 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 38 points.\n",
      "TP interpolation success\n",
      "Predicted for 2019\n",
      "Set of years: [2019, 2020, 2021]\n",
      "Year to interpolate missing data: 2020\n",
      "SPRING\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 0 points.\n",
      "TP interpolation success\n",
      "SUMMER\n",
      "For TN we will interpolate 63 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 63 points.\n",
      "TP interpolation success\n",
      "FALL\n",
      "For TN we will interpolate 59 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 59 points.\n",
      "TP interpolation success\n",
      "WINTER\n",
      "For TN we will interpolate 66 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 66 points.\n",
      "TP interpolation success\n",
      "Predicted for 2020\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "continuous = ['TN','TP','TEMP','DO','TURB','COND','VEL','SS','WDP','CHLcal','SECCHI']\n",
    "years = [[x-1, x, x+1] for x in range(1995, 2021)]\n",
    "newData[\"YEAR\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).year\n",
    "result = pd.DataFrame()\n",
    "for setOfYears in years:\n",
    "    print(\"Set of years: \" + str(setOfYears))\n",
    "    print(\"Year to interpolate missing data: \" + str(setOfYears[1]))\n",
    "    threeYearFrame = newData[newData['YEAR'].isin(setOfYears)]\n",
    "    seasons = ['SPRING','SUMMER','FALL','WINTER']\n",
    "    for season in seasons:\n",
    "        print(season)\n",
    "        seasonalFrame = threeYearFrame[threeYearFrame['SEASON'] == season]\n",
    "        if (seasonalFrame.shape[0] > 1):\n",
    "            seasonalHash = construct_hashtable(seasonalFrame)\n",
    "            for var in continuous:\n",
    "                predict_years(seasonalFrame, seasonalHash, var,setOfYears[1],2)\n",
    "            \n",
    "            yearToAdd = seasonalFrame[seasonalFrame['YEAR'] == setOfYears[1]]\n",
    "            result = result.append(yearToAdd, ignore_index = True)\n",
    "            result = result.reset_index(drop = True)\n",
    "            \n",
    "            \n",
    "    print(\"Predicted for \" + str(setOfYears[1]))\n",
    "    \n",
    "result.to_csv(r\"..\\pools_specific_EDA\\Open River\\allvars_interpolated_3yearsxseason.csv\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-november",
   "metadata": {},
   "source": [
    "# Prediction group year by year\n",
    "\n",
    "Here, we do predictions for missing data for a given year using the entire year's worth of data. As such, we use the `predict` function instead of the `predict_years` function. Here as well, we create a year column from the date in the data frame, which we then use to generate a list of years to predict data for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liable-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For TN we will interpolate 2 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 2 points.\n",
      "TP interpolation success\n",
      "Predicted for 1995\n",
      "For TN we will interpolate 0 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 180 points.\n",
      "TP interpolation success\n",
      "Predicted for 1996\n",
      "For TN we will interpolate 200 points.\n",
      "TN interpolation success\n",
      "For TP we will interpolate 200 points.\n",
      "TP interpolation success\n",
      "Predicted for 1997\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "newData = dataFrame.copy()\n",
    "newData[\"YEAR\"] = pd.DatetimeIndex(dataFrame[\"DATE\"]).year\n",
    "years = newData[\"YEAR\"].unique()\n",
    "result = pd.DataFrame()\n",
    "for year in years:\n",
    "    currentSet = newData[(newData[\"YEAR\"] == year)]\n",
    "    currentSet = currentSet.reset_index(drop = True)\n",
    "    hashTable = construct_hashtable(currentSet)\n",
    "    predict(currentSet, hashTable, \"TN\",2)\n",
    "    predict(currentSet, hashTable, \"TP\",2)\n",
    "    print(\"Predicted for \" + str(year))\n",
    "    result = result.append(currentSet)\n",
    "\n",
    "result = result.reset_index(drop = True)\n",
    "result.to_csv(r\"C:\\Users\\forre\\Desktop\\REU\\TDA\\Data\\predicted_tn_tp_years.csv\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-dover",
   "metadata": {},
   "source": [
    "# Spacial interpolation by year, by season (Casey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-wagner",
   "metadata": {},
   "source": [
    "Load functions - parameter definitons and correct documentation still needs to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "written-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions and classes\n",
    "\n",
    "# This class stores the latitude and longitude of a sample, and indicates \n",
    "# if this location has the desired variable we are estimating\n",
    "class Location:\n",
    "    def __init__(self,latitude,longitude,hasv,ID,value):\n",
    "        self.ID = ID\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.hasv = hasv\n",
    "        self.value = value\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.ID)\n",
    "\n",
    "# Calculates the distance between 2 samples in km\n",
    "def getdist(S1,S2):\n",
    "    # radius of earth in km\n",
    "    coords_1 = (S1.latitude, S1.longitude)\n",
    "    coords_2 = (S2.latitude, S2.longitude)\n",
    "    dist = distance.distance(coords_1, coords_2).km\n",
    "    return dist\n",
    "\n",
    "\n",
    "# PRE: all locations in the dataframe are\n",
    "# unique\n",
    "def DistanceMatrix(dataframe,variable):\n",
    "    # the list of location objects\n",
    "    locations = []\n",
    "    # the list of indexes where the the row is located in the dataframe\n",
    "    #indexes = []\n",
    "    for index,row in dataframe.iterrows():\n",
    "        # make a location object on this row\n",
    "        if pd.isnull(row[variable]):\n",
    "            hasv = False\n",
    "        else:\n",
    "            hasv = True\n",
    "        locations.append(Location(row[\"LATITUDE\"],row[\"LONGITUDE\"],hasv,row[\"LOCATCD\"],row[variable]))\n",
    "        #indexes.append(index)\n",
    "        \n",
    "    matrix = pd.DataFrame(0,index=locations,columns=locations)\n",
    "    for ci,column in enumerate(locations):\n",
    "        for ri,row in enumerate(locations):\n",
    "            if ri>ci:\n",
    "                # compute distance between column and row\n",
    "                dist = getdist(row,column)\n",
    "            elif ci>ri:\n",
    "                dist = matrix.iloc[ci,ri]\n",
    "            # put this distance in the dataframe\n",
    "            else:\n",
    "                continue\n",
    "            matrix.iloc[ri,ci] = dist\n",
    "    return matrix\n",
    "\n",
    "      \n",
    "def getclosest(numclosest,distancematrix,location,testing):\n",
    "    # Make a set of the closest locations that contain variable\n",
    "    closest = {}\n",
    "    column = distancematrix.loc[:,location].copy()\n",
    "    #print(type(distancematrix.index[0]))\n",
    "    # Filter the locations that dont have the desired variable\n",
    "    doesnthavev = []\n",
    "    for i in range(len(column)):\n",
    "        if not column.index[i].hasv:\n",
    "            doesnthavev.append(column.index[i])\n",
    "    column.drop(doesnthavev,inplace = True)\n",
    "    #print(type(column))\n",
    "    column.sort_values(inplace = True)\n",
    "    # Are we predicting for a value we already have?\n",
    "    if testing:\n",
    "        return column.iloc[1:numclosest+1]\n",
    "    else:\n",
    "        return column.iloc[0:numclosest]\n",
    "\n",
    "# Key: Location Code\n",
    "# Value: List of tuples (locatcd,distance,value)\n",
    "def makeDict(data,variable,numclosest,testing):\n",
    "    D = DistanceMatrix(data,variable)\n",
    "    # Loop through each location without a value for variable\n",
    "    closestDict = {}\n",
    "    for loc in D.columns:\n",
    "        if not loc.hasv or testing:\n",
    "            # Get the closest locations to loc THAT ISN'T LOC\n",
    "            closest = getclosest(numclosest,D,loc,testing)\n",
    "            # The list of tuples that contain location id, the distance, and the value for variable\n",
    "            tuples = []\n",
    "            for i,dist in enumerate(closest):\n",
    "                ID = closest.index[i].ID\n",
    "                val = closest.index[i].value\n",
    "                tuples.append((ID,dist,val))\n",
    "            closestDict[loc.ID] = tuples\n",
    "    return closestDict\n",
    "\n",
    "def predict(tuples,numclosest = 2):\n",
    "    loc2 = tuples[0]\n",
    "    loc3 = tuples[1]\n",
    "    d12 = loc2[1]\n",
    "    val2 = loc2[2]\n",
    "    d13 = loc3[1]\n",
    "    val3 = loc3[2]\n",
    "    \n",
    "    c2 = d12/(d12+d13)\n",
    "    c3 = d13/(d12+d13)\n",
    "    \n",
    "    predicted = c2*val2+c3*val3\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "        \n",
    "'''\n",
    "data - the pandas dataframe that is ready to interpolate missing values\n",
    "MUST HAVE \"LATITUDE\", \"LONGITUDE\",\"YEAR\", \"SEASON\", \"LOCATCD\" columns\n",
    "\n",
    "missing_vars - the list of column names (as strings) of the dataframe that we should attempt to fill in\n",
    "\n",
    "numlocations - the number of locations used to predict the new value, default is 2 (currently the only option implemented)\n",
    "\n",
    "RETURN - a dataframe with extra columns saying the predicted values of the missing_vars\n",
    "'''\n",
    "def linear_interpolate(data,missing_vars,numlocations = 2,testing = False):\n",
    "    print(\"Building a new dataframe with predicted values\")\n",
    "    start_time = time.time()\n",
    "    # Testing for duplicated locations if needed\n",
    "    #s = qualdata_noprediction[\"LOCATCD\"].duplicated(keep=False)\n",
    "    # get the years and timecodes for this dataset\n",
    "    # predictions can only be made if the point is in the same year and time code (what if we don't need to do this)\n",
    "    years = data[\"YEAR\"].unique()\n",
    "    seasons = data[\"SEASON\"].unique()\n",
    "    data_prediction = pd.DataFrame()\n",
    "    for year in years:\n",
    "        for season in seasons:\n",
    "            print(\"Appending predicted data for \",year,\"  \",season)\n",
    "            # curset is the current set of rows we are predicting for\n",
    "            curset = data[(data[\"YEAR\"]==year) & (data[\"SEASON\"]==season)].copy()\n",
    "            print(\"Size of this year and season:\", curset.shape)\n",
    "            \n",
    "            for var in missing_vars:\n",
    "                print(\"Interpolating \"+var)\n",
    "                newcolumn = \"Predicted\"+var\n",
    "                curset[newcolumn] = 0\n",
    "                \n",
    "                #check to see if there are enough valid locations\n",
    "                # that can be used to predict\n",
    "                if not testing:\n",
    "                    bad = bool((curset[var].notnull().sum()<numlocations))\n",
    "                else:\n",
    "                    bad = bool((curset[var].notnull().sum()<numlocations+1))\n",
    "                \n",
    "                # Returns a dictionary mapping each location code to a tuple with prediction information\n",
    "                Dict = makeDict(curset,var,numlocations,testing)\n",
    "\n",
    "                if(bad):\n",
    "                    print(\"Less than \"+str(numlocations)+\" locations have \"+var+\" in this set, dropping rows without \"+var)\n",
    "                    curset = curset[curset[var].notnull()]\n",
    "                    curset[newcolumn] = curset[var]\n",
    "                    print(\"Current set is now \",curset.shape)\n",
    "                else:\n",
    "                    #put in predicted variable\n",
    "                    for index,row in curset.iterrows():\n",
    "                        if pd.isnull(row[var]) or testing:\n",
    "                            try:\n",
    "                                curset.loc[index,newcolumn] = predict(Dict[row[\"LOCATCD\"]])\n",
    "                            except ZeroDivisionError:\n",
    "                                print(\"Couldn't predict for \", str(row[\"LOCATCD\"]))\n",
    "                                print(Dict[row[\"LOCATCD\"]])\n",
    "                                curset.loc[index,newcolumn] = None\n",
    "                        else:\n",
    "                            curset.loc[index,newcolumn] = row[var]\n",
    "\n",
    "            data_prediction = data_prediction.append(curset,ignore_index=True)  \n",
    "            \n",
    "    print(\"Final data set size is \",data_prediction.shape)\n",
    "    print(f\"Interpolating took {(time.time()-start_time)/60} minutes\")\n",
    "    return data_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-outside",
   "metadata": {},
   "source": [
    "#### Interpolating missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "atmospheric-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a new dataframe with predicted values\n",
      "Appending predicted data for  1996    SUMMER\n",
      "Size of this year and season: (113, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Less than 2 locations have TP in this set, dropping rows without TP\n",
      "Current set is now  (0, 23)\n",
      "Appending predicted data for  1996    FALL\n",
      "Size of this year and season: (129, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Less than 2 locations have TP in this set, dropping rows without TP\n",
      "Current set is now  (0, 23)\n",
      "Appending predicted data for  1996    WINTER\n",
      "Size of this year and season: (10, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1996    SPRING\n",
      "Size of this year and season: (0, 21)\n",
      "Interpolating TN\n",
      "Less than 2 locations have TN in this set, dropping rows without TN\n",
      "Current set is now  (0, 22)\n",
      "Interpolating TP\n",
      "Less than 2 locations have TP in this set, dropping rows without TP\n",
      "Current set is now  (0, 23)\n",
      "Appending predicted data for  1997    SUMMER\n",
      "Size of this year and season: (197, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1997    FALL\n",
      "Size of this year and season: (203, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1997    WINTER\n",
      "Size of this year and season: (188, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1997    SPRING\n",
      "Size of this year and season: (189, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1998    SUMMER\n",
      "Size of this year and season: (198, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1998    FALL\n",
      "Size of this year and season: (196, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1998    WINTER\n",
      "Size of this year and season: (198, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1998    SPRING\n",
      "Size of this year and season: (199, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1999    SUMMER\n",
      "Size of this year and season: (205, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1999    FALL\n",
      "Size of this year and season: (137, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1999    WINTER\n",
      "Size of this year and season: (185, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  1999    SPRING\n",
      "Size of this year and season: (157, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2000    SUMMER\n",
      "Size of this year and season: (203, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  M066.3B\n",
      "[('M066.3B', 0.0, 2.234), ('M066.3B', 0.0, 3.7)]\n",
      "Interpolating TP\n",
      "Couldn't predict for  M066.3B\n",
      "[('M066.3B', 0.0, 0.199), ('M066.3B', 0.0, 0.332)]\n",
      "Appending predicted data for  2000    FALL\n",
      "Size of this year and season: (164, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2000    WINTER\n",
      "Size of this year and season: (98, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2000    SPRING\n",
      "Size of this year and season: (203, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  M078.0B\n",
      "[('M078.0B', 0.0, 2.898), ('M078.0B', 0.0, 3.302)]\n",
      "Couldn't predict for  M070.2A\n",
      "[('M070.2A', 0.0, 2.466), ('M070.2A', 0.0, 2.974)]\n",
      "Couldn't predict for  M066.3A\n",
      "[('M066.3A', 0.0, 2.358), ('M066.3A', 0.0, 1.799)]\n",
      "Couldn't predict for  M066.3B\n",
      "[('M066.3B', 0.0, 3.781), ('M066.3B', 0.0, 2.621)]\n",
      "Couldn't predict for  BM00.7S\n",
      "[('BM00.7S', 0.0, 1.331), ('BM00.7S', 0.0, 1.189)]\n",
      "Couldn't predict for  M066.4C\n",
      "[('M066.4C', 0.0, 1.917), ('M066.4C', 0.0, 2.79)]\n",
      "Couldn't predict for  M059.5I\n",
      "[('M059.5I', 0.0, 2.698), ('M059.5I', 0.0, 2.439)]\n",
      "Couldn't predict for  HD00.9M\n",
      "[('HD00.9M', 0.0, 1.174), ('HD00.9M', 0.0, 0.303)]\n",
      "Interpolating TP\n",
      "Appending predicted data for  2001    SUMMER\n",
      "Size of this year and season: (202, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  HD00.9M\n",
      "[('HD00.9M', 0.0, 1.777), ('HD00.9M', 0.0, 1.966)]\n",
      "Interpolating TP\n",
      "Appending predicted data for  2001    FALL\n",
      "Size of this year and season: (182, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2001    WINTER\n",
      "Size of this year and season: (135, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2001    SPRING\n",
      "Size of this year and season: (207, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2002    SUMMER\n",
      "Size of this year and season: (200, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  M078.0B\n",
      "[('M078.0B', 0.0, 1.422), ('M078.0B', 0.0, 3.751)]\n",
      "Couldn't predict for  M066.3A\n",
      "[('M066.3A', 0.0, 1.528), ('M066.3A', 0.0, 1.305)]\n",
      "Interpolating TP\n",
      "Couldn't predict for  M059.5I\n",
      "[('M059.5I', 0.0, 0.18), ('M059.5I', 0.0, 0.091)]\n",
      "Couldn't predict for  BM00.7S\n",
      "[('BM00.7S', 0.0, 0.135), ('BM00.7S', 0.0, 0.165)]\n",
      "Couldn't predict for  M078.0B\n",
      "[('M078.0B', 0.0, 0.347), ('M078.0B', 0.0, 0.158)]\n",
      "Appending predicted data for  2002    FALL\n",
      "Size of this year and season: (18, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2002    WINTER\n",
      "Size of this year and season: (142, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2002    SPRING\n",
      "Size of this year and season: (213, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  HD00.9M\n",
      "[('HD00.9M', 0.0, 1.158), ('HD00.9M', 0.0, 0.727)]\n",
      "Couldn't predict for  BM00.7S\n",
      "[('BM00.7S', 0.0, 1.156), ('BM00.7S', 0.0, 1.108)]\n",
      "Interpolating TP\n",
      "Appending predicted data for  2004    SUMMER\n",
      "Size of this year and season: (208, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  M066.3B\n",
      "[('M066.3B', 0.0, 2.777), ('M066.3B', 0.0, 3.064)]\n",
      "Couldn't predict for  M066.3B\n",
      "[('M066.3B', 0.0, 2.777), ('M066.3B', 0.0, 3.064)]\n",
      "Interpolating TP\n",
      "Appending predicted data for  2004    FALL\n",
      "Size of this year and season: (156, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2004    WINTER\n",
      "Size of this year and season: (106, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2004    SPRING\n",
      "Size of this year and season: (184, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2005    SUMMER\n",
      "Size of this year and season: (142, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2005    FALL\n",
      "Size of this year and season: (151, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2005    WINTER\n",
      "Size of this year and season: (159, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2005    SPRING\n",
      "Size of this year and season: (195, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2006    SUMMER\n",
      "Size of this year and season: (152, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2006    FALL\n",
      "Size of this year and season: (127, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2006    WINTER\n",
      "Size of this year and season: (123, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2006    SPRING\n",
      "Size of this year and season: (193, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2007    SUMMER\n",
      "Size of this year and season: (194, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2007    FALL\n",
      "Size of this year and season: (173, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2007    WINTER\n",
      "Size of this year and season: (140, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2007    SPRING\n",
      "Size of this year and season: (195, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2008    SUMMER\n",
      "Size of this year and season: (186, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2008    FALL\n",
      "Size of this year and season: (164, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2008    WINTER\n",
      "Size of this year and season: (138, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2008    SPRING\n",
      "Size of this year and season: (204, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2009    SUMMER\n",
      "Size of this year and season: (191, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2009    FALL\n",
      "Size of this year and season: (175, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2009    WINTER\n",
      "Size of this year and season: (64, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2009    SPRING\n",
      "Size of this year and season: (194, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2010    SUMMER\n",
      "Size of this year and season: (192, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2010    FALL\n",
      "Size of this year and season: (177, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2010    WINTER\n",
      "Size of this year and season: (159, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2010    SPRING\n",
      "Size of this year and season: (195, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2011    SUMMER\n",
      "Size of this year and season: (195, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2011    FALL\n",
      "Size of this year and season: (159, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2011    WINTER\n",
      "Size of this year and season: (105, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2011    SPRING\n",
      "Size of this year and season: (194, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2012    SUMMER\n",
      "Size of this year and season: (155, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2012    FALL\n",
      "Size of this year and season: (99, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2012    WINTER\n",
      "Size of this year and season: (154, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2012    SPRING\n",
      "Size of this year and season: (200, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2013    SUMMER\n",
      "Size of this year and season: (172, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2013    FALL\n",
      "Size of this year and season: (108, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2013    WINTER\n",
      "Size of this year and season: (97, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2013    SPRING\n",
      "Size of this year and season: (193, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2014    SUMMER\n",
      "Size of this year and season: (195, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2014    FALL\n",
      "Size of this year and season: (176, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2014    WINTER\n",
      "Size of this year and season: (18, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2014    SPRING\n",
      "Size of this year and season: (193, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2015    SUMMER\n",
      "Size of this year and season: (195, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2015    FALL\n",
      "Size of this year and season: (131, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2015    WINTER\n",
      "Size of this year and season: (128, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2015    SPRING\n",
      "Size of this year and season: (189, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2016    SUMMER\n",
      "Size of this year and season: (186, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2016    FALL\n",
      "Size of this year and season: (176, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2016    WINTER\n",
      "Size of this year and season: (159, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2016    SPRING\n",
      "Size of this year and season: (204, 21)\n",
      "Interpolating TN\n",
      "Couldn't predict for  M070.2A\n",
      "[('M070.2A', 0.0, 4.576), ('M070.2A', 0.0, 5.458)]\n",
      "Interpolating TP\n",
      "Couldn't predict for  M070.2A\n",
      "[('M070.2A', 0.0, 0.15), ('M070.2A', 0.0, 0.152)]\n",
      "Appending predicted data for  2017    SUMMER\n",
      "Size of this year and season: (186, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2017    FALL\n",
      "Size of this year and season: (173, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2017    WINTER\n",
      "Size of this year and season: (158, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2017    SPRING\n",
      "Size of this year and season: (204, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2018    SUMMER\n",
      "Size of this year and season: (186, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2018    FALL\n",
      "Size of this year and season: (177, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2018    WINTER\n",
      "Size of this year and season: (126, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2018    SPRING\n",
      "Size of this year and season: (204, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2019    SUMMER\n",
      "Size of this year and season: (183, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2019    FALL\n",
      "Size of this year and season: (183, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2019    WINTER\n",
      "Size of this year and season: (159, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2019    SPRING\n",
      "Size of this year and season: (204, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2020    SUMMER\n",
      "Size of this year and season: (204, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2020    FALL\n",
      "Size of this year and season: (180, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2020    WINTER\n",
      "Size of this year and season: (161, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Appending predicted data for  2020    SPRING\n",
      "Size of this year and season: (183, 21)\n",
      "Interpolating TN\n",
      "Interpolating TP\n",
      "Final data set size is  (15518, 23)\n",
      "Interpolating took 25.207410697142283 minutes\n"
     ]
    }
   ],
   "source": [
    "missing_vars = [\"TN\",\"TP\"]\n",
    "water_interpolated = linear_interpolate(water_data,missing_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-beverage",
   "metadata": {},
   "source": [
    "# Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-utility",
   "metadata": {},
   "source": [
    "Filter for non missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "unlikely-candle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out all rows with missing data\n",
      "(1943, 21)\n",
      "Filtering out colums that we dont need\n",
      "(1943, 11)\n"
     ]
    }
   ],
   "source": [
    "cols = ['TP','TN','CHLcal','SS','VEL','DO','COND','WDP','TURB','TEMP','SECCHI']\n",
    "print(\"Filtering out all rows with missing data\")\n",
    "qualdata = water_data.dropna(axis=0, how='any', thresh=None, subset=cols, inplace=False).copy()\n",
    "print(qualdata.shape)\n",
    "print(\"Filtering out colums that we dont need\")\n",
    "qualdata.drop(qualdata.columns.difference(cols), 1, inplace=True)\n",
    "print(qualdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "colored-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP training set mean squared error: 0.000000  on average off 0.000000\n",
      "TN training set mean squared error: 0.000000  on average off 0.000000 \n",
      "\n",
      "TP test set mean squared error: 153.344687  on average off 12.383242\n",
      "TN test set mean squared error: 41933.312604  on average off 204.776250 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Hyperparameter: Set the degree of the polynomial to fit\n",
    "d = 5\n",
    "\n",
    "\n",
    "X = np.array(qualdata[['CHLcal','SS','VEL','DO','COND','WDP','TURB','TEMP','SECCHI']])\n",
    "TP = np.array(qualdata['TP'])\n",
    "TN = np.array(qualdata['TN'])\n",
    "\n",
    "# Good idea to standardize predictor attributes - assumes each variable has a decently normal distribution\n",
    "scaler = RobustScaler().fit(X)\n",
    "X_standard = scaler.transform(X)\n",
    "\n",
    "\n",
    "# The PolynomialFeatures class in sklearn.preprocessing can be used to transform a data matrix by\n",
    "# adding higher-order and interaction terms for the existing features. It also adds a \"zeroth\"\n",
    "# column consisting of all 1's that corresponds to the weight w_0 in a regression model.\n",
    "poly = PolynomialFeatures(d)\n",
    "\n",
    "# We \"fit\" the poly object to our data matrix to allow it to identify the structure of the data\n",
    "# (notably the number of attributes, or columns, in the data matrix).\n",
    "poly.fit(X_standard)\n",
    "#poly.fit(X)\n",
    "\n",
    "\n",
    "# Now we use poly.transform to add any higher-order terms to the data matrix.\n",
    "# This also adds a zeroth attribute which is set to all 1's.\n",
    "augmented_X = poly.transform(X_standard)\n",
    "#augmented_X = poly.transform(X)\n",
    "\n",
    "\n",
    "# Next we create a linear regression object (named lm for \"linear model\").\n",
    "# Because our augmented data matrix includes an all 1's column, we don't\n",
    "# need to fit the intercept (w_0) here.\n",
    "TP_lm = LinearRegression(fit_intercept=False)\n",
    "TN_lm = LinearRegression(fit_intercept=False)\n",
    "\n",
    "\n",
    "# Split data into train and test for each\n",
    "TPX_train, TPX_test, TPy_train, TPy_test = train_test_split(augmented_X, TP, train_size=0.7)\n",
    "TNX_train, TNX_test, TNy_train, TNy_test = train_test_split(augmented_X, TN, train_size=0.7)\n",
    "\n",
    "# Fit models using training data\n",
    "TP_lm.fit(TPX_train, TPy_train)\n",
    "TN_lm.fit(TNX_train, TNy_train)\n",
    "\n",
    "# After fitting the regression model, we can estimate the error\n",
    "# Get training errors\n",
    "TP_train_err = np.mean((TPy_train - TP_lm.predict(TPX_train)) ** 2)\n",
    "TN_train_err = np.mean((TNy_train - TN_lm.predict(TNX_train)) ** 2)\n",
    "\n",
    "# Get test errors\n",
    "TP_test_err = np.mean((TPy_test - TP_lm.predict(TPX_test)) ** 2)\n",
    "TN_test_err = np.mean((TNy_test - TN_lm.predict(TNX_test)) ** 2)\n",
    "\n",
    "# Report\n",
    "print(\"TP training set mean squared error: {:.6f}\".format(TP_train_err),\" on average off {:.6f}\".format(np.sqrt(TP_train_err)))\n",
    "print(\"TN training set mean squared error: {:.6f}\".format(TN_train_err),\" on average off {:.6f}\".format(np.sqrt(TN_train_err)),\"\\n\")\n",
    "print(\"TP test set mean squared error: {:.6f}\".format(TP_test_err),\" on average off {:.6f}\".format(np.sqrt(TP_test_err)))\n",
    "print(\"TN test set mean squared error: {:.6f}\".format(TN_test_err),\" on average off {:.6f}\".format(np.sqrt(TN_test_err)),\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
