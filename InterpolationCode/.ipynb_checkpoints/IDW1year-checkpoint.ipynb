{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "crazy-physics",
   "metadata": {},
   "source": [
    "# Inverse Distance Weighted (IDW) Interpolation\n",
    "## Using 2 neighbors within the same year and season\n",
    "### Written and compiled by Casey McKean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-radius",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "turned-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to work with our datasets\n",
    "import pandas as pd\n",
    "# We use geopy to calculate the distance between latitude and longitude coordinates within the dataset\n",
    "from geopy import distance\n",
    "import sklearn.metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-consumer",
   "metadata": {},
   "source": [
    "### Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "common-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Loaded\n"
     ]
    }
   ],
   "source": [
    "class Sample:\n",
    "    \"\"\"This class stores various information about a sample.\n",
    "    \n",
    "    The attributes of this class are:\n",
    "    - latitude\n",
    "    - longitude\n",
    "    - hasv: a boolean indicating if this sample has a recorded value of the desired variable we are interpolating\n",
    "    - value: the recorded value of the variable we are interpolating\n",
    "    - SHEET: the unique SHEETBAR code of this sample\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,latitude,longitude,hasv,value,SHEET):\n",
    "        self.SHEET = SHEET\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self.hasv = hasv\n",
    "        self.value = value\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.SHEET)\n",
    "    \n",
    "def getdist(S1,S2):\n",
    "    \"\"\"Calculates the distance betwen 2 samples in kilometers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S1: Sample object\n",
    "    S2: Sample object\n",
    "    \n",
    "    RETURN: float representing distance in kilometers\n",
    "    \"\"\"\n",
    "    coords_1 = (S1.latitude, S1.longitude)\n",
    "    coords_2 = (S2.latitude, S2.longitude)\n",
    "    dist = distance.distance(coords_1, coords_2).km\n",
    "    return dist\n",
    "\n",
    "def DistanceMatrix(dataframe,variable):\n",
    "    \"\"\"Returns a pandas dataframe representing a distance matrix in kilometers between all samples\n",
    "    \n",
    "    The indices and columns of the distance matrix are sample objects. This is done to make it easier\n",
    "    to find the nearest samples that also have recorded values for the variable we are interpolating.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: the pandas dataframe of the dataset we are interpolating\n",
    "        PRE: all samples within this datframe have a unique SHEETBAR code\n",
    "        PRE: dataframe has 'SHEETBAR' 'LATITUDE' 'LONGITUDE' column names\n",
    "    variable: the variable we are interpolating as a string\n",
    "    \n",
    "    RETURN: pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checking that all samples are unique within this dataframe\n",
    "    numunique = len(dataframe[\"SHEETBAR\"].unique())\n",
    "    numlocations = dataframe.shape[0]\n",
    "    try:\n",
    "        assert(numunique == numlocations), f\"{numunique} unique samples but {numlocations} number of samples\"\n",
    "    \n",
    "    except AssertionError as msg:\n",
    "        print(dataframe[dataframe[\"SHEETBAR\"].duplicated(keep=False)])\n",
    "        print(msg)\n",
    "        \n",
    "    # the list of sample objects\n",
    "    samples = []\n",
    "    for index,row in dataframe.iterrows():\n",
    "        # make a sample object on this row\n",
    "        if pd.isnull(row[variable]):\n",
    "            hasv = False\n",
    "        else:\n",
    "            hasv = True\n",
    "        # Make a sample for each row in the dataframe\n",
    "        samples.append(Sample(row[\"LATITUDE\"],row[\"LONGITUDE\"],hasv,row[variable],row[\"SHEETBAR\"]))\n",
    "    \n",
    "    # Initialize the distance matrix to all 0's, with our samples as indices and columns\n",
    "    matrix = pd.DataFrame(0,index=samples,columns=samples)\n",
    "    \n",
    "    # Fill the distance matrix\n",
    "    for ci,column in enumerate(samples):\n",
    "        for ri,row in enumerate(samples):\n",
    "            # If row index is larger than the column index\n",
    "            if ri>ci:\n",
    "                # compute distance between column and row\n",
    "                dist = getdist(row,column)\n",
    "            # If column index is larger than row index\n",
    "            elif ci>ri:\n",
    "                # We already computed this distance, use symmetry\n",
    "                dist = matrix.iloc[ci,ri]\n",
    "            else:\n",
    "                # The distance between the same sample is 0\n",
    "                continue\n",
    "            # Assign the distance to the current row and column\n",
    "            matrix.iloc[ri,ci] = dist\n",
    "    return matrix\n",
    "\n",
    "def changeVar(DM,dataframe,variable):\n",
    "    \"\"\"This changes the variable information of a distance matrix\n",
    "    \n",
    "    This method saves computation time so new distance matrices aren't needed\n",
    "    when switching from interoplating one variable to interpolating another variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DM: pandas datframe of distance matrix\n",
    "    dataframe: the pandas dataframe we are interpolating\n",
    "    variable: the variable we are updating the distance matrix with\n",
    "    \n",
    "    RETURN: nothing\n",
    "    \"\"\"\n",
    "    samples = DM.index\n",
    "    # Loop through each sample\n",
    "    for i,sample in enumerate(samples):\n",
    "        SHEET = sample.SHEET\n",
    "        row = dataframe.loc[dataframe[\"SHEETBAR\"]==SHEET]\n",
    "        \n",
    "        # Asserting there is only 1 row with this sheetbar\n",
    "        try:\n",
    "            assert(row.shape[0]==1), \"Multiple rows with same SHEETBAR\"\n",
    "        except AssertionError as msg:\n",
    "            print(dataframe[dataframe[\"SHEETBAR\"].duplicated(keep=False)])\n",
    "            print(msg)\n",
    "            \n",
    "        # Pull value of desired variable\n",
    "        val = row.loc[row.index[0],variable]\n",
    "        if pd.isnull(val):\n",
    "            samples[i].hasv = False\n",
    "            samples[i].value = None\n",
    "        else:\n",
    "            samples[i].hasv = True\n",
    "            samples[i].value = val\n",
    "            \n",
    "    DM.index = samples\n",
    "    DM.columns = samples\n",
    "    \n",
    "def getclosest(numclosest,DM,sample):\n",
    "    \"\"\"Returns a given number of closest samples with non-null values to a sample\n",
    "    \n",
    "    The samples returned are the closest samples, and they have recorded values\n",
    "    for the current variable we are interpolating.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    numclosest: an integer telling how many samples to return\n",
    "    DM: a pandas dataframe of a distance matrix to get the samples from\n",
    "    sample: the sample object we want to find neighbors for\n",
    "    \n",
    "    RETURN: pandas series\n",
    "    \"\"\"\n",
    "    # Pull out the column of of the distance matrix for this sample\n",
    "    column = DM.loc[:,sample].copy()\n",
    "    \n",
    "    # The list of samples that don't have the desired variable\n",
    "    doesnthavev = []\n",
    "    for i in range(len(column)):\n",
    "        if not column.index[i].hasv:\n",
    "            doesnthavev.append(column.index[i])\n",
    "            \n",
    "    # Get rid of locations that dont have the desired variable\n",
    "    column.drop(doesnthavev,inplace = True)\n",
    "    # Get rid of the location we are predicting for if it exists\n",
    "    column.drop(sample,inplace = True,errors=\"ignore\")\n",
    "    # Sort the column based on distances\n",
    "    column.sort_values(inplace = True)\n",
    "    \n",
    "    # Return the first numclosest samples\n",
    "    return column.iloc[0:numclosest]\n",
    "\n",
    "def makeDict(DM,numclosest,testing):\n",
    "    \"\"\"\n",
    "    Returns a dictonary with keys as sheetbar codes that need predicting\n",
    "    and values as a list of tuples containing prediction information. The structure\n",
    "    of the tuples are (SHEETBAR,distance,value)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DM: a pandas dataframe as a distance matrix\n",
    "    numclosest: an integer telling the number of locations used to predict\n",
    "    testing: a boolean indicating whether we should predict for samples that already have recorded values\n",
    "    \n",
    "    RETURN: python dictionary\n",
    "    \"\"\"\n",
    "    # Initialize the dictionary\n",
    "    closestDict = {}\n",
    "    # Loop through each sample in the distance matrix\n",
    "    for sample in DM.columns:\n",
    "        if not sample.hasv or testing:\n",
    "            # Get the closest samples to sample THAT ISN'T SAMPLE\n",
    "            closest = getclosest(numclosest,DM,sample)\n",
    "            # The list of tuples that contain sample sheetbar, the distance, and the value for variable\n",
    "            tuples = []\n",
    "            for i,dist in enumerate(closest):\n",
    "                SHEET = closest.index[i].SHEET\n",
    "                val = closest.index[i].value\n",
    "                tuples.append((SHEET,dist,val))\n",
    "            closestDict[sample.SHEET] = tuples\n",
    "    return closestDict\n",
    "\n",
    "def predict(tuples,numclosest = 2):\n",
    "    \"\"\"Returns the prediction for a sample\n",
    "    \n",
    "    Currently only implemented for using 2 samples to make a prediction\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples: the list (SHEETBAR,distance,value) tuples needed for prediciton\n",
    "    numclosest: an integer telling how many samples are used to predict\n",
    "    \n",
    "    RETURN: float representing the predicted value\n",
    "    \"\"\"\n",
    "    loc2 = tuples[0]\n",
    "    loc3 = tuples[1]\n",
    "    d12 = loc2[1]\n",
    "    val2 = loc2[2]\n",
    "    d13 = loc3[1]\n",
    "    val3 = loc3[2]\n",
    "    \n",
    "    if d12 == d13:\n",
    "        return 0.5*val2+0.5*val3\n",
    "    elif d12 == 0:\n",
    "        return val2\n",
    "    elif d13 == 0:\n",
    "        return val3\n",
    "    \n",
    "    else:\n",
    "        c2 = d12/(d12+d13)\n",
    "        c3 = d13/(d12+d13)\n",
    "        predicted = c2*val2+c3*val3\n",
    "    \n",
    "        return predicted\n",
    "    \n",
    "\n",
    "def IDW_interpolate(data,missing_vars,numlocations = 2,testing = False,verbosity = 0):\n",
    "    '''This method does all the heavy lifting for appending interpolated columns to the dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: the pandas dataframe that is ready to interpolate missing values\n",
    "        PRE: MUST HAVE \"LATITUDE\", \"LONGITUDE\",\"YEAR\", \"SEASON\", \"SHEETBAR\", \"FLDNUM\" columns\n",
    "    missing_vars: the list of column names (as strings) of the dataframe that we should interpolate\n",
    "    numlocations: the number of locations used to predict the new value, default = 2 (currently the only option implemented)\n",
    "    testing: boolean telling whether to predict for values that are already recorded, defalut = False\n",
    "    verbosity: an integer telling how much output to be printed during interpolation process, default = 0\n",
    "    \n",
    "    \n",
    "    RETURN - a pandas dataframe with extra columns saying the predicted values of the missing_vars\n",
    "    '''\n",
    "    \n",
    "    print(\"Building a new dataframe with predicted values\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    years = data[\"YEAR\"].unique()\n",
    "    seasons = data[\"SEASON\"].unique()\n",
    "    pools = data[\"FLDNUM\"].unique()\n",
    "    \n",
    "    # Initialize new dataframe which will contain interpolated columns\n",
    "    data_prediction = pd.DataFrame()\n",
    "    \n",
    "    # Predictions are made within pools, within years, and within seasons\n",
    "    for pool in pools:\n",
    "        for year in years:\n",
    "            for season in seasons:\n",
    "                if verbosity > 0:\n",
    "                    print(f\"Appending predicted data for {year}  {season}  FLDNUM {pool}\")\n",
    "                # curset is the current set of rows we are predicting for\n",
    "                curset = data[(data[\"YEAR\"]==year) & (data[\"SEASON\"]==season) & (data[\"FLDNUM\"]==pool)].copy()\n",
    "                \n",
    "                if verbosity > 1:\n",
    "                    print(\"Size of this year and season:\", curset.shape)\n",
    "                \n",
    "                # Boolean to indicate if variable in Distance matrix needs updating\n",
    "                first = True\n",
    "                for var in missing_vars:\n",
    "                    newcolumn = \"PREDICTED_\"+var\n",
    "                    curset[newcolumn] = 0\n",
    "                \n",
    "                    #check to see if there are enough valid locations\n",
    "                    # that can be used to predict\n",
    "                    if not testing:\n",
    "                        bad = bool((curset[var].notnull().sum()<numlocations))\n",
    "                    else:\n",
    "                        bad = bool((curset[var].notnull().sum()<numlocations+1))\n",
    "                    \n",
    "                    \n",
    "                    if(bad):\n",
    "                        if verbosity > 2:\n",
    "                            print(\"Less than \"+str(numlocations)+\" locations have \"+var+\" in this set, dropping rows without \"+var)\n",
    "                        curset = curset[curset[var].notnull()]\n",
    "                        curset[newcolumn] = curset[var]\n",
    "                        if verbosity > 2:\n",
    "                            print(\"Current set is now \",curset.shape)\n",
    "                    else:\n",
    "                        if first:\n",
    "                            if verbosity > 2:\n",
    "                                print(\"Creating DM with \",var)\n",
    "                            DM = DistanceMatrix(curset,var)\n",
    "                            first = False\n",
    "                        else:\n",
    "                            if verbosity > 2:\n",
    "                                print(\"Changing to \",var)\n",
    "                            changeVar(DM,curset,var)\n",
    "                            \n",
    "                        # Returns a dictionary mapping each location code to a tuple with prediction information\n",
    "                        Dict = makeDict(DM,numlocations,testing)\n",
    "                        \n",
    "                        # Put predictions into curset\n",
    "                        for index,row in curset.iterrows():\n",
    "                            if pd.isnull(row[var]) or testing:\n",
    "                                try:\n",
    "                                    prediction = predict(Dict[row[\"SHEETBAR\"]])\n",
    "                                    curset.loc[index,newcolumn] = prediction\n",
    "                                except ZeroDivisionError:\n",
    "                                    print(\"Couldn't predict for \", str(row[\"SHEETBAR\"]))\n",
    "                                    print(Dict[row[\"SHEETBAR\"]])\n",
    "                                    curset.loc[index,newcolumn] = None\n",
    "                            else:\n",
    "                                curset.loc[index,newcolumn] = row[var]\n",
    "                                \n",
    "                # Append the predicted subset to the new dataframe\n",
    "                data_prediction = data_prediction.append(curset,ignore_index=True)  \n",
    "    \n",
    "    print(\"Final data set size is \",data_prediction.shape)\n",
    "    print(f\"Interpolating took {(time.time()-start_time)/60} minutes\")\n",
    "    return data_prediction\n",
    "\n",
    "print(\"Functions Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-queens",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-hands",
   "metadata": {},
   "source": [
    "The data should already have been cleaned and appended latitude and longitude columns to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "express-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>DO</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41000065</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.571864</td>\n",
       "      <td>-92.510970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.44875</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41000066</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.575497</td>\n",
       "      <td>-92.518497</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312002</td>\n",
       "      <td>4.876</td>\n",
       "      <td>0.229</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.24230</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41000067</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.573718</td>\n",
       "      <td>-92.523549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.72488</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41000068</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.566588</td>\n",
       "      <td>-92.541238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312003</td>\n",
       "      <td>4.257</td>\n",
       "      <td>0.212</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.48359</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41000069</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.568419</td>\n",
       "      <td>-92.548780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.52918</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR        DATE   LATITUDE  LONGITUDE  FLDNUM  STRATUM  LOCATCD  \\\n",
       "0  41000065  07/26/1993  44.571864 -92.510970       1        1  9312103   \n",
       "1  41000066  07/26/1993  44.575497 -92.518497       1        1  9312002   \n",
       "2  41000067  07/26/1993  44.573718 -92.523549       1        1  9312102   \n",
       "3  41000068  07/26/1993  44.566588 -92.541238       1        1  9312003   \n",
       "4  41000069  07/26/1993  44.568419 -92.548780       1        1  9312104   \n",
       "\n",
       "      TN     TP  TEMP   DO  TURB   COND  VEL    SS  WDP   CHLcal  SECCHI  \n",
       "0    NaN    NaN  23.0  6.6  28.0  550.0  NaN  42.3  2.2  9.44875    40.0  \n",
       "1  4.876  0.229  23.0  6.6  28.0  554.0  NaN  37.6  8.2  8.24230    42.0  \n",
       "2    NaN    NaN  22.9  6.3  24.0  564.0  NaN  34.1  4.3  8.72488    43.0  \n",
       "3  4.257  0.212  22.9  6.4  28.0  563.0  NaN  33.4  9.1  8.48359    38.0  \n",
       "4    NaN    NaN  23.0  6.6  33.0  556.0  NaN  48.0  6.7  9.52918    45.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = r\"..\\LTRM data\\water_data_qfneg.csv\"\n",
    "water_data = pd.read_csv(filepath, low_memory = False)\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-louisiana",
   "metadata": {},
   "source": [
    "We need to create year and season columns on the dataframe for this interpolation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aggregate-germany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>...</th>\n",
       "      <th>TURB</th>\n",
       "      <th>COND</th>\n",
       "      <th>VEL</th>\n",
       "      <th>SS</th>\n",
       "      <th>WDP</th>\n",
       "      <th>CHLcal</th>\n",
       "      <th>SECCHI</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SEASON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41000065</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.571864</td>\n",
       "      <td>-92.510970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.44875</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41000066</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.575497</td>\n",
       "      <td>-92.518497</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312002</td>\n",
       "      <td>4.876</td>\n",
       "      <td>0.229</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.24230</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41000067</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.573718</td>\n",
       "      <td>-92.523549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.9</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.72488</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41000068</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.566588</td>\n",
       "      <td>-92.541238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312003</td>\n",
       "      <td>4.257</td>\n",
       "      <td>0.212</td>\n",
       "      <td>22.9</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.48359</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41000069</td>\n",
       "      <td>07/26/1993</td>\n",
       "      <td>44.568419</td>\n",
       "      <td>-92.548780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9312104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.52918</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>SUMMER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR        DATE   LATITUDE  LONGITUDE  FLDNUM  STRATUM  LOCATCD  \\\n",
       "0  41000065  07/26/1993  44.571864 -92.510970       1        1  9312103   \n",
       "1  41000066  07/26/1993  44.575497 -92.518497       1        1  9312002   \n",
       "2  41000067  07/26/1993  44.573718 -92.523549       1        1  9312102   \n",
       "3  41000068  07/26/1993  44.566588 -92.541238       1        1  9312003   \n",
       "4  41000069  07/26/1993  44.568419 -92.548780       1        1  9312104   \n",
       "\n",
       "      TN     TP  TEMP  ...  TURB   COND  VEL    SS  WDP   CHLcal  SECCHI  \\\n",
       "0    NaN    NaN  23.0  ...  28.0  550.0  NaN  42.3  2.2  9.44875    40.0   \n",
       "1  4.876  0.229  23.0  ...  28.0  554.0  NaN  37.6  8.2  8.24230    42.0   \n",
       "2    NaN    NaN  22.9  ...  24.0  564.0  NaN  34.1  4.3  8.72488    43.0   \n",
       "3  4.257  0.212  22.9  ...  28.0  563.0  NaN  33.4  9.1  8.48359    38.0   \n",
       "4    NaN    NaN  23.0  ...  33.0  556.0  NaN  48.0  6.7  9.52918    45.0   \n",
       "\n",
       "   MONTH  YEAR  SEASON  \n",
       "0      7  1993  SUMMER  \n",
       "1      7  1993  SUMMER  \n",
       "2      7  1993  SUMMER  \n",
       "3      7  1993  SUMMER  \n",
       "4      7  1993  SUMMER  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data[\"MONTH\"] = pd.DatetimeIndex(water_data[\"DATE\"]).month\n",
    "water_data[\"YEAR\"] = pd.DatetimeIndex(water_data[\"DATE\"]).year\n",
    "water_data[\"SEASON\"] = water_data[\"MONTH\"]\n",
    "\n",
    "# Dictionary mapping month to season\n",
    "seasons = {3 : 'SPRING',\n",
    "           4 : 'SPRING',\n",
    "           5 : 'SPRING',\n",
    "           6 : 'SUMMER',\n",
    "           7 : 'SUMMER',\n",
    "           8 : 'SUMMER',\n",
    "           9 : 'FALL',\n",
    "           10 : 'FALL',\n",
    "           11: 'FALL',\n",
    "           12: 'WINTER',\n",
    "           1: 'WINTER',\n",
    "           2: 'WINTER'}\n",
    "\n",
    "water_data = water_data.replace({\"SEASON\" : seasons})\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-florist",
   "metadata": {},
   "source": [
    "There were extreme outliers in TN that caused high errors in model performance, and it was decided to remove these values. Killian's IDW using 3 years did not do this, and that is why his TN MAE and RMSE are much higher than this IDW. Random Forrest, Multivariate Polynomial Regression did the same. I believe but I am not sure that Regression Trees did this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "handled-friday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46795    187.429\n",
       "46545    165.177\n",
       "46727    149.712\n",
       "29136     46.989\n",
       "55650     32.965\n",
       "          ...   \n",
       "82475        NaN\n",
       "82477        NaN\n",
       "82478        NaN\n",
       "82479        NaN\n",
       "82480        NaN\n",
       "Name: TN, Length: 82481, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data[\"TN\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "knowing-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29136    46.989\n",
       "55650    32.965\n",
       "19178    22.939\n",
       "55611    22.677\n",
       "59504    22.576\n",
       "          ...  \n",
       "82475       NaN\n",
       "82477       NaN\n",
       "82478       NaN\n",
       "82479       NaN\n",
       "82480       NaN\n",
       "Name: TN, Length: 82481, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data.loc[46795,\"TN\"] = None\n",
    "water_data.loc[46545,\"TN\"] = None\n",
    "water_data.loc[46727,\"TN\"] = None\n",
    "water_data[\"TN\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-cream",
   "metadata": {},
   "source": [
    "### Testing Method on TP, TN, and VEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-denial",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing by year, by season IDW interpolation\n",
      "\n",
      "-----------------------------------\n",
      "Testing  TN\n",
      "Building a new dataframe with predicted values\n",
      "Final data set size is  (32185, 22)\n",
      "Interpolating took 8.268683723608653 minutes\n",
      "The MAE for TN is 0.404327\n",
      "The RMSE for TN is 0.862958\n",
      "count    32185.000000\n",
      "mean         0.404327\n",
      "std          0.762388\n",
      "min          0.000000\n",
      "25%          0.072140\n",
      "50%          0.183478\n",
      "75%          0.457552\n",
      "max         41.981454\n",
      "Name: TN error, dtype: float64\n",
      "count    32185.000000\n",
      "mean         0.744697\n",
      "std         12.720244\n",
      "min          0.000000\n",
      "25%          0.005204\n",
      "50%          0.033664\n",
      "75%          0.209354\n",
      "max       1762.442480\n",
      "Name: TN squared error, dtype: float64\n",
      "\n",
      "-----------------------------------\n",
      "Testing  TP\n",
      "Building a new dataframe with predicted values\n",
      "Final data set size is  (31450, 22)\n",
      "Interpolating took 8.833173775672913 minutes\n",
      "The MAE for TP is 0.046904\n",
      "The RMSE for TP is 0.146266\n",
      "count    31450.000000\n",
      "mean         0.046904\n",
      "std          0.138544\n",
      "min          0.000000\n",
      "25%          0.006643\n",
      "50%          0.017496\n",
      "75%          0.044172\n",
      "max          6.907558\n",
      "Name: TP error, dtype: float64\n",
      "count    31450.000000\n",
      "mean         0.021394\n",
      "std          0.467176\n",
      "min          0.000000\n",
      "25%          0.000044\n",
      "50%          0.000306\n",
      "75%          0.001951\n",
      "max         47.714361\n",
      "Name: TP squared error, dtype: float64\n",
      "\n",
      "-----------------------------------\n",
      "Testing  VEL\n",
      "Building a new dataframe with predicted values\n"
     ]
    }
   ],
   "source": [
    "variables = [\"TN\",\"TP\",\"VEL\"]\n",
    "print(\"\\n\\nTesting by year, by season IDW interpolation\")\n",
    "for var in variables:\n",
    "    print(\"\\n-----------------------------------\")\n",
    "    print(\"Testing \",var)\n",
    "    # Filter by locations that we already have for this variable\n",
    "    water_test = water_data[water_data[var].notna()]\n",
    "    \n",
    "    # Increase verbosity for more output, make verbosity 0 to report only the errors\n",
    "    water_test_interpolated = IDW_interpolate(water_test,[var],testing=True,verbosity=0)\n",
    "    \n",
    "    # Save the interpolated dataset\n",
    "    path = \"Interpolation_analysis_datasets\\\\\"+var\n",
    "    #pickle.dump(water_test_interpolated,open(path+\"_interpolated.p\",\"wb\"))\n",
    "    \n",
    "    \n",
    "    # Get name of predicted column\n",
    "    newcol = \"PREDICTED_\"+var\n",
    "    \n",
    "    MAE = sklearn.metrics.mean_absolute_error(water_test_interpolated[var],water_test_interpolated[newcol])\n",
    "    RMSE = sklearn.metrics.mean_squared_error(water_test_interpolated[var],water_test_interpolated[newcol],squared=False)\n",
    "    print(f\"The MAE for {var} is {MAE:8f}\")\n",
    "    print(f\"The RMSE for {var} is {RMSE:8f}\")\n",
    "    \n",
    "    # Make error column names\n",
    "    error_col = var+\" error\"\n",
    "    squared_error_col = var+\" squared error\"\n",
    "    water_test_interpolated[error_col] = round(abs(water_test_interpolated[var] - water_test_interpolated[newcol]),6)\n",
    "    water_test_interpolated[squared_error_col] = round((water_test_interpolated[var] - water_test_interpolated[newcol])**2,6)\n",
    "    print(water_test_interpolated[error_col].describe())\n",
    "    print(water_test_interpolated[squared_error_col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-button",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
