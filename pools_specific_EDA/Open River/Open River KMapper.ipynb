{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informed-cosmetic",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "from kmapper.plotlyviz import *\n",
    "import sklearn\n",
    "# DBSCAN from sklearn for clustering algorithms\n",
    "from sklearn.cluster import DBSCAN\n",
    "# PCA from sklearn for projection/lens creation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Plotly and Dash\n",
    "import plotly.graph_objs as go\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash\n",
    "from ipywidgets import interactive, HBox, VBox, widgets, interact\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-commander",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ethical-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_fun(X, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = [7,7], PERC_OVERLAP = [.5,.5]):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "#     keys = list(dict_df.keys())\n",
    "#     print(keys)\n",
    "#     X = dict_df.get(keys[0])\n",
    "    X = X[[\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\",\"PREDICTED_COND\", \"PREDICTED_VEL\", \"PREDICTED_TP\", \n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]]\n",
    "    if X.shape[0]<DBSCAN_MIN_SAMPLES:\n",
    "        #print(X)\n",
    "        print(\"Not enough data to cluster in \", keys, \"_size = \", X.shape[0])\n",
    "        print(\"DBSCAN_MIN_SAMPLES\", DBSCAN_MIN_SAMPLES)\n",
    "        return([DBSCAN_MIN_SAMPLES, X.shape[0]])\n",
    "    \n",
    "    \n",
    "    db = DBSCAN(eps=20, min_samples=2).fit(X)\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    \n",
    "    return(db)\n",
    "\n",
    "    \n",
    "    \n",
    "def mapper_pca_func(X,title, DBSCAN_EPSILON = 20, DBSCAN_MIN_SAMPLES = 1, N_CUBES = 7, PERC_OVERLAP = .5):\n",
    "    \"\"\"\n",
    "    str(df_stratum_season_time_dict_list[1].keys())\n",
    "    \"\"\"\n",
    "    \n",
    "    # \n",
    "#     keys = list(dict_df.keys())\n",
    "#     print(keys)\n",
    "#     X = dict_df.get(keys[0])\n",
    "    X = X[[\"PREDICTED_WDP\", \"PREDICTED_SECCHI\", \"PREDICTED_TEMP\", \"PREDICTED_DO\", \n",
    "           \"PREDICTED_TURB\",\"PREDICTED_COND\", \"PREDICTED_VEL\", \"PREDICTED_TP\", \n",
    "           \"PREDICTED_TN\", \"PREDICTED_SS\", \"PREDICTED_CHLcal\"]]\n",
    "    \n",
    "    if X.shape[0]<10:\n",
    "        #print(X)\n",
    "        print(\"Not enough data in \", keys, \"_size = \", X.shape[0])\n",
    "        return(X.shape[0])\n",
    "\n",
    "    # defining clustering and kmapper parameters\n",
    "    \n",
    "    # create instance of clustering alg\n",
    "    cluster_alg = sklearn.cluster.DBSCAN(eps=DBSCAN_EPSILON, min_samples=DBSCAN_MIN_SAMPLES, metric='euclidean')\n",
    "\n",
    "    # Instantiate kepler mapper object\n",
    "    mapper = km.KeplerMapper(verbose=0)\n",
    "    \n",
    "    # defining filter function as projection on to the first 2 component axis\n",
    "    pca = PCA(n_components=1)\n",
    "    lens = pca.fit_transform(X)\n",
    "    \n",
    "    # Generate the simplicial complex\n",
    "    scomplex = mapper.map(lens, X, cover=km.Cover(n_cubes=N_CUBES, perc_overlap=PERC_OVERLAP), clusterer=cluster_alg)  \n",
    "\n",
    "\n",
    "    pl_brewer = [[0.0, '#006837'],\n",
    "             [0.1, '#1a9850'],\n",
    "             [0.2, '#66bd63'],\n",
    "             [0.3, '#a6d96a'],\n",
    "             [0.4, '#d9ef8b'],\n",
    "             [0.5, '#ffffbf'],\n",
    "             [0.6, '#fee08b'],\n",
    "             [0.7, '#fdae61'],\n",
    "             [0.8, '#f46d43'],\n",
    "             [0.9, '#d73027'],\n",
    "             [1.0, '#a50026']]\n",
    "\n",
    "    color_values = lens [:,0] - lens[:,0].min()\n",
    "    my_colorscale = pl_brewer\n",
    "    kmgraph,  mapper_summary, colorf_distribution = get_mapper_graph(scomplex, \n",
    "                                                                     color_values,  \n",
    "                                                                     color_function_name='Distance to x-min', \n",
    "                                                                     colorscale=my_colorscale)\n",
    "\n",
    "    bgcolor = 'rgba(10,10,10, 0.9)'\n",
    "    # y_gridcolor = 'rgb(150,150,150)'# on a black background the gridlines are set on  grey\n",
    "\n",
    "    plotly_graph_data = plotly_graph(kmgraph, graph_layout='fr', colorscale=my_colorscale, \n",
    "                                     factor_size=2.5, edge_linewidth=0.5)\n",
    "    plot_title = title + str(DBSCAN_EPSILON) + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    # plot_title = 'Pool 13, Summer 1993-1999; Epsilon ' + str(DBSCAN_EPSILON) + ', MIN_SAMPLES ' + str(DBSCAN_MIN_SAMPLES) \n",
    "    layout = plot_layout(title=plot_title,  \n",
    "                         width=620, height=570,\n",
    "                         annotation_text=get_kmgraph_meta(mapper_summary),  \n",
    "                         bgcolor=bgcolor)\n",
    "    \n",
    "    # FigureWidget is responsible for event listeners\n",
    "\n",
    "    fw_graph = go.FigureWidget(data=plotly_graph_data, layout=layout)\n",
    "    fw_hist = node_hist_fig(colorf_distribution, bgcolor=bgcolor)\n",
    "    fw_summary = summary_fig(mapper_summary, height=300)\n",
    "\n",
    "    dashboard = hovering_widgets(kmgraph, \n",
    "                                 fw_graph, \n",
    "                                 bgcolor=bgcolor, \n",
    "                                 member_textbox_width=600)\n",
    "\n",
    "    # DESIRED FILE PATH, CHANGE TO FIT YOUR LOCAL MACHINE\n",
    "    directory_path = r\"Mapper outputs\"\n",
    "    \n",
    "    #Update the fw_graph colorbar, setting its title:\n",
    "    fw_graph.data[1].marker.colorbar.title = 'dist to<br>x-min'\n",
    "    html_output_path = directory_path + \"\\\\\" + title + 'PCA_1' + 'all_var_' + 'Eps_' + str(DBSCAN_EPSILON) +'MinS_' + str(DBSCAN_MIN_SAMPLES) + 'NCUBES_' + str(N_CUBES) + 'PEROvLp_' + str(PERC_OVERLAP) + '.html'\n",
    "    html_output_path = html_output_path.replace(\":\",\"_\")\n",
    "    mapper.visualize(scomplex, path_html=html_output_path)\n",
    "    return(scomplex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-labor",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rotary-fishing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHEETBAR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>FLDNUM</th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>LOCATCD</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>...</th>\n",
       "      <th>PREDICTED_TP</th>\n",
       "      <th>PREDICTED_TEMP</th>\n",
       "      <th>PREDICTED_DO</th>\n",
       "      <th>PREDICTED_TURB</th>\n",
       "      <th>PREDICTED_COND</th>\n",
       "      <th>PREDICTED_VEL</th>\n",
       "      <th>PREDICTED_SS</th>\n",
       "      <th>PREDICTED_WDP</th>\n",
       "      <th>PREDICTED_CHLcal</th>\n",
       "      <th>PREDICTED_SECCHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001219</td>\n",
       "      <td>04/24/1995</td>\n",
       "      <td>37.309363</td>\n",
       "      <td>-89.512099</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9551101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20800</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>210.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.566517</td>\n",
       "      <td>158.799943</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.87946</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45001220</td>\n",
       "      <td>04/24/1995</td>\n",
       "      <td>37.311229</td>\n",
       "      <td>-89.514268</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9551100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20800</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>230.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.565424</td>\n",
       "      <td>176.740056</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.25618</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45001221</td>\n",
       "      <td>04/24/1995</td>\n",
       "      <td>37.323359</td>\n",
       "      <td>-89.497913</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9551099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44675</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>220.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.530415</td>\n",
       "      <td>226.904952</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.43426</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45001222</td>\n",
       "      <td>04/24/1995</td>\n",
       "      <td>37.325091</td>\n",
       "      <td>-89.495577</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9551018</td>\n",
       "      <td>7.961</td>\n",
       "      <td>0.508</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50800</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>210.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.522220</td>\n",
       "      <td>212.720407</td>\n",
       "      <td>14.7</td>\n",
       "      <td>11.36578</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45001223</td>\n",
       "      <td>04/24/1995</td>\n",
       "      <td>37.328490</td>\n",
       "      <td>-89.488649</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9551017</td>\n",
       "      <td>4.282</td>\n",
       "      <td>0.110</td>\n",
       "      <td>12.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11000</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>210.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.493716</td>\n",
       "      <td>182.309561</td>\n",
       "      <td>5.8</td>\n",
       "      <td>11.98906</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHEETBAR        DATE   LATITUDE  LONGITUDE  FLDNUM  STRATUM  LOCATCD  \\\n",
       "0  45001219  04/24/1995  37.309363 -89.512099       5        1  9551101   \n",
       "1  45001220  04/24/1995  37.311229 -89.514268       5        1  9551100   \n",
       "2  45001221  04/24/1995  37.323359 -89.497913       5        1  9551099   \n",
       "3  45001222  04/24/1995  37.325091 -89.495577       5        1  9551018   \n",
       "4  45001223  04/24/1995  37.328490 -89.488649       5        1  9551017   \n",
       "\n",
       "      TN     TP  TEMP  ...  PREDICTED_TP  PREDICTED_TEMP  PREDICTED_DO  \\\n",
       "0    NaN    NaN  12.9  ...       0.20800            12.9           8.5   \n",
       "1    NaN    NaN  13.0  ...       0.20800            13.0           8.5   \n",
       "2    NaN    NaN  12.9  ...       0.44675            12.9           8.6   \n",
       "3  7.961  0.508  12.8  ...       0.50800            12.8           8.6   \n",
       "4  4.282  0.110  12.8  ...       0.11000            12.8           8.6   \n",
       "\n",
       "   PREDICTED_TURB  PREDICTED_COND  PREDICTED_VEL  PREDICTED_SS  PREDICTED_WDP  \\\n",
       "0           210.0           417.0       0.566517    158.799943           12.1   \n",
       "1           230.0           414.0       0.565424    176.740056            9.4   \n",
       "2           220.0           418.0       0.530415    226.904952           12.7   \n",
       "3           210.0           418.0       0.522220    212.720407           14.7   \n",
       "4           210.0           418.0       0.493716    182.309561            5.8   \n",
       "\n",
       "   PREDICTED_CHLcal PREDICTED_SECCHI  \n",
       "0          12.87946             13.0  \n",
       "1          12.25618             15.0  \n",
       "2          12.43426             15.0  \n",
       "3          11.36578             15.0  \n",
       "4          11.98906             15.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df = pd.read_csv(r\"Interpolated Data\\allvars_interpolated_3yearsxseason.csv\")\n",
    "predicted_df.drop(\"Unnamed: 0\",axis = 1,inplace = True)\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "centered-vaccine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "### Creating three main time spans and two overlapping time spans,\n",
    "### a total of five time spans\n",
    "\n",
    "# defining different time periods\n",
    "# first decade\n",
    "time_dec1 = [1993, 1994, 1995, 1997, 1998, 1999, 2000]\n",
    "# second decade\n",
    "time_dec2 = [2001, 2002,2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013]\n",
    "# third decade\n",
    "time_dec3 = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "# overlap time periods for continuity\n",
    "time_overlap1 = [1998, 1999, 2000, 2001, 2002,2003, 2004]\n",
    "time_overlap2 = [2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "time_list = [time_dec1, time_overlap1, time_dec2, time_overlap2, time_dec3]\n",
    "\n",
    "time_list_names = ['93-00', '98-04', '01-13', '10-16', '14-20']\n",
    "# The stratums in my pool\n",
    "stratum_list = [1, 2] #, 4, 5, 6, 7, 9]\n",
    "# The seasons we are currently looking at\n",
    "Season_names = [\"SUMMER\"] #, \"SPRING\", \"FALL\", \"WINTER\"]\n",
    "\n",
    "\n",
    "df_stratum_season_time_dict = {}\n",
    "s=\"\"\n",
    "for i in range(len(time_list)):\n",
    "    for j in stratum_list:\n",
    "        for k in Season_names:\n",
    "            s= \"Stratum \" + str(j)+ \" \" + k + \" \" + time_list_names[i] + \": \"\n",
    "            df_stratum_season_time_dict[s] = predicted_df[(predicted_df['YEAR'].isin(time_list[i])) &\n",
    "                                                             (predicted_df['STRATUM'].isin([j])) & \n",
    "                                                             (predicted_df['SEASON'].isin([k]))]\n",
    "            s=\"\"\n",
    "print(len(df_stratum_season_time_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "monetary-times",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stratum 1 SUMMER 93-00_'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Stratum 1 SUMMER 93-00:\"\n",
    "test.replace(\":\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blocked-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratum 1 SUMMER 93-00: \n",
      "Stratum 2 SUMMER 93-00: \n",
      "Stratum 1 SUMMER 98-04: \n",
      "Stratum 2 SUMMER 98-04: \n",
      "Stratum 1 SUMMER 01-13: \n",
      "Stratum 2 SUMMER 01-13: \n",
      "Stratum 1 SUMMER 10-16: \n",
      "Stratum 2 SUMMER 10-16: \n",
      "Stratum 1 SUMMER 14-20: \n",
      "Stratum 2 SUMMER 14-20: \n"
     ]
    }
   ],
   "source": [
    "for key in df_stratum_season_time_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "controlling-photographer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_stratum_season_time_dict_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f0ee6b5ad7e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdbclus_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_stratum_season_time_dict_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdbclus_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_stratum_season_time_dict_list' is not defined"
     ]
    }
   ],
   "source": [
    "# dbclus_dict = {}\n",
    "# for i in df_stratum_season_time_dict_list:\n",
    "#     dbclus_dict[str(list(i.keys()))]=cluster_fun(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relative-tiffany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 32\n",
      "Estimated number of noise points: 48\n",
      "Estimated number of clusters: 21\n",
      "Estimated number of noise points: 54\n",
      "Estimated number of clusters: 20\n",
      "Estimated number of noise points: 36\n",
      "Estimated number of clusters: 18\n",
      "Estimated number of noise points: 40\n",
      "Estimated number of clusters: 18\n",
      "Estimated number of noise points: 30\n",
      "Estimated number of clusters: 11\n",
      "Estimated number of noise points: 41\n",
      "Estimated number of clusters: 23\n",
      "Estimated number of noise points: 44\n",
      "Estimated number of clusters: 25\n",
      "Estimated number of noise points: 43\n",
      "Estimated number of clusters: 25\n",
      "Estimated number of noise points: 50\n",
      "Estimated number of clusters: 30\n",
      "Estimated number of noise points: 47\n"
     ]
    }
   ],
   "source": [
    "dbclus_dict = {}\n",
    "for key in df_stratum_season_time_dict:\n",
    "    dbclus_dict[key] = cluster_fun(df_stratum_season_time_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "intelligent-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cubes = [5, 10, 15]\n",
    "perc_overlap = [.35, .45, .55]\n",
    "\n",
    "mapper_pca_output_dict = {}\n",
    "for key in df_stratum_season_time_dict:\n",
    "    for j in n_cubes:\n",
    "        for k in perc_overlap:\n",
    "            newkey = key+\"ncubes_\"+str(j)+\"_overlap_\"+str(k)\n",
    "            mapper_pca_output_dict[newkey] = mapper_pca_func(df_stratum_season_time_dict[key],key, N_CUBES = j, PERC_OVERLAP = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wound-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapper_pca_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-amount",
   "metadata": {},
   "source": [
    "Saving all outputs to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "industrial-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsonFile = json.dumps(mapper_pca_output_dict)\n",
    "f = open(\"All_graphs.json\",\"w\")\n",
    "f.write(jsonFile)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-valve",
   "metadata": {},
   "source": [
    "Load mapper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "english-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFilePath = r\"All_graphs.json\"\n",
    "jsonFile = open(jsonFilePath,\"r\")\n",
    "data = json.load(jsonFile)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ordinary-series",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-parliament",
   "metadata": {},
   "source": [
    "Pick one output to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "documentary-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratum 2 SUMMER 01-13: ncubes_10_overlap_0.45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['nodes', 'links', 'simplices', 'meta_data', 'meta_nodes'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key = list(data.keys())[0]\n",
    "key = \"Stratum 2 SUMMER 01-13: ncubes_10_overlap_0.45\"\n",
    "print(key)\n",
    "output = data[key]\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-third",
   "metadata": {},
   "source": [
    "Function to return a nested list of connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "activated-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components(output):\n",
    "    simplices = output.get(\"simplices\")\n",
    "    # Pick out the edges\n",
    "    pairs = [item for item in simplices if len(item)==2]\n",
    "    # Pick out all nodes\n",
    "    nodes = output.get(\"nodes\").keys()\n",
    "    # Unpacks the list of lists to get every node that is connected to at least one other node with an edge\n",
    "    connected_nodes = [node for sublist in edges for node in sublist]\n",
    "    # Pick out the nodes that are its own connected component (not a connected node)\n",
    "    singles = [[node] for node in nodes if node not in connected_nodes]\n",
    "    \n",
    "    # Build connected components\n",
    "    components = []\n",
    "    for a, b in pairs:\n",
    "        for component in components:\n",
    "            if a in component:\n",
    "                for i, other_component in enumerate(components):\n",
    "                    if b in other_component and other_component != component: # a, and b are already in different components: merge\n",
    "                        component.extend(other_component)\n",
    "                        components[i:i+1] = []\n",
    "                        break # we don't have to look for other components for b\n",
    "                else: # b wasn't found in any other component\n",
    "                    if b not in component:\n",
    "                        component.append(b)\n",
    "                break # we don't have to look for other components for a\n",
    "            if b in component: # a wasn't in in the component \n",
    "                component.append(a)\n",
    "                break # we don't have to look further\n",
    "        else: # neither a nor b were found\n",
    "            components.append([a, b])\n",
    "            \n",
    "    # Add the singles into the components\n",
    "    print(\"Number of singles:\",len(singles))\n",
    "    components.extend(singles)\n",
    "    \n",
    "    # Sort the components by size\n",
    "    components.sort(reverse = True, key = len)\n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "occupational-worth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of singles: 15\n"
     ]
    }
   ],
   "source": [
    "components = connected_components(output)\n",
    "len(components)\n",
    "for component in components:\n",
    "    print(len(component))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "understood-uruguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cube0_cluster0',\n",
       "  'cube1_cluster0',\n",
       "  'cube2_cluster0',\n",
       "  'cube2_cluster9',\n",
       "  'cube3_cluster0',\n",
       "  'cube3_cluster5',\n",
       "  'cube3_cluster16',\n",
       "  'cube4_cluster4',\n",
       "  'cube5_cluster2'],\n",
       " ['cube3_cluster19',\n",
       "  'cube4_cluster14',\n",
       "  'cube3_cluster20',\n",
       "  'cube5_cluster7',\n",
       "  'cube6_cluster3'],\n",
       " ['cube5_cluster5',\n",
       "  'cube6_cluster2',\n",
       "  'cube7_cluster0',\n",
       "  'cube8_cluster0',\n",
       "  'cube9_cluster7'],\n",
       " ['cube4_cluster0', 'cube5_cluster0', 'cube6_cluster0', 'cube6_cluster1'],\n",
       " ['cube2_cluster17', 'cube3_cluster14', 'cube4_cluster12'],\n",
       " ['cube3_cluster11', 'cube4_cluster7', 'cube3_cluster12'],\n",
       " ['cube0_cluster1', 'cube1_cluster6'],\n",
       " ['cube0_cluster2', 'cube1_cluster11'],\n",
       " ['cube1_cluster1', 'cube2_cluster6'],\n",
       " ['cube1_cluster2', 'cube2_cluster7'],\n",
       " ['cube1_cluster3', 'cube2_cluster8'],\n",
       " ['cube1_cluster4', 'cube2_cluster11'],\n",
       " ['cube1_cluster5', 'cube2_cluster12'],\n",
       " ['cube1_cluster7', 'cube2_cluster13'],\n",
       " ['cube1_cluster8', 'cube2_cluster14'],\n",
       " ['cube1_cluster9', 'cube2_cluster15'],\n",
       " ['cube1_cluster10', 'cube2_cluster19'],\n",
       " ['cube2_cluster1', 'cube3_cluster1'],\n",
       " ['cube2_cluster3', 'cube3_cluster2'],\n",
       " ['cube2_cluster4', 'cube3_cluster6'],\n",
       " ['cube2_cluster5', 'cube3_cluster8'],\n",
       " ['cube2_cluster10', 'cube3_cluster13'],\n",
       " ['cube2_cluster16', 'cube3_cluster15'],\n",
       " ['cube3_cluster3', 'cube4_cluster1'],\n",
       " ['cube3_cluster4', 'cube4_cluster2'],\n",
       " ['cube3_cluster7', 'cube4_cluster3'],\n",
       " ['cube3_cluster9', 'cube4_cluster5'],\n",
       " ['cube3_cluster17', 'cube4_cluster16'],\n",
       " ['cube3_cluster18', 'cube4_cluster17'],\n",
       " ['cube4_cluster8', 'cube5_cluster1'],\n",
       " ['cube4_cluster10', 'cube5_cluster3'],\n",
       " ['cube4_cluster11', 'cube5_cluster4'],\n",
       " ['cube4_cluster13', 'cube5_cluster6'],\n",
       " ['cube4_cluster15', 'cube5_cluster8'],\n",
       " ['cube4_cluster18', 'cube5_cluster9'],\n",
       " ['cube8_cluster1', 'cube9_cluster0'],\n",
       " ['cube8_cluster2', 'cube9_cluster5'],\n",
       " ['cube0_cluster3'],\n",
       " ['cube0_cluster4'],\n",
       " ['cube0_cluster5'],\n",
       " ['cube0_cluster6'],\n",
       " ['cube2_cluster2'],\n",
       " ['cube2_cluster18'],\n",
       " ['cube3_cluster10'],\n",
       " ['cube4_cluster6'],\n",
       " ['cube4_cluster9'],\n",
       " ['cube5_cluster10'],\n",
       " ['cube9_cluster1'],\n",
       " ['cube9_cluster2'],\n",
       " ['cube9_cluster3'],\n",
       " ['cube9_cluster4'],\n",
       " ['cube9_cluster6']]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-southwest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
